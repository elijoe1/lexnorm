{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import graphviz as graphviz\n",
    "import tree as tree\n",
    "\n",
    "import lexnorm.models.normalise\n",
    "from lexnorm.definitions import DATA_PATH\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, \"hpc/train_ngrams.txt\"), index_col=0, keep_default_na=False, na_values=\"\")\n",
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/dev_ngrams.txt\"), index_col=0, keep_default_na=False, na_values=\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "      cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\nan          0.377180              NaN            NaN                  NaN   \nca          0.255824              NaN            NaN                  NaN   \ncab         0.261057              NaN            NaN                  NaN   \ncam         0.299136              NaN            NaN                  NaN   \ncan         1.000000              NaN            NaN                  1.0   \n...              ...              ...            ...                  ...   \nlulu        0.401415              NaN            NaN                  NaN   \npol         0.230619              NaN            NaN                  NaN   \nsmh         0.896277              2.0            NaN                  NaN   \nsol         0.285978              NaN            NaN                  NaN   \nvol         0.235724              NaN            NaN                  NaN   \n\n      from_split  norms_seen  spellcheck_rank  in_lexicon  length  same_order  \\\nan           NaN         NaN              4.0         1.0       2         NaN   \nca           NaN         NaN              5.0         1.0       2         NaN   \ncab          NaN         NaN              2.0         1.0       3         NaN   \ncam          NaN         NaN              3.0         1.0       3         NaN   \ncan          NaN        72.0              NaN         1.0       3         1.0   \n...          ...         ...              ...         ...     ...         ...   \nlulu         NaN         NaN             15.0         1.0       4         NaN   \npol          NaN         NaN             10.0         1.0       3         NaN   \nsmh          NaN         NaN              NaN         NaN       3         NaN   \nsol          NaN         NaN              4.0         1.0       3         NaN   \nvol          NaN         NaN             13.0         NaN       3         NaN   \n\n      ...  next  process  tweet  tok twitter_uni twitter_bi_prev  \\\nan    ...   you       35      0    2    44841230        0.000000   \nca    ...   you       35      0    2      779786        0.000000   \ncab   ...   you       35      0    2      197597        0.000000   \ncam   ...   you       35      0    2     1000282        0.000000   \ncan   ...   you       35      0    2    71160951        0.000001   \n...   ...   ...      ...    ...  ...         ...             ...   \nlulu  ...     \"       32      9   25       71752        0.000000   \npol   ...     \"       32      9   25       55886        0.000000   \nsmh   ...     \"       32      9   25     4365260        0.000056   \nsol   ...     \"       32      9   25      130095        0.000000   \nvol   ...     \"       32      9   25      121788        0.000000   \n\n     twitter_bi_next  wiki_uni  wiki_bi_prev  wiki_bi_next  \nan          0.000645   9348289           0.0  7.488001e-07  \nca          0.001702     13058           0.0  0.000000e+00  \ncab         0.004838     13063           0.0  0.000000e+00  \ncam         0.006341     10015           0.0  0.000000e+00  \ncan         0.083374   1938264           0.0  1.226355e-03  \n...              ...       ...           ...           ...  \nlulu        0.000181      3345           0.0  0.000000e+00  \npol         0.000072      3705           0.0  0.000000e+00  \nsmh         0.000154       135           0.0  0.000000e+00  \nsol         0.000300      9006           0.0  3.331113e-04  \nvol         0.000000      2936           0.0  0.000000e+00  \n\n[724672 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>...</th>\n      <th>next</th>\n      <th>process</th>\n      <th>tweet</th>\n      <th>tok</th>\n      <th>twitter_uni</th>\n      <th>twitter_bi_prev</th>\n      <th>twitter_bi_next</th>\n      <th>wiki_uni</th>\n      <th>wiki_bi_prev</th>\n      <th>wiki_bi_next</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>an</th>\n      <td>0.377180</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>you</td>\n      <td>35</td>\n      <td>0</td>\n      <td>2</td>\n      <td>44841230</td>\n      <td>0.000000</td>\n      <td>0.000645</td>\n      <td>9348289</td>\n      <td>0.0</td>\n      <td>7.488001e-07</td>\n    </tr>\n    <tr>\n      <th>ca</th>\n      <td>0.255824</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>you</td>\n      <td>35</td>\n      <td>0</td>\n      <td>2</td>\n      <td>779786</td>\n      <td>0.000000</td>\n      <td>0.001702</td>\n      <td>13058</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>cab</th>\n      <td>0.261057</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>you</td>\n      <td>35</td>\n      <td>0</td>\n      <td>2</td>\n      <td>197597</td>\n      <td>0.000000</td>\n      <td>0.004838</td>\n      <td>13063</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>cam</th>\n      <td>0.299136</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>you</td>\n      <td>35</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1000282</td>\n      <td>0.000000</td>\n      <td>0.006341</td>\n      <td>10015</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>can</th>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>72.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>you</td>\n      <td>35</td>\n      <td>0</td>\n      <td>2</td>\n      <td>71160951</td>\n      <td>0.000001</td>\n      <td>0.083374</td>\n      <td>1938264</td>\n      <td>0.0</td>\n      <td>1.226355e-03</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>lulu</th>\n      <td>0.401415</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"</td>\n      <td>32</td>\n      <td>9</td>\n      <td>25</td>\n      <td>71752</td>\n      <td>0.000000</td>\n      <td>0.000181</td>\n      <td>3345</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>pol</th>\n      <td>0.230619</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"</td>\n      <td>32</td>\n      <td>9</td>\n      <td>25</td>\n      <td>55886</td>\n      <td>0.000000</td>\n      <td>0.000072</td>\n      <td>3705</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>smh</th>\n      <td>0.896277</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"</td>\n      <td>32</td>\n      <td>9</td>\n      <td>25</td>\n      <td>4365260</td>\n      <td>0.000056</td>\n      <td>0.000154</td>\n      <td>135</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>sol</th>\n      <td>0.285978</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"</td>\n      <td>32</td>\n      <td>9</td>\n      <td>25</td>\n      <td>130095</td>\n      <td>0.000000</td>\n      <td>0.000300</td>\n      <td>9006</td>\n      <td>0.0</td>\n      <td>3.331113e-04</td>\n    </tr>\n    <tr>\n      <th>vol</th>\n      <td>0.235724</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"</td>\n      <td>32</td>\n      <td>9</td>\n      <td>25</td>\n      <td>121788</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2936</td>\n      <td>0.0</td>\n      <td>0.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n<p>724672 rows × 26 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "dev"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "train.fillna(0, inplace=True)\n",
    "dev.fillna(0, inplace=True)\n",
    "X_train = train.drop([\"correct\", \"process\", \"tweet\", \"tok\", \"gold\", \"raw\", \"prev\", \"next\"], axis=1)\n",
    "X_dev = dev.drop([\"process\", \"tweet\", \"tok\", \"raw\", \"prev\", \"next\"], axis=1)\n",
    "y_train = train[\"correct\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "      cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\nan          0.627653        -0.170470      -2.474822            -0.097874   \nca          0.057893        -0.170470      -2.474822            -0.097874   \ncab         0.082459        -0.170470      -2.474822            -0.097874   \ncam         0.261241        -0.170470      -2.474822            -0.097874   \ncan         3.551773        -0.170470      -2.474822            10.217216   \n...              ...              ...            ...                  ...   \nlulu        0.741435        -0.170470      -2.474822            -0.097874   \npol        -0.060446        -0.170470      -2.474822            -0.097874   \nsmh         3.064797         1.999929      -2.474822            -0.097874   \nsol         0.199462        -0.170470      -2.474822            -0.097874   \nvol        -0.036479        -0.170470      -2.474822            -0.097874   \n\n      from_split  norms_seen  spellcheck_rank  in_lexicon    length  \\\nan      -0.04862   -0.048873         1.195236    0.227769 -2.076705   \nca      -0.04862   -0.048873         1.565143    0.227769 -2.076705   \ncab     -0.04862   -0.048873         0.455422    0.227769 -1.746082   \ncam     -0.04862   -0.048873         0.825329    0.227769 -1.746082   \ncan     -0.04862    4.885382        -0.284392    0.227769 -1.746082   \n...          ...         ...              ...         ...       ...   \nlulu    -0.04862   -0.048873         5.264212    0.227769 -1.415459   \npol     -0.04862   -0.048873         3.414678    0.227769 -1.746082   \nsmh     -0.04862   -0.048873        -0.284392   -4.390404 -1.746082   \nsol     -0.04862   -0.048873         1.195236    0.227769 -1.746082   \nvol     -0.04862   -0.048873         4.524398   -4.390404 -1.746082   \n\n      same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\nan     -3.048499        -0.663646         0.337691              0.0   \nca     -3.048499        -0.663646         0.337691              0.0   \ncab    -3.048499        -0.663646         0.337691              0.0   \ncam    -3.048499        -0.663646         0.337691              0.0   \ncan     0.328030        -0.663646         0.337691              0.0   \n...          ...              ...              ...              ...   \nlulu   -3.048499         0.230612         0.337691              0.0   \npol    -3.048499         0.230612         0.337691              0.0   \nsmh    -3.048499         0.230612         0.337691              0.0   \nsol    -3.048499         0.230612         0.337691              0.0   \nvol    -3.048499         0.230612         0.337691              0.0   \n\n      orig_length  twitter_uni  twitter_bi_prev  twitter_bi_next  wiki_uni  \\\nan       0.416862     1.501276        -0.148572        -0.120367  2.384874   \nca       0.416862    -0.064304        -0.148572        -0.080547 -0.054789   \ncab      0.416862    -0.084990        -0.148572         0.037614 -0.054788   \ncam      0.416862    -0.056469        -0.148572         0.094242 -0.055585   \ncan      0.416862     2.436461        -0.148520         2.996429  0.448343   \n...           ...          ...              ...              ...       ...   \nlulu     0.416862    -0.089461        -0.148572        -0.137834 -0.057328   \npol      0.416862    -0.090025        -0.148572        -0.141963 -0.057234   \nsmh      0.416862     0.063094        -0.146468        -0.138869 -0.058167   \nsol      0.416862    -0.087388        -0.148572        -0.133366 -0.055848   \nvol      0.416862    -0.087684        -0.148572        -0.144660 -0.057435   \n\n      wiki_bi_prev  wiki_bi_next  \nan       -0.122505     -0.121960  \nca       -0.122505     -0.121987  \ncab      -0.122505     -0.121987  \ncam      -0.122505     -0.121987  \ncan      -0.122505     -0.077587  \n...            ...           ...  \nlulu     -0.122505     -0.121987  \npol      -0.122505     -0.121987  \nsmh      -0.122505     -0.121987  \nsol      -0.122505     -0.109927  \nvol      -0.122505     -0.121987  \n\n[724672 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>twitter_uni</th>\n      <th>twitter_bi_prev</th>\n      <th>twitter_bi_next</th>\n      <th>wiki_uni</th>\n      <th>wiki_bi_prev</th>\n      <th>wiki_bi_next</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>an</th>\n      <td>0.627653</td>\n      <td>-0.170470</td>\n      <td>-2.474822</td>\n      <td>-0.097874</td>\n      <td>-0.04862</td>\n      <td>-0.048873</td>\n      <td>1.195236</td>\n      <td>0.227769</td>\n      <td>-2.076705</td>\n      <td>-3.048499</td>\n      <td>-0.663646</td>\n      <td>0.337691</td>\n      <td>0.0</td>\n      <td>0.416862</td>\n      <td>1.501276</td>\n      <td>-0.148572</td>\n      <td>-0.120367</td>\n      <td>2.384874</td>\n      <td>-0.122505</td>\n      <td>-0.121960</td>\n    </tr>\n    <tr>\n      <th>ca</th>\n      <td>0.057893</td>\n      <td>-0.170470</td>\n      <td>-2.474822</td>\n      <td>-0.097874</td>\n      <td>-0.04862</td>\n      <td>-0.048873</td>\n      <td>1.565143</td>\n      <td>0.227769</td>\n      <td>-2.076705</td>\n      <td>-3.048499</td>\n      <td>-0.663646</td>\n      <td>0.337691</td>\n      <td>0.0</td>\n      <td>0.416862</td>\n      <td>-0.064304</td>\n      <td>-0.148572</td>\n      <td>-0.080547</td>\n      <td>-0.054789</td>\n      <td>-0.122505</td>\n      <td>-0.121987</td>\n    </tr>\n    <tr>\n      <th>cab</th>\n      <td>0.082459</td>\n      <td>-0.170470</td>\n      <td>-2.474822</td>\n      <td>-0.097874</td>\n      <td>-0.04862</td>\n      <td>-0.048873</td>\n      <td>0.455422</td>\n      <td>0.227769</td>\n      <td>-1.746082</td>\n      <td>-3.048499</td>\n      <td>-0.663646</td>\n      <td>0.337691</td>\n      <td>0.0</td>\n      <td>0.416862</td>\n      <td>-0.084990</td>\n      <td>-0.148572</td>\n      <td>0.037614</td>\n      <td>-0.054788</td>\n      <td>-0.122505</td>\n      <td>-0.121987</td>\n    </tr>\n    <tr>\n      <th>cam</th>\n      <td>0.261241</td>\n      <td>-0.170470</td>\n      <td>-2.474822</td>\n      <td>-0.097874</td>\n      <td>-0.04862</td>\n      <td>-0.048873</td>\n      <td>0.825329</td>\n      <td>0.227769</td>\n      <td>-1.746082</td>\n      <td>-3.048499</td>\n      <td>-0.663646</td>\n      <td>0.337691</td>\n      <td>0.0</td>\n      <td>0.416862</td>\n      <td>-0.056469</td>\n      <td>-0.148572</td>\n      <td>0.094242</td>\n      <td>-0.055585</td>\n      <td>-0.122505</td>\n      <td>-0.121987</td>\n    </tr>\n    <tr>\n      <th>can</th>\n      <td>3.551773</td>\n      <td>-0.170470</td>\n      <td>-2.474822</td>\n      <td>10.217216</td>\n      <td>-0.04862</td>\n      <td>4.885382</td>\n      <td>-0.284392</td>\n      <td>0.227769</td>\n      <td>-1.746082</td>\n      <td>0.328030</td>\n      <td>-0.663646</td>\n      <td>0.337691</td>\n      <td>0.0</td>\n      <td>0.416862</td>\n      <td>2.436461</td>\n      <td>-0.148520</td>\n      <td>2.996429</td>\n      <td>0.448343</td>\n      <td>-0.122505</td>\n      <td>-0.077587</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>lulu</th>\n      <td>0.741435</td>\n      <td>-0.170470</td>\n      <td>-2.474822</td>\n      <td>-0.097874</td>\n      <td>-0.04862</td>\n      <td>-0.048873</td>\n      <td>5.264212</td>\n      <td>0.227769</td>\n      <td>-1.415459</td>\n      <td>-3.048499</td>\n      <td>0.230612</td>\n      <td>0.337691</td>\n      <td>0.0</td>\n      <td>0.416862</td>\n      <td>-0.089461</td>\n      <td>-0.148572</td>\n      <td>-0.137834</td>\n      <td>-0.057328</td>\n      <td>-0.122505</td>\n      <td>-0.121987</td>\n    </tr>\n    <tr>\n      <th>pol</th>\n      <td>-0.060446</td>\n      <td>-0.170470</td>\n      <td>-2.474822</td>\n      <td>-0.097874</td>\n      <td>-0.04862</td>\n      <td>-0.048873</td>\n      <td>3.414678</td>\n      <td>0.227769</td>\n      <td>-1.746082</td>\n      <td>-3.048499</td>\n      <td>0.230612</td>\n      <td>0.337691</td>\n      <td>0.0</td>\n      <td>0.416862</td>\n      <td>-0.090025</td>\n      <td>-0.148572</td>\n      <td>-0.141963</td>\n      <td>-0.057234</td>\n      <td>-0.122505</td>\n      <td>-0.121987</td>\n    </tr>\n    <tr>\n      <th>smh</th>\n      <td>3.064797</td>\n      <td>1.999929</td>\n      <td>-2.474822</td>\n      <td>-0.097874</td>\n      <td>-0.04862</td>\n      <td>-0.048873</td>\n      <td>-0.284392</td>\n      <td>-4.390404</td>\n      <td>-1.746082</td>\n      <td>-3.048499</td>\n      <td>0.230612</td>\n      <td>0.337691</td>\n      <td>0.0</td>\n      <td>0.416862</td>\n      <td>0.063094</td>\n      <td>-0.146468</td>\n      <td>-0.138869</td>\n      <td>-0.058167</td>\n      <td>-0.122505</td>\n      <td>-0.121987</td>\n    </tr>\n    <tr>\n      <th>sol</th>\n      <td>0.199462</td>\n      <td>-0.170470</td>\n      <td>-2.474822</td>\n      <td>-0.097874</td>\n      <td>-0.04862</td>\n      <td>-0.048873</td>\n      <td>1.195236</td>\n      <td>0.227769</td>\n      <td>-1.746082</td>\n      <td>-3.048499</td>\n      <td>0.230612</td>\n      <td>0.337691</td>\n      <td>0.0</td>\n      <td>0.416862</td>\n      <td>-0.087388</td>\n      <td>-0.148572</td>\n      <td>-0.133366</td>\n      <td>-0.055848</td>\n      <td>-0.122505</td>\n      <td>-0.109927</td>\n    </tr>\n    <tr>\n      <th>vol</th>\n      <td>-0.036479</td>\n      <td>-0.170470</td>\n      <td>-2.474822</td>\n      <td>-0.097874</td>\n      <td>-0.04862</td>\n      <td>-0.048873</td>\n      <td>4.524398</td>\n      <td>-4.390404</td>\n      <td>-1.746082</td>\n      <td>-3.048499</td>\n      <td>0.230612</td>\n      <td>0.337691</td>\n      <td>0.0</td>\n      <td>0.416862</td>\n      <td>-0.087684</td>\n      <td>-0.148572</td>\n      <td>-0.144660</td>\n      <td>-0.057435</td>\n      <td>-0.122505</td>\n      <td>-0.121987</td>\n    </tr>\n  </tbody>\n</table>\n<p>724672 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "feature_vals = X_train.values\n",
    "scaler = preprocessing.StandardScaler().fit(feature_vals)\n",
    "feature_vals = scaler.transform(feature_vals)\n",
    "X_train[:] = feature_vals\n",
    "\n",
    "feature_vals = X_dev.values\n",
    "scaler = preprocessing.StandardScaler().fit(feature_vals)\n",
    "feature_vals = scaler.transform(feature_vals)\n",
    "X_dev[:] = feature_vals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear].............................."
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(class_weight=\"balanced\", verbose=1).fit(X_train, y_train.values.ravel())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mjoblib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dump, load\n\u001B[0;32m----> 2\u001B[0m dump(\u001B[43msvm\u001B[49m, os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(DATA_PATH, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../models/svm.joblib\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m      3\u001B[0m test \u001B[38;5;241m=\u001B[39m load(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(DATA_PATH, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../models/svm.joblib\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m      4\u001B[0m test\u001B[38;5;241m.\u001B[39mcoef_\n",
      "\u001B[0;31mNameError\u001B[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(svm, os.path.join(DATA_PATH, \"../models/svm.joblib\"))\n",
    "test = load(os.path.join(DATA_PATH, \"../models/svm.joblib\"))\n",
    "test.coef_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "preds = svm.decision_function(X_dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9983700596728575"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_dev, y_dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "          cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\nnah             2.656120         3.877197      -2.593884            -0.094405   \noh              2.745444         2.535195      -2.593884            -0.094405   \nuh              2.624856         5.219199      -2.593884            -0.094405   \nye ah          -1.138580        -0.148809      -2.593884            -0.094405   \nye-ah          -1.138580        -0.148809      -2.593884            -0.094405   \n...                  ...              ...            ...                  ...   \nupward          0.569510        -0.148809       0.385522            -0.094405   \nupwardly        0.702616        -0.148809       0.385522            -0.094405   \nupwards         0.833669        -0.148809       0.385522            -0.094405   \nus              1.122110        -0.148809      -2.593884            -0.094405   \nyup            -0.101099        -0.148809      -2.593884            -0.094405   \n\n          from_split  norms_seen  spellcheck_rank  in_lexicon    length  \\\nnah        -0.046030   -0.048241        -0.268871   -4.348835 -1.763720   \noh         -0.046030   -0.048241        -0.268871    0.229947 -2.095137   \nuh         -0.046030   -0.048241        -0.268871    0.229947 -2.095137   \nye ah      21.724887   -0.048241         1.360023   -4.348835 -1.100884   \nye-ah      -0.046030   -0.048241         1.767247   -4.348835 -1.100884   \n...              ...         ...              ...         ...       ...   \nupward     -0.046030   -0.048241        -0.268871    0.229947 -0.769467   \nupwardly   -0.046030   -0.048241        -0.268871    0.229947 -0.106631   \nupwards    -0.046030   -0.048241        -0.268871    0.229947 -0.438049   \nus         -0.046030   -0.048241         2.988917    0.229947 -2.095137   \nyup        -0.046030   -0.048241         2.581694    0.229947 -1.763720   \n\n          same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\nnah        -3.155060        -1.057043         0.345895              0.0   \noh         -3.155060        -1.057043         0.345895              0.0   \nuh         -3.155060        -1.057043         0.345895              0.0   \nye ah       0.316951        -1.057043         0.345895              0.0   \nye-ah       0.316951        -1.057043         0.345895              0.0   \n...              ...              ...              ...              ...   \nupward      0.316951        -0.688526         0.345895              0.0   \nupwardly    0.316951        -0.688526         0.345895              0.0   \nupwards     0.316951        -0.688526         0.345895              0.0   \nus         -3.155060        -0.688526         0.345895              0.0   \nyup         0.316951        -0.688526         0.345895              0.0   \n\n          orig_length  \nnah          1.361154  \noh           1.361154  \nuh           1.361154  \nye ah        1.361154  \nye-ah        1.361154  \n...               ...  \nupward      -0.462068  \nupwardly    -0.462068  \nupwards     -0.462068  \nus          -0.462068  \nyup         -0.462068  \n\n[2988229 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>nah</th>\n      <td>2.656120</td>\n      <td>3.877197</td>\n      <td>-2.593884</td>\n      <td>-0.094405</td>\n      <td>-0.046030</td>\n      <td>-0.048241</td>\n      <td>-0.268871</td>\n      <td>-4.348835</td>\n      <td>-1.763720</td>\n      <td>-3.155060</td>\n      <td>-1.057043</td>\n      <td>0.345895</td>\n      <td>0.0</td>\n      <td>1.361154</td>\n    </tr>\n    <tr>\n      <th>oh</th>\n      <td>2.745444</td>\n      <td>2.535195</td>\n      <td>-2.593884</td>\n      <td>-0.094405</td>\n      <td>-0.046030</td>\n      <td>-0.048241</td>\n      <td>-0.268871</td>\n      <td>0.229947</td>\n      <td>-2.095137</td>\n      <td>-3.155060</td>\n      <td>-1.057043</td>\n      <td>0.345895</td>\n      <td>0.0</td>\n      <td>1.361154</td>\n    </tr>\n    <tr>\n      <th>uh</th>\n      <td>2.624856</td>\n      <td>5.219199</td>\n      <td>-2.593884</td>\n      <td>-0.094405</td>\n      <td>-0.046030</td>\n      <td>-0.048241</td>\n      <td>-0.268871</td>\n      <td>0.229947</td>\n      <td>-2.095137</td>\n      <td>-3.155060</td>\n      <td>-1.057043</td>\n      <td>0.345895</td>\n      <td>0.0</td>\n      <td>1.361154</td>\n    </tr>\n    <tr>\n      <th>ye ah</th>\n      <td>-1.138580</td>\n      <td>-0.148809</td>\n      <td>-2.593884</td>\n      <td>-0.094405</td>\n      <td>21.724887</td>\n      <td>-0.048241</td>\n      <td>1.360023</td>\n      <td>-4.348835</td>\n      <td>-1.100884</td>\n      <td>0.316951</td>\n      <td>-1.057043</td>\n      <td>0.345895</td>\n      <td>0.0</td>\n      <td>1.361154</td>\n    </tr>\n    <tr>\n      <th>ye-ah</th>\n      <td>-1.138580</td>\n      <td>-0.148809</td>\n      <td>-2.593884</td>\n      <td>-0.094405</td>\n      <td>-0.046030</td>\n      <td>-0.048241</td>\n      <td>1.767247</td>\n      <td>-4.348835</td>\n      <td>-1.100884</td>\n      <td>0.316951</td>\n      <td>-1.057043</td>\n      <td>0.345895</td>\n      <td>0.0</td>\n      <td>1.361154</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>upward</th>\n      <td>0.569510</td>\n      <td>-0.148809</td>\n      <td>0.385522</td>\n      <td>-0.094405</td>\n      <td>-0.046030</td>\n      <td>-0.048241</td>\n      <td>-0.268871</td>\n      <td>0.229947</td>\n      <td>-0.769467</td>\n      <td>0.316951</td>\n      <td>-0.688526</td>\n      <td>0.345895</td>\n      <td>0.0</td>\n      <td>-0.462068</td>\n    </tr>\n    <tr>\n      <th>upwardly</th>\n      <td>0.702616</td>\n      <td>-0.148809</td>\n      <td>0.385522</td>\n      <td>-0.094405</td>\n      <td>-0.046030</td>\n      <td>-0.048241</td>\n      <td>-0.268871</td>\n      <td>0.229947</td>\n      <td>-0.106631</td>\n      <td>0.316951</td>\n      <td>-0.688526</td>\n      <td>0.345895</td>\n      <td>0.0</td>\n      <td>-0.462068</td>\n    </tr>\n    <tr>\n      <th>upwards</th>\n      <td>0.833669</td>\n      <td>-0.148809</td>\n      <td>0.385522</td>\n      <td>-0.094405</td>\n      <td>-0.046030</td>\n      <td>-0.048241</td>\n      <td>-0.268871</td>\n      <td>0.229947</td>\n      <td>-0.438049</td>\n      <td>0.316951</td>\n      <td>-0.688526</td>\n      <td>0.345895</td>\n      <td>0.0</td>\n      <td>-0.462068</td>\n    </tr>\n    <tr>\n      <th>us</th>\n      <td>1.122110</td>\n      <td>-0.148809</td>\n      <td>-2.593884</td>\n      <td>-0.094405</td>\n      <td>-0.046030</td>\n      <td>-0.048241</td>\n      <td>2.988917</td>\n      <td>0.229947</td>\n      <td>-2.095137</td>\n      <td>-3.155060</td>\n      <td>-0.688526</td>\n      <td>0.345895</td>\n      <td>0.0</td>\n      <td>-0.462068</td>\n    </tr>\n    <tr>\n      <th>yup</th>\n      <td>-0.101099</td>\n      <td>-0.148809</td>\n      <td>-2.593884</td>\n      <td>-0.094405</td>\n      <td>-0.046030</td>\n      <td>-0.048241</td>\n      <td>2.581694</td>\n      <td>0.229947</td>\n      <td>-1.763720</td>\n      <td>0.316951</td>\n      <td>-0.688526</td>\n      <td>0.345895</td>\n      <td>0.0</td>\n      <td>-0.462068</td>\n    </tr>\n  </tbody>\n</table>\n<p>2988229 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "data": {
      "text/plain": "         cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\ncitch          0.756863              1.0            0.0                  0.0   \nco             0.240537              0.0            0.0                  0.0   \nhoe            0.741933              4.0            0.0                  0.0   \nlo             0.361795              0.0            0.0                  0.0   \nnigga          0.742659              3.0            0.0                  0.0   \n...                 ...              ...            ...                  ...   \nyowl's         0.000000              0.0            1.0                  0.0   \nyowled         0.283298              0.0            1.0                  0.0   \nyowling        0.225846              0.0            1.0                  0.0   \nyowls          0.204925              0.0            1.0                  0.0   \nyr             0.448676              0.0            0.0                  0.0   \n\n         from_split  norms_seen  spellcheck_rank  in_lexicon  length  \\\ncitch           0.0         0.0              0.0         0.0       5   \nco              0.0         0.0             14.0         0.0       2   \nhoe             0.0         0.0              0.0         1.0       3   \nlo              0.0         0.0             13.0         1.0       2   \nnigga           0.0         0.0              0.0         1.0       5   \n...             ...         ...              ...         ...     ...   \nyowl's          0.0         0.0              0.0         1.0       6   \nyowled          0.0         0.0              0.0         1.0       6   \nyowling         0.0         0.0              0.0         1.0       7   \nyowls           0.0         0.0              0.0         1.0       5   \nyr              0.0         0.0             12.0         0.0       2   \n\n         same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\ncitch           0.0              1.0              1.0              1.0   \nco              0.0              1.0              1.0              1.0   \nhoe             0.0              1.0              1.0              1.0   \nlo              0.0              1.0              1.0              1.0   \nnigga           0.0              1.0              1.0              1.0   \n...             ...              ...              ...              ...   \nyowl's          1.0              1.0              1.0              1.0   \nyowled          1.0              1.0              1.0              1.0   \nyowling         1.0              1.0              1.0              1.0   \nyowls           1.0              1.0              1.0              1.0   \nyr              0.0              1.0              1.0              1.0   \n\n         orig_length  process  tweet  tok     preds  \ncitch            2.0        0      0    4 -1.731161  \nco               2.0        0      0    4 -2.434154  \nhoe              2.0        0      0    4 -1.538175  \nlo               2.0        0      0    4 -1.583027  \nnigga            2.0        0      0    4 -1.389208  \n...              ...      ...    ...  ...       ...  \nyowl's           2.0        0      0    4 -1.555294  \nyowled           2.0        0      0    4 -1.327322  \nyowling          2.0        0      0    4 -1.390141  \nyowls            2.0        0      0    4 -1.373803  \nyr               2.0        0      0    4 -2.192546  \n\n[112 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>process</th>\n      <th>tweet</th>\n      <th>tok</th>\n      <th>preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>citch</th>\n      <td>0.756863</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-1.731161</td>\n    </tr>\n    <tr>\n      <th>co</th>\n      <td>0.240537</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-2.434154</td>\n    </tr>\n    <tr>\n      <th>hoe</th>\n      <td>0.741933</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-1.538175</td>\n    </tr>\n    <tr>\n      <th>lo</th>\n      <td>0.361795</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-1.583027</td>\n    </tr>\n    <tr>\n      <th>nigga</th>\n      <td>0.742659</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-1.389208</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>yowl's</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-1.555294</td>\n    </tr>\n    <tr>\n      <th>yowled</th>\n      <td>0.283298</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-1.327322</td>\n    </tr>\n    <tr>\n      <th>yowling</th>\n      <td>0.225846</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-1.390141</td>\n    </tr>\n    <tr>\n      <th>yowls</th>\n      <td>0.204925</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-1.373803</td>\n    </tr>\n    <tr>\n      <th>yr</th>\n      <td>0.448676</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>-2.192546</td>\n    </tr>\n  </tbody>\n</table>\n<p>112 rows × 18 columns</p>\n</div>"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev[\"preds\"] = preds\n",
    "dev.loc[(dev.process == 0) & (dev.tweet == 0) & (dev.tok == 4)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "['brother',\n 'get',\n 'out',\n 'yo',\n 'feelings',\n 'lol',\n 'manan',\n 'dund',\n 'xaragdax',\n 'ter',\n 'uuliin',\n 'oroid',\n 'minii',\n 'aav',\n 'xezee',\n 'neg',\n 'cagt',\n 'zogsoj',\n 'baisan',\n 'photo',\n 'by',\n 'why',\n 'dese',\n 'niggers',\n 'think',\n 'dey',\n 'doin',\n 'summn',\n \"it's\",\n 'about',\n 'more',\n 'than',\n 'number',\n 'brother',\n 'and',\n \"i'm\",\n 'not',\n 'talkn',\n 'about',\n 'statistics',\n \"i'm\",\n 'talkn',\n 'about',\n 'skill',\n 'level',\n 'yes',\n 'omg',\n 'i',\n \"don't\",\n 'want',\n 'him',\n 'feeling',\n 'unappreciated',\n 'or',\n 'stuff',\n 'like',\n 'that',\n 'lmao',\n 'the',\n 'whole',\n 'time',\n 'actually',\n 'we',\n 'need',\n 'to',\n 'start',\n 'our',\n 'own',\n 'team',\n \"y'all\",\n 'were',\n 'wilding',\n 'last',\n 'nigjt',\n 'yoh',\n 'niya',\n 'ja',\n 'saying',\n 'kau',\n 'aku',\n 'with',\n 'couple',\n 'is',\n 'actually',\n 'sweet',\n 'k',\n 'michelle',\n 'met',\n 'yo',\n 'match',\n 'that',\n 'fonk',\n 'rana',\n 'samaha',\n 'ignore',\n 'all',\n 'the',\n 'criticism',\n 'a',\n 'spotlight',\n 'can',\n 'never',\n 'see',\n 'the',\n 'shadows',\n 'anyways',\n \"you're\",\n 'flawless',\n 'boko',\n 'haram',\n 'shettima',\n 'warns',\n 'nigerian',\n 'leaders',\n 'over',\n 'politicization',\n 'of',\n 'chibok',\n 'abduction',\n 'and',\n 'in',\n 'that',\n 'moment',\n 'karma',\n 'realised',\n 'she',\n 'was',\n 'hella',\n 'gay',\n 'for',\n 'her',\n 'bestie',\n 'not',\n 'you',\n 'because',\n 'you',\n 'chillen',\n 'wit',\n 'me',\n 'kardashia',\n 'kardashian',\n 'died',\n 'because',\n 'her',\n 'ass',\n 'was',\n 'too',\n 'big',\n 'hahah',\n 'niggra',\n 'summation',\n 'classified',\n 'directory',\n 'high',\n 'grille',\n 'for',\n 'the',\n 'online',\n 'game',\n 'atd',\n 'lexx',\n 'little',\n 'cute',\n 'ass',\n 'woke',\n 'up',\n 'mad',\n 'as',\n 'hell',\n 'lol',\n 'green',\n 'day',\n 'paramore',\n 'yellowcard',\n 'fall',\n 'out',\n 'boy',\n 'is',\n 'that',\n 'minho',\n 'beside',\n 'taemin',\n 'omo',\n 'looks',\n 'like',\n 'him',\n '140529',\n 'smtown',\n 'artists',\n 'with',\n 'exo',\n 'photoset',\n 'flintandpyrite',\n 'ume',\n 'by',\n 'andrea',\n 'rangel',\n 'knits',\n 'for',\n 'spring',\n 'because',\n \"that's\",\n 'going to',\n 'happen',\n 'lol',\n 'need',\n 'to',\n 'revisit',\n 'their',\n 'thameslink',\n 'bid',\n 'the',\n 'moorgate',\n 'route',\n 'closed',\n '4',\n 'years',\n 'ago',\n 'icons',\n 'da',\n 'demi',\n 'sem',\n 'psd',\n 'no',\n 'the',\n 'x',\n 'factor',\n 'x8',\n 'you',\n 'dun',\n \"i'm\",\n 'da',\n 'king',\n 'of',\n 'sweg',\n 'haha',\n \"that's\",\n 'funny',\n 'but',\n 'not',\n 'every',\n 'girl',\n 'is',\n 'darlin',\n 'imran',\n 'khan',\n 'saying',\n 'really',\n 'true',\n 'about',\n 'pmln',\n 'and',\n \"you'll\",\n 'always',\n 'be',\n 'my',\n '5',\n 'heros',\n 'who',\n 'can',\n 'always',\n 'make',\n 'me',\n 'smyle',\n 'even',\n 'when',\n 'i',\n 'm',\n 'in',\n 'the',\n 'sadest',\n 'mood',\n 'ever',\n 'xxc',\n 'lol',\n 'what',\n 'he',\n 'trippin',\n 'on',\n 'xabi',\n 'alonso',\n 'just',\n 'achieved',\n 'stratospheric',\n 'heights',\n 'of',\n 'coolness',\n 'lmaoo',\n 'my',\n 'fault',\n 'yo',\n 'ima',\n 'let',\n 'you',\n 'get',\n 'your',\n 'shine',\n 'james',\n 'and',\n 'i',\n 'say',\n 'hi',\n 'with',\n 'a',\n 'dog',\n 'tenerezza',\n 'omg',\n 'hawt',\n 'like',\n 'omg',\n 'can',\n 'my',\n 'husband',\n 'please',\n 'look',\n 'like',\n 'you',\n 'or',\n 'can',\n 'i',\n 'have',\n 'your',\n 'babies',\n 'i',\n 'miss',\n 'going',\n 'to',\n 'mansion',\n 'elan',\n 'ery',\n 'wkeend',\n \"i'm\",\n 'finna',\n 'start',\n 'back',\n 'going',\n 'doe',\n 'facts',\n 'bro',\n 'this',\n 'babyface',\n \"ain't\",\n 'helping',\n 'nothing',\n 'lmao',\n 'can',\n 'i',\n 'have',\n 'him',\n 'yet',\n 'orrr',\n 'noo',\n 'ughh',\n '140524',\n 'hyoyeon',\n 'yuri',\n '2nd',\n 'day',\n 'kobe',\n 'by',\n 'rebecca',\n 'crowdfunding',\n 'roundup',\n 'a',\n 'late',\n 'spring',\n 'flowering',\n 'of',\n 'projects',\n 'every',\n 'week',\n 'tuaw',\n 'provides',\n 'readers',\n 'with',\n 'an',\n 'update',\n 'o',\n 'mayweather',\n 'needs',\n 'to',\n 'fight',\n 'paquiao',\n 'that',\n 'would',\n 'be',\n 'ammmazing',\n \"i'm\",\n 'actully',\n 'excited',\n 'to',\n 'see',\n 'what',\n 'it',\n 'will',\n 'look',\n 'like',\n 'so',\n 'its',\n 'happening',\n 'when',\n 'the',\n 'lawn',\n 'area',\n 'get',\n 'done',\n 'lol',\n 'who',\n 'bouta',\n 'come',\n 'way',\n 'out',\n 'there',\n 'come',\n 'get',\n 'me',\n 'bring',\n 'me',\n 'bck',\n \"we'll\",\n 'come',\n 'lol',\n 'i',\n 'forgot',\n 'you',\n 'moved',\n 'canal',\n 'then',\n 'lol',\n 'apple',\n 'forgets',\n 'to',\n 'renew',\n 'ssl',\n 'certificate',\n 'breaking',\n 'os',\n 'x',\n 'software',\n 'update',\n 'ik',\n 'id',\n 'rather',\n 'someone',\n 'unfollow',\n 'me',\n 'than',\n 'mute',\n 'me',\n 'like',\n 'what',\n 'ohhh',\n 'my',\n 'poor',\n 'zac',\n 'take',\n 'good',\n 'care',\n 'of',\n 'urself',\n 'kimberley',\n 'walsh',\n 'confirms',\n 'cheryl',\n \"cole's\",\n \"britain's\",\n 'got',\n 'talent',\n 'appearance',\n 'contactmusic',\n 'comkimberley',\n 'walsh',\n 'confir',\n 'exo',\n 'is',\n 'practising',\n 'for',\n 'concert',\n 'lol',\n 'you',\n 'still',\n 'in',\n 'school',\n 'shutup',\n 'he',\n 'wants',\n 'to',\n 'get',\n 'bigger',\n 'than',\n 'parth',\n 'lmfao',\n 'chanyeol',\n 'is',\n 'so',\n 'caring',\n 'omg',\n 'be',\n 'mine',\n 'please',\n 'nothin',\n 'just',\n 'chillin',\n 'imy',\n 'you',\n \"don't\",\n 'fuck',\n 'with',\n 'a',\n 'thug',\n 'nomore',\n 'lol',\n 'udah',\n 'lama',\n 'nda',\n 'how',\n 'about',\n 'it',\n 'how',\n 'about',\n 'that',\n 'lol',\n 'ik',\n 'i',\n 'just',\n 'took',\n 'them',\n 'real',\n 'quick',\n 'i',\n 'wasnt',\n 'thinkin',\n 'the',\n 'order',\n '1',\n 'daily',\n 'follower',\n '0',\n 'unfollowers',\n 'justunfollow',\n \"doesn't\",\n 'miss',\n 'a',\n 'trick',\n \"i'm\",\n 'going to',\n 'do',\n 'it',\n 'after',\n 'graduation',\n 'lol',\n 'second',\n 'time',\n 'this',\n 'shit',\n 'crashed',\n 'on',\n 'datpiff',\n 'so',\n 'we',\n 'on',\n 'soundcloud',\n 'with',\n 'it',\n 'genji',\n 'sports',\n 'pop',\n 'up',\n 'family',\n 'beach',\n 'tent',\n 'and',\n 'beach',\n 'sunshelter',\n 'genji',\n 'sports',\n 'pop',\n 'up',\n 'fami',\n 'titan',\n 'baseball',\n 'beats',\n 'brv',\n 'to',\n 'advance',\n 'to',\n 'county',\n 'championship',\n 'tri',\n 'tomorrow',\n '4',\n 'pm',\n 'jumpseat',\n 'radio',\n '018',\n 'combat',\n 'ready',\n 'firefighting',\n 'with',\n 'tony',\n 'kelleher',\n 'repost',\n 'i',\n 'added',\n 'a',\n 'video',\n 'to',\n 'a',\n 'playlist',\n 'plg',\n 'sensual',\n 'toribash',\n 'ep',\n '3',\n \"let's\",\n 'tango',\n 'wildfires',\n 'turkey',\n 'feather',\n 'fletching',\n 'for',\n 'archery',\n 'arrows',\n 'diy',\n 'pheasant',\n 'feathers',\n 'for',\n 'arro',\n 'where',\n 'the',\n 'mj',\n 'though',\n 'lol',\n '492',\n 'luke',\n 'hemmings',\n 'from',\n '5sos',\n 'i',\n 'love',\n 'you',\n 'so',\n 'much',\n 'please',\n 'follow',\n 'me',\n 'you',\n 'are',\n 'everything',\n 'to',\n 'me',\n 'please',\n 'dude',\n 'you',\n 'never',\n 'gave',\n 'me',\n 'the',\n 'kik',\n 'or',\n 'snapchat',\n \"you'll\",\n 'sea',\n 'lmfao',\n 'oookay',\n 'bean',\n 'eating',\n 'headass',\n 'morning',\n 'exercise',\n 'paakyat',\n 'ng',\n 'thunderbird',\n 'i',\n 'love',\n 'you',\n 'phil',\n 'of',\n 'the',\n 'future',\n 'i',\n 'love',\n 'everything',\n 'abt',\n 'you',\n 'nao',\n 'superei',\n 'ainda',\n 'this',\n 'is',\n 'for',\n 'niall',\n 'e',\n 'vcs',\n 'wara',\n 'man',\n 'talaga',\n 'forever',\n 'niyata',\n 'ano',\n 'una',\n 'mo',\n 'imortal',\n 'ka',\n 'hahahahahahhahaha',\n 'hot',\n 'music',\n 'mariah',\n 'carey',\n 'meteorite',\n 'q',\n 'meteorite',\n 'version',\n 'mariah',\n 'carey',\n 'has',\n 'ohh',\n 'i',\n 'feel',\n 'you',\n 'haha',\n 'so',\n 'is',\n 'writin',\n 'a',\n 'book',\n 'about',\n 'jay',\n 'z',\n 'and',\n 'beyonce',\n 'tellin',\n 'someone',\n \"else's\",\n 'secrets',\n 'for',\n 'money',\n 'shows',\n 'how',\n 'low',\n 'some',\n 'people',\n 'will',\n 'stoop',\n 'fast',\n 'forward',\n 'to',\n 'june',\n '9',\n 'please',\n 'para',\n 'makapag',\n 'ipon',\n 'na',\n 'hahahahahah',\n 'lol',\n 'thank',\n 'you',\n 'liam',\n 'for',\n 'asking',\n 'louis',\n 'what',\n 'flavour',\n 'harry',\n 'is',\n \"i'm\",\n 'so',\n 'jskcosnxoancoamxis',\n 'ahhhhh',\n 'salt',\n 'and',\n 'vinegar',\n \"don't\",\n 'take',\n 'it',\n 'personal',\n 'kid',\n 'caroline',\n 'wozniacki',\n 'breaks',\n 'silence',\n 'on',\n 'rory',\n 'mcilroy',\n 'breakup',\n '140525',\n 'boakwon',\n 'ig',\n 'update',\n 'with',\n 'exo',\n 'and',\n 'suju',\n 'siwon',\n 'donghae',\n 'more',\n 'and',\n 'forehead',\n 'ft',\n 'hyuk',\n 'thanks',\n 'for',\n 'that',\n 'spiderman',\n 'carnage',\n 'mask',\n '300rb',\n 'lom',\n 'ama',\n 'ongkir',\n 'ready',\n 'stock',\n 'runnin',\n 'with',\n 'who',\n 'do',\n 'you',\n 'think',\n 'is',\n 'faster',\n 'nicki',\n 'minaj',\n 'slick',\n 'went',\n 'from',\n 'brownskin',\n 'to',\n 'lightskin',\n 'over',\n 'the',\n 'years',\n 'if',\n 'you',\n \"don't\",\n 'fuck',\n 'wit',\n 'dunny',\n 'gage',\n 'then',\n 'fuck',\n 'ya',\n 'life',\n 'last',\n 'day',\n 'of',\n 'school',\n 'gonna',\n 'have',\n 'people',\n 'like',\n 'the',\n 'bad',\n 'pastor',\n 'impostors',\n 'so',\n 'loves',\n 'a',\n 'lottle',\n 'to',\n 'jesus',\n 'the',\n 'people',\n 'can',\n 'intercesion',\n 'for',\n 'he',\n 'for',\n 'the',\n 'soul',\n 'peole',\n 'wilshire',\n 'itq',\n 'hehe',\n 'stay',\n 'strong',\n '1',\n 'k',\n 'swim',\n 'sauna',\n 'post',\n 'work',\n 'now',\n 'beer',\n 'work',\n 'tomorrow',\n 'terserah',\n 'suho',\n 'gave',\n 'a',\n 'teddy',\n 'bear',\n 'and',\n 'took',\n 'a',\n 'selca',\n 'with',\n 'a',\n 'fan',\n 'tazz',\n 'needa',\n 'quit',\n 'it',\n 'wit',\n 'that',\n 'last',\n 'quote',\n 'lol',\n 'she',\n \"don't\",\n 'live',\n 'that',\n 'life',\n 'why',\n 'the',\n 'fuck',\n 'did',\n 'i',\n 'think',\n 'i',\n 'was',\n 'scheduled',\n 'today',\n 'am',\n 'i',\n 'on',\n 'crack',\n 'lmao',\n 'wut',\n 'my',\n 'top',\n '3',\n 'artists',\n 'girls',\n 'aloud',\n '15',\n 'christina',\n 'aguilera',\n '13',\n 'kylie',\n 'minogue',\n '12',\n 'how',\n 'he',\n 'top',\n '5',\n 'scorer',\n 'and',\n 'the',\n 'offense',\n \"ain't\",\n 'around',\n 'atleast',\n 'him',\n 'lol',\n 'that',\n \"don't\",\n 'make',\n 'sense',\n 'that',\n 'mean',\n 'he',\n 'jackin',\n 'then',\n 'lol',\n 'kompany',\n 'going',\n 'up',\n 'to',\n 'yaya',\n 'toure',\n 'after',\n 'he',\n 'found',\n 'out',\n 'he',\n 'wanted',\n 'to',\n 'leave',\n 'first',\n 'class',\n 'thing',\n 'see',\n 'wizkid',\n 'and',\n 'banky',\n 'w',\n 'having',\n 'fun',\n 'on',\n 'via',\n 'the',\n 'old',\n 'bargin',\n 'giant',\n 'would',\n 'make',\n 'a',\n 'good',\n 'entertainment',\n ...]"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get top prediction for each raw token\n",
    "predictions = dev.sort_values(\"preds\", ascending=False).drop_duplicates([\"process\", \"tweet\", \"tok\"])\n",
    "pred_tokens = predictions.sort_values([\"process\", \"tweet\", \"tok\"]).index.tolist()\n",
    "pred_tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from lexnorm.data.normEval import loadNormData\n",
    "\n",
    "raw, norm = loadNormData(os.path.join(DATA_PATH, \"raw/dev.norm\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[199], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlexnorm\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerate_extract\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfiltering\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_eligible\n\u001B[0;32m----> 3\u001B[0m pred_tokens_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(\u001B[43mpred_tokens\u001B[49m)\n\u001B[1;32m      5\u001B[0m pred_tweets \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m tweet \u001B[38;5;129;01min\u001B[39;00m raw:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pred_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "from lexnorm.generate_extract.filtering import is_eligible\n",
    "\n",
    "pred_tokens_iter = iter(pred_tokens)\n",
    "\n",
    "pred_tweets = []\n",
    "\n",
    "for tweet in raw:\n",
    "    pred_tweet = []\n",
    "    for tok in tweet:\n",
    "        if is_eligible(tok):\n",
    "            pred_tweet.append(next(pred_tokens_iter))\n",
    "        else:\n",
    "            pred_tweet.append(tok)\n",
    "    pred_tweets.append(pred_tweet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline acc.(LAI): 93.10\n",
      "Accuracy:           96.28\n",
      "ERR:                46.13\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.9309630275929763, 0.9628094666812084, 0.4612954186413895)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexnorm.data.normEval import evaluate\n",
    "\n",
    "evaluate(raw, norm, pred_tweets)\n",
    "# pretty bad. Some reasons: not good enough feature extraction, using a linear svm when data might not be linearly seperable in our feature space (may need different kernel), set non-calculated/absent values to zero which can be picked up by a random forest but NOT by most models! May need to give highest possible value instead."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), slice(None, 2, None))",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3801\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3802\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3803\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:144\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: '(slice(None, None, None), slice(None, 2, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[157], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minspection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DecisionBoundaryDisplay\n\u001B[0;32m----> 2\u001B[0m DecisionBoundaryDisplay\u001B[38;5;241m.\u001B[39mfrom_estimator(svm, \u001B[43mX_dev\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m)\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3805\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3806\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3807\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3809\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3809\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3804\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3805\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3806\u001B[0m         \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3807\u001B[0m         \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m-> 3809\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_indexing_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3810\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m   3812\u001B[0m \u001B[38;5;66;03m# GH#42269\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:5925\u001B[0m, in \u001B[0;36mIndex._check_indexing_error\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   5921\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_check_indexing_error\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m   5922\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(key):\n\u001B[1;32m   5923\u001B[0m         \u001B[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001B[39;00m\n\u001B[1;32m   5924\u001B[0m         \u001B[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001B[39;00m\n\u001B[0;32m-> 5925\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n",
      "\u001B[0;31mInvalidIndexError\u001B[0m: (slice(None, None, None), slice(None, 2, None))"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "DecisionBoundaryDisplay.from_estimator(svm, X_dev[:, :2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "import os\n",
    "from lexnorm.definitions import DATA_PATH\n",
    "rd_clf = load(os.path.join(DATA_PATH, \"../models/rf.joblib\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "data": {
      "text/plain": "[DecisionTreeClassifier(max_features='sqrt', random_state=1608637542),\n DecisionTreeClassifier(max_features='sqrt', random_state=1273642419),\n DecisionTreeClassifier(max_features='sqrt', random_state=1935803228),\n DecisionTreeClassifier(max_features='sqrt', random_state=787846414),\n DecisionTreeClassifier(max_features='sqrt', random_state=996406378),\n DecisionTreeClassifier(max_features='sqrt', random_state=1201263687),\n DecisionTreeClassifier(max_features='sqrt', random_state=423734972),\n DecisionTreeClassifier(max_features='sqrt', random_state=415968276),\n DecisionTreeClassifier(max_features='sqrt', random_state=670094950),\n DecisionTreeClassifier(max_features='sqrt', random_state=1914837113),\n DecisionTreeClassifier(max_features='sqrt', random_state=669991378),\n DecisionTreeClassifier(max_features='sqrt', random_state=429389014),\n DecisionTreeClassifier(max_features='sqrt', random_state=249467210),\n DecisionTreeClassifier(max_features='sqrt', random_state=1972458954),\n DecisionTreeClassifier(max_features='sqrt', random_state=1572714583),\n DecisionTreeClassifier(max_features='sqrt', random_state=1433267572),\n DecisionTreeClassifier(max_features='sqrt', random_state=434285667),\n DecisionTreeClassifier(max_features='sqrt', random_state=613608295),\n DecisionTreeClassifier(max_features='sqrt', random_state=893664919),\n DecisionTreeClassifier(max_features='sqrt', random_state=648061058),\n DecisionTreeClassifier(max_features='sqrt', random_state=88409749),\n DecisionTreeClassifier(max_features='sqrt', random_state=242285876),\n DecisionTreeClassifier(max_features='sqrt', random_state=2018247425),\n DecisionTreeClassifier(max_features='sqrt', random_state=953477463),\n DecisionTreeClassifier(max_features='sqrt', random_state=1427830251),\n DecisionTreeClassifier(max_features='sqrt', random_state=1883569565),\n DecisionTreeClassifier(max_features='sqrt', random_state=911989541),\n DecisionTreeClassifier(max_features='sqrt', random_state=3344769),\n DecisionTreeClassifier(max_features='sqrt', random_state=780932287),\n DecisionTreeClassifier(max_features='sqrt', random_state=2114032571),\n DecisionTreeClassifier(max_features='sqrt', random_state=787716372),\n DecisionTreeClassifier(max_features='sqrt', random_state=504579232),\n DecisionTreeClassifier(max_features='sqrt', random_state=1306710475),\n DecisionTreeClassifier(max_features='sqrt', random_state=479546681),\n DecisionTreeClassifier(max_features='sqrt', random_state=106328085),\n DecisionTreeClassifier(max_features='sqrt', random_state=30349564),\n DecisionTreeClassifier(max_features='sqrt', random_state=1855189739),\n DecisionTreeClassifier(max_features='sqrt', random_state=99052376),\n DecisionTreeClassifier(max_features='sqrt', random_state=1250819632),\n DecisionTreeClassifier(max_features='sqrt', random_state=106406362),\n DecisionTreeClassifier(max_features='sqrt', random_state=480404538),\n DecisionTreeClassifier(max_features='sqrt', random_state=1717389822),\n DecisionTreeClassifier(max_features='sqrt', random_state=599121577),\n DecisionTreeClassifier(max_features='sqrt', random_state=200427519),\n DecisionTreeClassifier(max_features='sqrt', random_state=1254751707),\n DecisionTreeClassifier(max_features='sqrt', random_state=2034764475),\n DecisionTreeClassifier(max_features='sqrt', random_state=1573512143),\n DecisionTreeClassifier(max_features='sqrt', random_state=999745294),\n DecisionTreeClassifier(max_features='sqrt', random_state=1958805693),\n DecisionTreeClassifier(max_features='sqrt', random_state=389151677),\n DecisionTreeClassifier(max_features='sqrt', random_state=1224821422),\n DecisionTreeClassifier(max_features='sqrt', random_state=508464061),\n DecisionTreeClassifier(max_features='sqrt', random_state=857592370),\n DecisionTreeClassifier(max_features='sqrt', random_state=1642661739),\n DecisionTreeClassifier(max_features='sqrt', random_state=61136438),\n DecisionTreeClassifier(max_features='sqrt', random_state=2075460851),\n DecisionTreeClassifier(max_features='sqrt', random_state=396917567),\n DecisionTreeClassifier(max_features='sqrt', random_state=2004731384),\n DecisionTreeClassifier(max_features='sqrt', random_state=199502978),\n DecisionTreeClassifier(max_features='sqrt', random_state=1545932260),\n DecisionTreeClassifier(max_features='sqrt', random_state=461901618),\n DecisionTreeClassifier(max_features='sqrt', random_state=774414982),\n DecisionTreeClassifier(max_features='sqrt', random_state=732395540),\n DecisionTreeClassifier(max_features='sqrt', random_state=1934879560),\n DecisionTreeClassifier(max_features='sqrt', random_state=279394470),\n DecisionTreeClassifier(max_features='sqrt', random_state=56972561),\n DecisionTreeClassifier(max_features='sqrt', random_state=1927948675),\n DecisionTreeClassifier(max_features='sqrt', random_state=1899242072),\n DecisionTreeClassifier(max_features='sqrt', random_state=1999874363),\n DecisionTreeClassifier(max_features='sqrt', random_state=271820813),\n DecisionTreeClassifier(max_features='sqrt', random_state=1324556529),\n DecisionTreeClassifier(max_features='sqrt', random_state=1655351289),\n DecisionTreeClassifier(max_features='sqrt', random_state=1308306184),\n DecisionTreeClassifier(max_features='sqrt', random_state=68574553),\n DecisionTreeClassifier(max_features='sqrt', random_state=419498548),\n DecisionTreeClassifier(max_features='sqrt', random_state=991681409),\n DecisionTreeClassifier(max_features='sqrt', random_state=791274835),\n DecisionTreeClassifier(max_features='sqrt', random_state=1035196507),\n DecisionTreeClassifier(max_features='sqrt', random_state=1890440558),\n DecisionTreeClassifier(max_features='sqrt', random_state=787110843),\n DecisionTreeClassifier(max_features='sqrt', random_state=524150214),\n DecisionTreeClassifier(max_features='sqrt', random_state=472432043),\n DecisionTreeClassifier(max_features='sqrt', random_state=2126768636),\n DecisionTreeClassifier(max_features='sqrt', random_state=1431061255),\n DecisionTreeClassifier(max_features='sqrt', random_state=147697582),\n DecisionTreeClassifier(max_features='sqrt', random_state=744595490),\n DecisionTreeClassifier(max_features='sqrt', random_state=1758017741),\n DecisionTreeClassifier(max_features='sqrt', random_state=1679592528),\n DecisionTreeClassifier(max_features='sqrt', random_state=1111451555),\n DecisionTreeClassifier(max_features='sqrt', random_state=782698033),\n DecisionTreeClassifier(max_features='sqrt', random_state=698027879),\n DecisionTreeClassifier(max_features='sqrt', random_state=1096768899),\n DecisionTreeClassifier(max_features='sqrt', random_state=1338788865),\n DecisionTreeClassifier(max_features='sqrt', random_state=1826030589),\n DecisionTreeClassifier(max_features='sqrt', random_state=86191493),\n DecisionTreeClassifier(max_features='sqrt', random_state=893102645),\n DecisionTreeClassifier(max_features='sqrt', random_state=200619113),\n DecisionTreeClassifier(max_features='sqrt', random_state=290770691),\n DecisionTreeClassifier(max_features='sqrt', random_state=793943861),\n DecisionTreeClassifier(max_features='sqrt', random_state=134489564)]"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_clf.estimators_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9995261407341941"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_clf.oob_score_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[200], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mrd_clf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecision_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_dev\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:311\u001B[0m, in \u001B[0;36mBaseForest.decision_path\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    308\u001B[0m n_nodes\u001B[38;5;241m.\u001B[39mextend([i\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m indicators])\n\u001B[1;32m    309\u001B[0m n_nodes_ptr \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(n_nodes)\u001B[38;5;241m.\u001B[39mcumsum()\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msparse_hstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindicators\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtocsr(), n_nodes_ptr\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/scipy/sparse/_construct.py:535\u001B[0m, in \u001B[0;36mhstack\u001B[0;34m(blocks, format, dtype)\u001B[0m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhstack\u001B[39m(blocks, \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    506\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    507\u001B[0m \u001B[38;5;124;03m    Stack sparse matrices horizontally (column wise)\u001B[39;00m\n\u001B[1;32m    508\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    533\u001B[0m \n\u001B[1;32m    534\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 535\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbmat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mblocks\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/scipy/sparse/_construct.py:627\u001B[0m, in \u001B[0;36mbmat\u001B[0;34m(blocks, format, dtype)\u001B[0m\n\u001B[1;32m    623\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mformat\u001B[39m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(b, csr_matrix)\n\u001B[1;32m    624\u001B[0m                                     \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m blocks\u001B[38;5;241m.\u001B[39mflat)):\n\u001B[1;32m    625\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m N \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    626\u001B[0m         \u001B[38;5;66;03m# stack along columns (axis 1):\u001B[39;00m\n\u001B[0;32m--> 627\u001B[0m         blocks \u001B[38;5;241m=\u001B[39m [[_stack_along_minor_axis(blocks[b, :], \u001B[38;5;241m1\u001B[39m)]\n\u001B[1;32m    628\u001B[0m                   \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(M)]   \u001B[38;5;66;03m# must have shape: (M, 1)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m         blocks \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(blocks, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    631\u001B[0m     \u001B[38;5;66;03m# stack along rows (axis 0):\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/scipy/sparse/_construct.py:627\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    623\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mformat\u001B[39m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(b, csr_matrix)\n\u001B[1;32m    624\u001B[0m                                     \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m blocks\u001B[38;5;241m.\u001B[39mflat)):\n\u001B[1;32m    625\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m N \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    626\u001B[0m         \u001B[38;5;66;03m# stack along columns (axis 1):\u001B[39;00m\n\u001B[0;32m--> 627\u001B[0m         blocks \u001B[38;5;241m=\u001B[39m [[\u001B[43m_stack_along_minor_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblocks\u001B[49m\u001B[43m[\u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m]\n\u001B[1;32m    628\u001B[0m                   \u001B[38;5;28;01mfor\u001B[39;00m b \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(M)]   \u001B[38;5;66;03m# must have shape: (M, 1)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m         blocks \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(blocks, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    631\u001B[0m     \u001B[38;5;66;03m# stack along rows (axis 0):\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/scipy/sparse/_construct.py:484\u001B[0m, in \u001B[0;36m_stack_along_minor_axis\u001B[0;34m(blocks, axis)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data_cat\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    483\u001B[0m     indptr_cat \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate(indptr_list)\u001B[38;5;241m.\u001B[39mastype(idx_dtype)\n\u001B[0;32m--> 484\u001B[0m     indices_cat \u001B[38;5;241m=\u001B[39m (\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mblocks\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m                    \u001B[38;5;241m.\u001B[39mastype(idx_dtype))\n\u001B[1;32m    486\u001B[0m     indptr \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty(constant_dim \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39midx_dtype)\n\u001B[1;32m    487\u001B[0m     indices \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty_like(indices_cat)\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mconcatenate\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "rd_clf.decision_path(X_dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['cosine_to_orig', 'embeddings_rank', 'from_clipping',\n       'from_original_token', 'from_split', 'norms_seen',\n       'spellcheck_rank', 'in_lexicon', 'length', 'same_order',\n       'orig_norms_seen', 'orig_in_lexicon', 'orig_same_order',\n       'orig_length'], dtype=object)"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_clf.feature_names_in_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2.52070851e-01, 4.31976125e-03, 7.92054467e-03, 1.64534043e-01,\n       1.61258200e-04, 4.01924066e-01, 3.03852361e-03, 7.35963146e-03,\n       6.02726879e-02, 9.02983575e-03, 3.24685801e-02, 7.44901879e-03,\n       0.00000000e+00, 4.94511981e-02])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_clf.feature_importances_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "preds = rd_clf.predict_proba(X_dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['brother',\n 'get',\n 'out',\n 'you',\n 'feelings',\n 'lol',\n 'manan',\n 'dund',\n 'paradox',\n 'ter',\n 'insulin',\n 'oroid',\n 'minii',\n 'aav',\n 'xezee',\n 'neg',\n 'cagt',\n 'couscous',\n 'baisan',\n 'photo',\n 'by',\n 'why',\n 'dese',\n 'niggers',\n 'think',\n 'dey',\n 'doing',\n 'summn',\n \"it's\",\n 'about',\n 'more',\n 'than',\n 'number',\n 'brother',\n 'and',\n \"i'm\",\n 'not',\n 'talking',\n 'about',\n 'statistics',\n \"i'm\",\n 'talking',\n 'about',\n 'skill',\n 'level',\n 'yes',\n 'omg',\n 'i',\n \"don't\",\n 'want',\n 'him',\n 'feeling',\n 'unappreciated',\n 'or',\n 'stuff',\n 'like',\n 'that',\n 'lmao',\n 'the',\n 'whole',\n 'time',\n 'actually',\n 'we',\n 'need',\n 'to',\n 'start',\n 'our',\n 'own',\n 'team',\n \"y'all\",\n 'were',\n 'wilding',\n 'last',\n 'nigjt',\n 'yoh',\n 'niya',\n 'ja',\n 'saying',\n 'kau',\n 'aku',\n 'with',\n 'couple',\n 'is',\n 'actually',\n 'sweet',\n 'k',\n 'michelle',\n 'met',\n 'you',\n 'match',\n 'that',\n 'fonk',\n 'rana',\n 'samaha',\n 'ignore',\n 'all',\n 'the',\n 'criticism',\n 'a',\n 'spotlight',\n 'can',\n 'never',\n 'see',\n 'the',\n 'shadows',\n 'anyways',\n \"you're\",\n 'flawless',\n 'boko',\n 'haram',\n 'estimate',\n 'warns',\n 'nigerian',\n 'leaders',\n 'over',\n 'politicization',\n 'of',\n 'chibok',\n 'abduction',\n 'and',\n 'in',\n 'that',\n 'moment',\n 'karma',\n 'realised',\n 'she',\n 'was',\n 'hella',\n 'gay',\n 'for',\n 'her',\n 'bestie',\n 'not',\n 'you',\n 'because',\n 'you',\n 'chillen',\n 'with',\n 'me',\n 'kardashia',\n 'kardashian',\n 'died',\n 'because',\n 'her',\n 'ass',\n 'was',\n 'too',\n 'big',\n 'hahah',\n 'niggra',\n 'summation',\n 'classified',\n 'directory',\n 'high',\n 'grille',\n 'for',\n 'the',\n 'online',\n 'game',\n 'atd',\n 'lexx',\n 'little',\n 'cute',\n 'ass',\n 'woke',\n 'up',\n 'mad',\n 'as',\n 'hell',\n 'lol',\n 'green',\n 'day',\n 'paramore',\n 'yellowcard',\n 'fall',\n 'out',\n 'boy',\n 'is',\n 'that',\n 'minho',\n 'beside',\n 'taemin',\n 'omo',\n 'looks',\n 'like',\n 'him',\n '140529',\n 'smtown',\n 'artists',\n 'with',\n 'exo',\n 'photoset',\n 'flintandpyrite',\n 'ume',\n 'by',\n 'andrea',\n 'rangel',\n 'knits',\n 'for',\n 'spring',\n 'because',\n \"that's\",\n 'going to',\n 'happen',\n 'lol',\n 'need',\n 'to',\n 'revisit',\n 'their',\n 'thameslink',\n 'bid',\n 'the',\n 'moorgate',\n 'route',\n 'closed',\n '4',\n 'years',\n 'ago',\n 'icons',\n 'the',\n 'demi',\n 'sem',\n 'psd',\n 'no',\n 'the',\n 'x',\n 'factoring',\n 'x8',\n 'you',\n \"don't\",\n \"i'm\",\n 'the',\n 'king',\n 'of',\n 'sweg',\n 'haha',\n \"that's\",\n 'funny',\n 'but',\n 'not',\n 'every',\n 'girl',\n 'is',\n 'darlin',\n 'imran',\n 'khan',\n 'saying',\n 'really',\n 'true',\n 'about',\n 'pmln',\n 'and',\n \"you'll\",\n 'always',\n 'be',\n 'my',\n '5',\n 'heros',\n 'who',\n 'can',\n 'always',\n 'make',\n 'me',\n 'smyle',\n 'even',\n 'when',\n 'i',\n 'm',\n 'in',\n 'the',\n 'sadest',\n 'mood',\n 'ever',\n 'xxc',\n 'lol',\n 'what',\n 'he',\n 'tripping',\n 'on',\n 'xabi',\n 'alonso',\n 'just',\n 'achieved',\n 'stratospheric',\n 'heights',\n 'of',\n 'coolness',\n 'lmaoo',\n 'my',\n 'fault',\n 'you',\n \"i'm going to\",\n 'let',\n 'you',\n 'get',\n 'your',\n 'shine',\n 'james',\n 'and',\n 'i',\n 'say',\n 'hi',\n 'with',\n 'a',\n 'dog',\n 'containerize',\n 'omg',\n 'hawt',\n 'like',\n 'omg',\n 'can',\n 'my',\n 'husband',\n 'please',\n 'look',\n 'like',\n 'you',\n 'or',\n 'can',\n 'i',\n 'have',\n 'your',\n 'babies',\n 'i',\n 'miss',\n 'going',\n 'to',\n 'mansion',\n 'elan',\n 'ery',\n 'keen',\n \"i'm\",\n 'going to',\n 'start',\n 'back',\n 'going',\n 'doe',\n 'facts',\n 'bro',\n 'this',\n 'babyface',\n \"ain't\",\n 'helping',\n 'nothing',\n 'lmao',\n 'can',\n 'i',\n 'have',\n 'him',\n 'yet',\n 'orrr',\n 'noo',\n 'ughh',\n '140524',\n 'hyoyeon',\n 'yuri',\n '2nd',\n 'day',\n 'kobe',\n 'by',\n 'rebecca',\n 'crowdfunding',\n 'roundup',\n 'a',\n 'late',\n 'spring',\n 'flowering',\n 'of',\n 'projects',\n 'every',\n 'week',\n 'tuaw',\n 'provides',\n 'reviewers',\n 'with',\n 'an',\n 'update',\n 'o',\n 'mayweather',\n 'needs',\n 'to',\n 'fight',\n 'paquiao',\n 'that',\n 'would',\n 'be',\n 'ammmazing',\n \"i'm\",\n 'actully',\n 'excited',\n 'to',\n 'see',\n 'what',\n 'it',\n 'will',\n 'look',\n 'like',\n 'so',\n 'its',\n 'happening',\n 'when',\n 'the',\n 'lawn',\n 'area',\n 'get',\n 'done',\n 'lol',\n 'who',\n 'about to',\n 'come',\n 'way',\n 'out',\n 'there',\n 'come',\n 'get',\n 'me',\n 'bring',\n 'me',\n 'back',\n \"we'll\",\n 'come',\n 'lol',\n 'i',\n 'forgot',\n 'you',\n 'moved',\n 'canal',\n 'then',\n 'lol',\n 'apple',\n 'forgets',\n 'to',\n 'renew',\n 'ssl',\n 'certificate',\n 'breaking',\n 'os',\n 'x',\n 'software',\n 'update',\n 'i know',\n 'id',\n 'rather',\n 'someone',\n 'unfollow',\n 'me',\n 'than',\n 'mute',\n 'me',\n 'like',\n 'what',\n 'oh',\n 'my',\n 'poor',\n 'zac',\n 'take',\n 'good',\n 'care',\n 'of',\n 'yourself',\n 'kimberley',\n 'walsh',\n 'confirms',\n 'cheryl',\n \"cole's\",\n \"britain's\",\n 'got',\n 'talent',\n 'appearance',\n 'contact music',\n 'comkimberley',\n 'walsh',\n 'confir',\n 'exo',\n 'is',\n 'practising',\n 'for',\n 'concert',\n 'lol',\n 'you',\n 'still',\n 'in',\n 'school',\n 'shut up',\n 'he',\n 'wants',\n 'to',\n 'get',\n 'bigger',\n 'than',\n 'parth',\n 'lmfao',\n 'chanyeol',\n 'is',\n 'so',\n 'caring',\n 'omg',\n 'be',\n 'mine',\n 'please',\n 'nothing',\n 'just',\n 'chilling',\n 'imy',\n 'you',\n \"don't\",\n 'fuck',\n 'with',\n 'a',\n 'thug',\n 'no more',\n 'lol',\n 'udah',\n 'lama',\n 'nda',\n 'how',\n 'about',\n 'it',\n 'how',\n 'about',\n 'that',\n 'lol',\n 'i know',\n 'i',\n 'just',\n 'took',\n 'them',\n 'real',\n 'quick',\n 'i',\n \"wasn't\",\n 'thinking',\n 'the',\n 'order',\n '1',\n 'daily',\n 'follower',\n '0',\n 'unfollowers',\n 'just unfollow',\n \"doesn't\",\n 'miss',\n 'a',\n 'trick',\n \"i'm\",\n 'going to',\n 'do',\n 'it',\n 'after',\n 'graduation',\n 'lol',\n 'second',\n 'time',\n 'this',\n 'shit',\n 'crashed',\n 'on',\n 'datpiff',\n 'so',\n 'we',\n 'on',\n 'soundcloud',\n 'with',\n 'it',\n 'genji',\n 'sports',\n 'pop',\n 'up',\n 'family',\n 'beach',\n 'tent',\n 'and',\n 'beach',\n 'sun shelter',\n 'genji',\n 'sports',\n 'pop',\n 'up',\n 'fami',\n 'titan',\n 'baseball',\n 'beats',\n 'brv',\n 'to',\n 'advance',\n 'to',\n 'county',\n 'championship',\n 'tri',\n 'tomorrow',\n '4',\n 'pm',\n 'jump seat',\n 'radio',\n '018',\n 'combat',\n 'ready',\n 'firefighting',\n 'with',\n 'tony',\n 'kelleher',\n 'repost',\n 'i',\n 'added',\n 'a',\n 'video',\n 'to',\n 'a',\n 'playlist',\n 'plg',\n 'seductive',\n 'retribution',\n 'ep',\n '3',\n \"let's\",\n 'tango',\n 'wildfires',\n 'turkey',\n 'feather',\n 'fletching',\n 'for',\n 'archery',\n 'arrows',\n 'diy',\n 'pheasant',\n 'feathers',\n 'for',\n 'arro',\n 'where',\n 'the',\n 'mj',\n 'though',\n 'lol',\n '492',\n 'luke',\n 'hemmings',\n 'from',\n '5sos',\n 'i',\n 'love',\n 'you',\n 'so',\n 'much',\n 'please',\n 'follow',\n 'me',\n 'you',\n 'are',\n 'everything',\n 'to',\n 'me',\n 'please',\n 'dude',\n 'you',\n 'never',\n 'gave',\n 'me',\n 'the',\n 'kik',\n 'or',\n 'snapchat',\n \"you'll\",\n 'sea',\n 'lmfao',\n 'oookay',\n 'bean',\n 'eating',\n 'headass',\n 'morning',\n 'exercise',\n 'paakyat',\n 'ng',\n 'thunderbird',\n 'i',\n 'love',\n 'you',\n 'phil',\n 'of',\n 'the',\n 'future',\n 'i',\n 'love',\n 'everything',\n 'about',\n 'you',\n 'nao',\n 'superei',\n 'ainda',\n 'this',\n 'is',\n 'for',\n 'niall',\n 'e',\n 'vcs',\n 'wara',\n 'man',\n 'talaga',\n 'forever',\n 'lanyard',\n 'ano',\n 'una',\n 'mo',\n 'imortal',\n 'ka',\n 'hahahahahahhahaha',\n 'hot',\n 'music',\n 'mariah',\n 'carey',\n 'meteorite',\n 'q',\n 'meteorite',\n 'version',\n 'mariah',\n 'carey',\n 'has',\n 'ohh',\n 'i',\n 'feel',\n 'you',\n 'haha',\n 'so',\n 'is',\n 'writing',\n 'a',\n 'book',\n 'about',\n 'jay',\n 'z',\n 'and',\n 'beyonce',\n 'telling',\n 'someone',\n \"else's\",\n 'secrets',\n 'for',\n 'money',\n 'shows',\n 'how',\n 'low',\n 'some',\n 'people',\n 'will',\n 'stoop',\n 'fast',\n 'forward',\n 'to',\n 'june',\n '9',\n 'please',\n 'para',\n 'makapag',\n 'ipon',\n 'na',\n 'hahahahahah',\n 'lol',\n 'thank',\n 'you',\n 'liam',\n 'for',\n 'asking',\n 'louis',\n 'what',\n 'flavour',\n 'harry',\n 'is',\n \"i'm\",\n 'so',\n 'jskcosnxoancoamxis',\n 'ahhhhh',\n 'salt',\n 'and',\n 'vinegar',\n \"don't\",\n 'take',\n 'it',\n 'personal',\n 'kid',\n 'caroline',\n 'wozniacki',\n 'breaks',\n 'silence',\n 'on',\n 'rory',\n 'mcilroy',\n 'breakup',\n '140525',\n 'boakwon',\n 'instagram',\n 'update',\n 'with',\n 'exo',\n 'and',\n 'suju',\n 'siwon',\n 'donghae',\n 'more',\n 'and',\n 'forehead',\n 'ft',\n 'hyuk',\n 'thanks',\n 'for',\n 'that',\n 'spiderman',\n 'carnage',\n 'mask',\n '300rb',\n 'lom',\n 'ama',\n 'ongkir',\n 'ready',\n 'stock',\n 'running',\n 'with',\n 'who',\n 'do',\n 'you',\n 'think',\n 'is',\n 'faster',\n 'nicki',\n 'minaj',\n 'slick',\n 'went',\n 'from',\n 'brownskin',\n 'to',\n 'lightskin',\n 'over',\n 'the',\n 'years',\n 'if',\n 'you',\n \"don't\",\n 'fuck',\n 'with',\n 'dunny',\n 'gage',\n 'then',\n 'fuck',\n 'ya',\n 'life',\n 'last',\n 'day',\n 'of',\n 'school',\n 'gonna',\n 'have',\n 'people',\n 'like',\n 'the',\n 'bad',\n 'pastor',\n 'impostors',\n 'so',\n 'loves',\n 'a',\n 'lottle',\n 'to',\n 'jesus',\n 'the',\n 'people',\n 'can',\n 'intercession',\n 'for',\n 'he',\n 'for',\n 'the',\n 'soul',\n 'peole',\n 'wilshire',\n 'itq',\n 'hehe',\n 'stay',\n 'strong',\n '1',\n 'k',\n 'swim',\n 'sauna',\n 'post',\n 'work',\n 'now',\n 'beer',\n 'work',\n 'tomorrow',\n 'terserah',\n 'suho',\n 'gave',\n 'a',\n 'teddy',\n 'bear',\n 'and',\n 'took',\n 'a',\n 'selca',\n 'with',\n 'a',\n 'fan',\n 'tazz',\n 'needa',\n 'quit',\n 'it',\n 'with',\n 'that',\n 'last',\n 'quote',\n 'lol',\n 'she',\n \"don't\",\n 'live',\n 'that',\n 'life',\n 'why',\n 'the',\n 'fuck',\n 'did',\n 'i',\n 'think',\n 'i',\n 'was',\n 'scheduled',\n 'today',\n 'am',\n 'i',\n 'on',\n 'crack',\n 'lmao',\n 'what',\n 'my',\n 'top',\n '3',\n 'artists',\n 'girls',\n 'aloud',\n '15',\n 'christina',\n 'aguilera',\n '13',\n 'kylie',\n 'minogue',\n '12',\n 'how',\n 'he',\n 'top',\n '5',\n 'scorer',\n 'and',\n 'the',\n 'offense',\n \"ain't\",\n 'around',\n 'atleast',\n 'him',\n 'lol',\n 'that',\n \"don't\",\n 'make',\n 'sense',\n 'that',\n 'mean',\n 'he',\n 'jackin',\n 'then',\n 'lol',\n 'kompany',\n 'going',\n 'up',\n 'to',\n 'yaya',\n 'toure',\n 'after',\n 'he',\n 'found',\n 'out',\n 'he',\n 'wanted',\n 'to',\n 'leave',\n 'first',\n 'class',\n 'thing',\n 'see',\n 'wizkid',\n 'and',\n 'banky',\n 'w',\n 'having',\n 'fun',\n 'on',\n 'via',\n 'the',\n 'old',\n 'bargin',\n 'giant',\n 'would',\n 'make',\n 'a',\n 'good',\n 'entertainment',\n ...]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev[\"preds\"] = preds[:, 1]\n",
    "predictions = dev.sort_values(\"preds\", ascending=False).drop_duplicates([\"process\", \"tweet\", \"tok\"])\n",
    "pred_tokens = predictions.sort_values([\"process\", \"tweet\", \"tok\"]).index.tolist()\n",
    "pred_tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "from lexnorm.generate_extract.filtering import is_eligible\n",
    "from lexnorm.data.normEval import loadNormData, evaluate\n",
    "raw, norm = loadNormData(os.path.join(DATA_PATH, \"raw/dev.norm\"))\n",
    "# pred_tokens_iter = iter(pred_tokens)\n",
    "#\n",
    "# pred_tweets = []\n",
    "#\n",
    "# for tweet in raw:\n",
    "#     pred_tweet = []\n",
    "#     for tok in tweet:\n",
    "#         if is_eligible(tok):\n",
    "#             pred_tweet.append(next(pred_tokens_iter))\n",
    "#         else:\n",
    "#             pred_tweet.append(tok)\n",
    "#     pred_tweets.append(pred_tweet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline acc.(LAI): 93.10\n",
      "Accuracy:           96.28\n",
      "ERR:                46.13\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.9309630275929763, 0.9628094666812084, 0.4612954186413895)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# better!!\n",
    "evaluate(raw, norm, pred_tweets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       ...,\n       [0.98, 0.02],\n       [1.  , 0.  ],\n       [1.  , 0.  ]])"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from lexnorm.definitions import DATA_PATH\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, \"hpc/train_processed_annotated.txt\"), index_col=0)\n",
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/dev_processed.txt\"), index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'loc'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m[(train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprocess\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m63\u001B[39m) \u001B[38;5;241m&\u001B[39m (train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtweet\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m&\u001B[39m (train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtok\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m)]\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'function' object has no attribute 'loc'"
     ]
    }
   ],
   "source": [
    "train.loc[(train['process'] == 63) & (train['tweet'] == 0) & (train['tok'] == 2)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from lexnorm.data.word2vec import get_vectors\n",
    "\n",
    "vectors = get_vectors(os.path.join(DATA_PATH, \"raw/train.norm\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"
     ]
    },
    {
     "data": {
      "text/plain": "     cosine_to_orig  embeddings_rank\nyea        0.912848                1\nyes        0.821176                2\noh         0.817392                3\nnah        0.798594                4\nuh         0.792015                5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>yea</th>\n      <td>0.912848</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>yes</th>\n      <td>0.821176</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>oh</th>\n      <td>0.817392</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>nah</th>\n      <td>0.798594</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>uh</th>\n      <td>0.792015</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexnorm.generate_extract.modules import word_embeddings\n",
    "\n",
    "word_embeddings(\"yeah\", vectors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "process  tweet  tok\n0        0      1       16\n                2       34\n                3      291\n                4      113\n                5       11\n                      ... \n58       9      10      49\n                11      55\n                12      38\n                13       6\n                14       1\nLength: 6876, dtype: int64"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from lexnorm.models.random_forest import train\n",
    "\n",
    "dev.groupby([\"process\", \"tweet\", \"tok\"]).size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6876\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for tweet in raw:\n",
    "    for tok in tweet:\n",
    "        if is_eligible(tok):\n",
    "            count += 1\n",
    "\n",
    "print(count)\n",
    "# as expected - candidates generated for every eligible raw token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexnorm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[62], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlexnorm\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m random_forest\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m importlib\u001B[38;5;241m.\u001B[39mreload(\u001B[43mlexnorm\u001B[49m\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mnormalise\u001B[38;5;241m.\u001B[39mprep_test)\n\u001B[1;32m      7\u001B[0m clf \u001B[38;5;241m=\u001B[39m joblib\u001B[38;5;241m.\u001B[39mload(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(DATA_PATH, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../models/rf.joblib\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m      8\u001B[0m dev_X \u001B[38;5;241m=\u001B[39m prep_test(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(DATA_PATH, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhpc/dev_processed.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'lexnorm' is not defined"
     ]
    }
   ],
   "source": [
    "from lexnorm.models.normalise import prep_test, normalise\n",
    "import joblib\n",
    "\n",
    "from lexnorm.models import random_forest\n",
    "clf = joblib.load(os.path.join(DATA_PATH, \"../models/rf.joblib\"))\n",
    "dev_X = prep_test(os.path.join(DATA_PATH, \"hpc/dev_processed.txt\"))\n",
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/dev_processed.txt\"), index_col=0)\n",
    "preds = random_forest.predict(clf, dev_X, dev)\n",
    "predictions = normalise(raw, preds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo your you\n",
      "xaragdax xaragdax paradox\n",
      "uuliin uuliin insulin\n",
      "zogsoj zogsoj couscous\n",
      "dese these dese\n",
      "dey they dey\n",
      "summn something summn\n",
      "nigjt night nigjt\n",
      "shettima shettima estimate\n",
      "realised realized realised\n",
      "hella hell of a lot of hella\n",
      "bestie best friend bestie\n",
      "chillen chilling chillen\n",
      "niggra nigger niggra\n",
      "yellowcard yellow card yellowcard\n",
      "da da the\n",
      "factor factor factoring\n",
      "darlin darling darlin\n",
      "smyle smile smyle\n",
      "sadest saddest sadest\n",
      "tenerezza tenerezza containerize\n",
      "wkeend weekend keen\n",
      "bro brother bro\n",
      "babyface baby face babyface\n",
      "orrr or orrr\n",
      "noo no noo\n",
      "readers readers reviewers\n",
      "ammmazing amazing ammmazing\n",
      "actully actually actully\n",
      "id i'd id\n",
      "ohhh ohhh oh\n",
      "contactmusic contactmusic contact music\n",
      "datpiff the piff datpiff\n",
      "soundcloud sound cloud soundcloud\n",
      "sunshelter sunshelter sun shelter\n",
      "jumpseat jumpseat jump seat\n",
      "sensual sensual seductive\n",
      "toribash toribash retribution\n",
      "diy do it yourself diy\n",
      "oookay okay oookay\n",
      "headass head ass headass\n",
      "niyata niyata lanyard\n",
      "flavour flavor flavour\n",
      "n n and\n",
      "brownskin brown skin brownskin\n",
      "lightskin light skin lightskin\n",
      "ya your ya\n",
      "lottle lot lottle\n",
      "intercesion intercesion intercession\n",
      "peole people peole\n",
      "atleast at least atleast\n",
      "jackin jacking jackin\n",
      "centre center centre\n",
      "akukamba akukamba akimbo\n",
      "rt rt retweet\n",
      "vag vagina vag\n",
      "thang thing thang\n",
      "tho though tho\n",
      "carcillo carcillo gazillion\n",
      "yovani yovani ovarian\n",
      "nows now is nows\n",
      "pdx portland pdx\n",
      "glisan glisan glissandi\n",
      "whatdoiwear what do i wear whatdoiwear\n",
      "brutha brother brutha\n",
      "asst assistant asst\n",
      "yah you yah\n",
      "n n and\n",
      "fav favorite fav\n",
      "falaknuma falaknuma flakiness\n",
      "whisky whiskey whisky\n",
      "nid need nid\n",
      "2 to 2\n",
      "meetin meeting meetin\n",
      "tho though tho\n",
      "openheart openheart open heart\n",
      "shizz shit shizz\n",
      "ill i'll ill\n",
      "shoutout shout out shoutout\n",
      "d d the\n",
      "bre breath bre\n",
      "happylgovo happy happylgovo\n",
      "gal guy gal\n",
      "nd and nd\n",
      "liek like liek\n",
      "nd and nd\n",
      "doesng doesn't doesng\n",
      "lang long lang\n",
      "yhu you yhu\n",
      "nuh know nuh\n",
      "ntn nothing ntn\n",
      "wearr wear wearr\n",
      "reherseal rehearsal reherseal\n",
      "thotler thotler throttler\n",
      "mnl my new love mnl\n",
      "alrdy already alrdy\n",
      "bongkaran bongkaran background\n",
      "ya you ya\n",
      "poooollll pool poooollll\n",
      "sence sense sence\n",
      "humour humor humour\n",
      "ish ish shit\n",
      "tho though tho\n",
      "tho though tho\n",
      "havr have havr\n",
      "dogg dog dogg\n",
      "dogg dog dogg\n",
      "goddamit god damn it goddamit\n",
      "jornet jornet cornet\n",
      "zegama zegama amalgam\n",
      "b be b\n",
      "w with w\n",
      "throught through throught\n",
      "throught through throught\n",
      "singapore singapore singletree\n",
      "viru virus viru\n",
      "theirselves themselves theirselves\n",
      "golelhum golelhum glenohumeral\n",
      "farrukh farrukh farrago\n",
      "getcha get you getcha\n",
      "openfollow open follow openfollow\n",
      "sayeng sayeng sang\n",
      "vuldemurt vuldemurt voltmeter\n",
      "ur you're your\n",
      "wezird wezird weir\n",
      "ca'nt can't ca'nt\n",
      "whr where whr\n",
      "peewee peewee pee wee\n",
      "voy boy voy\n",
      "photobomb photo bomb photobomb\n",
      "photobomb photo bomb photobomb\n",
      "shoutout shout out shoutout\n",
      "skepta sunglasses skepta\n",
      "youtbe youtube youtbe\n",
      "d d the\n",
      "filmz film filmz\n",
      "bro brother bro\n",
      "adultwork adult work adultwork\n",
      "devs developer devs\n",
      "pies pies pie's\n",
      "ym my ym\n",
      "gdo god gdo\n",
      "keepin keeping keepin\n",
      "witchu with you witchu\n",
      "witchu with you witchu\n",
      "prez president prez\n",
      "quil quill quil\n",
      "nem they nem\n",
      "yo your you\n",
      "fkn fucking fkn\n",
      "tickt ticket tickt\n",
      "swsh swsh swoosh\n",
      "tix tickets ticket\n",
      "ya you ya\n",
      "sim seems sim\n",
      "upto up to upto\n",
      "nizamabad nizamabad consumable\n",
      "ya you ya\n",
      "clareta clareta clarity\n",
      "gospe gospel gospe\n",
      "switc switch switc\n",
      "alot a lot alot\n",
      "fav favorite fav\n",
      "ill i'll ill\n",
      "ill i'll ill\n",
      "rememberin remembering rememberin\n",
      "prayin praying prayin\n",
      "em em them\n",
      "dm dm direct message\n",
      "mamodou mamodou marmot\n",
      "1000follow 1000follow follow\n",
      "satnite saturday night satnite\n",
      "ya you ya\n",
      "esp especially esp\n",
      "hazard hazard hazard's\n",
      "asap asap as soon as possible\n",
      "diaporama diaporama pyramidal\n",
      "clonedvd clonedvd cloned\n",
      "haboyo haboyo harbor\n",
      "kaygeo kaygeo kayo\n",
      "hw homework hw\n",
      "nuffin nothing nuffin\n",
      "diss this diss\n",
      "hapi happy hapi\n",
      "2 to 2\n",
      "nd and nd\n",
      "nd and nd\n",
      "nd and nd\n",
      "2 to 2\n",
      "tho though tho\n",
      "legt left legt\n",
      "doesnot doesn't doesnot\n",
      "inspite in spite inspite\n",
      "r r are\n",
      "452740 452740 4th\n",
      "hapi happy hapi\n",
      "weeknd weeknd weekend\n",
      "hbu how about you hbu\n",
      "yessss yes yessss\n",
      "fu fu fuck\n",
      "fu fu fuck\n",
      "d d the\n",
      "ofcourse of course ofcourse\n",
      "vas was vas\n",
      "happenin happening happenin\n",
      "los los las\n",
      "boliches boliches abolishes\n",
      "closeeee close closeeee\n",
      "turnup turn up turnup\n",
      "redsox red sox redsox\n",
      "lifeee life lifeee\n",
      "loveholic loveholic alcoholic\n",
      "harrystyles harry styles harrystyles\n",
      "feela feels feela\n",
      "runnn run runnn\n",
      "townvilla townvilla town villa\n",
      "moodbreaker mood breaker moodbreaker\n",
      "moodbooster mood booster moodbooster\n",
      "marketwatch market watch marketwatch\n",
      "marketwatch market watch marketwatch\n",
      "fanmeet fan meet fanmeet\n",
      "ur you're your\n",
      "fav favorite fav\n",
      "sup what's up sup\n",
      "fatass fat ass fatass\n",
      "wassup what's up wassup\n",
      "meth methamphetamine meth\n",
      "meth methamphetamine meth\n",
      "d d the\n",
      "cocky cocky conceited\n",
      "c see c\n",
      "c see c\n",
      "4 for 4\n",
      "za that za\n",
      "wateva whatever wateva\n",
      "cums comes cums\n",
      "dnt doesn't don't\n",
      "los los las\n",
      "angeles angeles francisco\n",
      "thou though thou\n",
      "andd and andd\n",
      "ur you're your\n",
      "no not no\n",
      "polls polls elections\n",
      "singles singles dingles\n",
      "da da the\n",
      "mammaye mammaye mayoress\n",
      "nw nw now\n",
      "waitin waiting waitin\n",
      "its it's its\n",
      "onew one onew\n",
      "angeres angeres anger\n",
      "crippers crippers crippler\n",
      "sweatin sweating sweatin\n",
      "otha other otha\n",
      "yuh you yuh\n",
      "yuh you yuh\n",
      "judgement judgment judgement\n",
      "fav favorite fav\n",
      "meth methamphetamine meth\n",
      "cupcake cupcake shortcake\n",
      "orenjy orenjy orange\n",
      "mountsby mountsby mounts by\n",
      "incase in case incase\n",
      "shat shit shat\n",
      "d d the\n",
      "yea you yeah\n",
      "camikum camikum cadmium\n",
      "openfollow open follow openfollow\n",
      "thankyou thank you thankyou\n",
      "anyones anyone anyones\n",
      "tech tech techs\n",
      "sawtell sawtell satellite\n",
      "slp sleep slp\n",
      "famly family famly\n",
      "cupcake cupcake shortcake\n",
      "swearin swearing swearin\n",
      "o on o\n",
      "4 for 4\n",
      "dia their dia\n",
      "gd gd good\n",
      "creekview creek view creekview\n",
      "bc bc because\n",
      "yo your you\n",
      "fuccin fucking fuccin\n",
      "cuh see you cuh\n",
      "3volution 3volution convolution\n",
      "hovsepian hovsepian overspent\n",
      "tonyselznick tonyselznick tony selznick\n",
      "trynna trying to trynna\n",
      "c see c\n",
      "hw homework hw\n",
      "w with w\n",
      "wayeee wayeee freeway\n",
      "pepl people pepl\n",
      "heurelho heurelho heraldic\n",
      "ish ish shit\n",
      "nuff enough nuff\n",
      "teamchill teamchill team chill\n",
      "eatin eating eatin\n",
      "pre preorder pre\n",
      "order  order\n",
      "asheville asheville archival\n",
      "asheville asheville archival\n",
      "donut doughnut donut\n",
      "definitley definitely definitley\n",
      "pics pics pictures\n",
      "yeh yeah yeh\n",
      "tix tickets ticket\n",
      "miles miles kilometers\n",
      "da that the\n",
      "kishwar kishwar coachwork\n",
      "bedi's bedi's bedding's\n",
      "mazkirah mazkirah muskrat\n",
      "rip rip rest in peace\n",
      "v very v\n",
      "l'wren l'wren wren\n",
      "waitin waiting waitin\n",
      "b be b\n",
      "w with w\n",
      "af as fuck af\n",
      "czech czech ukrainian\n",
      "cannnot can't cannnot\n",
      "mybe maybe mybe\n",
      "ull you will ull\n",
      "fqauwh fqauwh foxhole\n",
      "icant i can't icant\n",
      "harrystyles harry styles harrystyles\n",
      "mah my mah\n",
      "brotha brother brotha\n",
      "dottie's dottie's dot tie's\n",
      "v very v\n",
      "b be b\n",
      "rangera rangera anger\n",
      "wada water wada\n",
      "suckin sucking suckin\n",
      "chu you chu\n",
      "loctite loctite lactate\n",
      "epoxy epoxy thermoplastic\n",
      "loctite loctite lactate\n",
      "Baseline acc.(LAI): 93.10\n",
      "Accuracy:           96.29\n",
      "ERR:                46.29\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.9309630275929763, 0.9629185298287709, 0.4628751974723546)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(raw, norm, predictions, verbose=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.09050270864114\n",
      "113.20335644201992\n"
     ]
    }
   ],
   "source": [
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/train_processed_annotated.txt\"), index_col=0)\n",
    "print(dev.groupby([\"process\", \"tweet\", \"tok\"]).size().mean())\n",
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/train_annotated.txt\"), index_col=0)\n",
    "print(dev.groupby([\"process\", \"tweet\", \"tok\"]).size().mean())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "        cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\nnah           0.798594              3.0            NaN                  NaN   \noh            0.817392              2.0            NaN                  NaN   \nuh            0.792014              4.0            NaN                  NaN   \nye ah              NaN              NaN            NaN                  NaN   \nye-ah              NaN              NaN            NaN                  NaN   \nyea           0.912848              0.0            NaN                  NaN   \nyea h              NaN              NaN            NaN                  NaN   \nyea-h              NaN              NaN            NaN                  NaN   \nyeah          1.000000              NaN            1.0                  1.0   \nyeah's        0.587786              NaN            1.0                  NaN   \nyeahs         0.659100              NaN            1.0                  NaN   \nyear          0.396437              NaN            NaN                  NaN   \nyeas          0.574666              NaN            NaN                  NaN   \nyeoman        0.221668              NaN            NaN                  NaN   \nyes           0.821176              1.0            NaN                  NaN   \nyeti          0.378206              NaN            NaN                  NaN   \n\n        from_split  norms_seen  spellcheck_rank  in_lexicon  length  \\\nnah            NaN         NaN              NaN         NaN       3   \noh             NaN         NaN              NaN         1.0       2   \nuh             NaN         NaN              NaN         1.0       2   \nye ah          1.0         NaN              4.0         NaN       5   \nye-ah          NaN         NaN              5.0         NaN       5   \nyea            NaN         NaN              0.0         1.0       3   \nyea h          NaN         NaN              6.0         NaN       5   \nyea-h          NaN         NaN              7.0         NaN       5   \nyeah           NaN        18.0              NaN         1.0       4   \nyeah's         NaN         NaN              NaN         1.0       6   \nyeahs          NaN         NaN              1.0         1.0       5   \nyear           NaN         NaN              3.0         1.0       4   \nyeas           NaN         NaN              2.0         1.0       4   \nyeoman         NaN         NaN              9.0         1.0       6   \nyes            NaN         NaN              NaN         1.0       3   \nyeti           NaN         NaN              8.0         1.0       4   \n\n        same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\nnah            NaN             18.0              1.0              1.0   \noh             NaN             18.0              1.0              1.0   \nuh             NaN             18.0              1.0              1.0   \nye ah          1.0             18.0              1.0              1.0   \nye-ah          1.0             18.0              1.0              1.0   \nyea            NaN             18.0              1.0              1.0   \nyea h          1.0             18.0              1.0              1.0   \nyea-h          1.0             18.0              1.0              1.0   \nyeah           1.0             18.0              1.0              1.0   \nyeah's         1.0             18.0              1.0              1.0   \nyeahs          1.0             18.0              1.0              1.0   \nyear           NaN             18.0              1.0              1.0   \nyeas           NaN             18.0              1.0              1.0   \nyeoman         NaN             18.0              1.0              1.0   \nyes            NaN             18.0              1.0              1.0   \nyeti           NaN             18.0              1.0              1.0   \n\n        orig_length  correct  process  tweet  tok  gold  \nnah             4.0      NaN       63      0    2  yeah  \noh              4.0      NaN       63      0    2  yeah  \nuh              4.0      NaN       63      0    2  yeah  \nye ah           4.0      NaN       63      0    2  yeah  \nye-ah           4.0      NaN       63      0    2  yeah  \nyea             4.0      NaN       63      0    2  yeah  \nyea h           4.0      NaN       63      0    2  yeah  \nyea-h           4.0      NaN       63      0    2  yeah  \nyeah            4.0      1.0       63      0    2  yeah  \nyeah's          4.0      NaN       63      0    2  yeah  \nyeahs           4.0      NaN       63      0    2  yeah  \nyear            4.0      NaN       63      0    2  yeah  \nyeas            4.0      NaN       63      0    2  yeah  \nyeoman          4.0      NaN       63      0    2  yeah  \nyes             4.0      NaN       63      0    2  yeah  \nyeti            4.0      NaN       63      0    2  yeah  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>correct</th>\n      <th>process</th>\n      <th>tweet</th>\n      <th>tok</th>\n      <th>gold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>nah</th>\n      <td>0.798594</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>oh</th>\n      <td>0.817392</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>uh</th>\n      <td>0.792014</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>ye ah</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>ye-ah</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>yea</th>\n      <td>0.912848</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>yea h</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>yea-h</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>yeah</th>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>yeah's</th>\n      <td>0.587786</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>yeahs</th>\n      <td>0.659100</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>year</th>\n      <td>0.396437</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>yeas</th>\n      <td>0.574666</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>yeoman</th>\n      <td>0.221668</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>yes</th>\n      <td>0.821176</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>yeti</th>\n      <td>0.378206</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/train_annotated.txt\"), index_col=0)\n",
    "dev.loc[(dev['process'] == 63) & (dev['tweet'] == 0) & (dev['tok'] == 2)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "        cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\nleah          0.384448              NaN            NaN                  NaN   \nnah           0.798594              5.0            NaN                  NaN   \noh            0.817392              4.0            NaN                  NaN   \nuh            0.792014              6.0            NaN                  NaN   \nye ah              NaN              NaN            NaN                  NaN   \nye-ah              NaN              NaN            NaN                  NaN   \nyea           0.912848              1.0            NaN                  NaN   \nyea h              NaN              NaN            NaN                  NaN   \nyea-h              NaN              NaN            NaN                  NaN   \nyeah          1.000000              2.0            NaN                  1.0   \nyeah's        0.587786              NaN            1.0                  NaN   \nyeahs         0.659100              NaN            1.0                  NaN   \nyear          0.396437              NaN            NaN                  NaN   \nyeas          0.574666              NaN            NaN                  NaN   \nyeoman        0.221668              NaN            NaN                  NaN   \nyes           0.821176              3.0            NaN                  NaN   \nyeti          0.378206              NaN            NaN                  NaN   \n\n        from_split  norms_seen  spellcheck_rank  in_lexicon  length  \\\nleah           NaN         NaN              5.0         1.0       4   \nnah            NaN         NaN              NaN         NaN       3   \noh             NaN         NaN              NaN         1.0       2   \nuh             NaN         NaN              NaN         1.0       2   \nye ah          1.0         NaN              6.0         NaN       5   \nye-ah          NaN         NaN              7.0         NaN       5   \nyea            NaN         NaN              1.0         1.0       3   \nyea h          NaN         NaN              8.0         NaN       5   \nyea-h          NaN         NaN              9.0         NaN       5   \nyeah           NaN        18.0              NaN         1.0       4   \nyeah's         NaN         NaN              NaN         1.0       6   \nyeahs          NaN         NaN              2.0         1.0       5   \nyear           NaN         NaN              4.0         1.0       4   \nyeas           NaN         NaN              3.0         1.0       4   \nyeoman         NaN         NaN             11.0         1.0       6   \nyes            NaN         NaN              NaN         1.0       3   \nyeti           NaN         NaN             10.0         1.0       4   \n\n        same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\nleah           NaN             18.0              1.0              1.0   \nnah            NaN             18.0              1.0              1.0   \noh             NaN             18.0              1.0              1.0   \nuh             NaN             18.0              1.0              1.0   \nye ah          1.0             18.0              1.0              1.0   \nye-ah          1.0             18.0              1.0              1.0   \nyea            NaN             18.0              1.0              1.0   \nyea h          1.0             18.0              1.0              1.0   \nyea-h          1.0             18.0              1.0              1.0   \nyeah           1.0             18.0              1.0              1.0   \nyeah's         1.0             18.0              1.0              1.0   \nyeahs          1.0             18.0              1.0              1.0   \nyear           NaN             18.0              1.0              1.0   \nyeas           NaN             18.0              1.0              1.0   \nyeoman         NaN             18.0              1.0              1.0   \nyes            NaN             18.0              1.0              1.0   \nyeti           NaN             18.0              1.0              1.0   \n\n        orig_length   raw  gold  correct  process  tweet  tok  \nleah            4.0  yeah  yeah      NaN       63      0    2  \nnah             4.0  yeah  yeah      NaN       63      0    2  \noh              4.0  yeah  yeah      NaN       63      0    2  \nuh              4.0  yeah  yeah      NaN       63      0    2  \nye ah           4.0  yeah  yeah      NaN       63      0    2  \nye-ah           4.0  yeah  yeah      NaN       63      0    2  \nyea             4.0  yeah  yeah      NaN       63      0    2  \nyea h           4.0  yeah  yeah      NaN       63      0    2  \nyea-h           4.0  yeah  yeah      NaN       63      0    2  \nyeah            4.0  yeah  yeah      1.0       63      0    2  \nyeah's          4.0  yeah  yeah      NaN       63      0    2  \nyeahs           4.0  yeah  yeah      NaN       63      0    2  \nyear            4.0  yeah  yeah      NaN       63      0    2  \nyeas            4.0  yeah  yeah      NaN       63      0    2  \nyeoman          4.0  yeah  yeah      NaN       63      0    2  \nyes             4.0  yeah  yeah      NaN       63      0    2  \nyeti            4.0  yeah  yeah      NaN       63      0    2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>raw</th>\n      <th>gold</th>\n      <th>correct</th>\n      <th>process</th>\n      <th>tweet</th>\n      <th>tok</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>leah</th>\n      <td>0.384448</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>nah</th>\n      <td>0.798594</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>oh</th>\n      <td>0.817392</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>uh</th>\n      <td>0.792014</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>ye ah</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>ye-ah</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>yea</th>\n      <td>0.912848</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>yea h</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>yea-h</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>yeah</th>\n      <td>1.000000</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>1.0</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>yeah's</th>\n      <td>0.587786</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>yeahs</th>\n      <td>0.659100</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>year</th>\n      <td>0.396437</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>yeas</th>\n      <td>0.574666</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>yeoman</th>\n      <td>0.221668</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>yes</th>\n      <td>0.821176</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>yeti</th>\n      <td>0.378206</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>yeah</td>\n      <td>yeah</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/train_processed_annotated.txt\"), index_col=0)\n",
    "dev.loc[(dev['process'] == 63) & (dev['tweet'] == 0) & (dev['tok'] == 2)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'test'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[77], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_log_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:907\u001B[0m, in \u001B[0;36mForestClassifier.predict_log_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    886\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_log_proba\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    887\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    888\u001B[0m \u001B[38;5;124;03m    Predict class log-probabilities for X.\u001B[39;00m\n\u001B[1;32m    889\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    905\u001B[0m \u001B[38;5;124;03m        classes corresponds to that in the attribute :term:`classes_`.\u001B[39;00m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 907\u001B[0m     proba \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    909\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    910\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mlog(proba)\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862\u001B[0m, in \u001B[0;36mForestClassifier.predict_proba\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    860\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    861\u001B[0m \u001B[38;5;66;03m# Check data\u001B[39;00m\n\u001B[0;32m--> 862\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_X_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[38;5;66;03m# Assign chunk of trees to jobs\u001B[39;00m\n\u001B[1;32m    865\u001B[0m n_jobs, _, _ \u001B[38;5;241m=\u001B[39m _partition_estimators(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_estimators, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:602\u001B[0m, in \u001B[0;36mBaseForest._validate_X_predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    599\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001B[39;00m\n\u001B[1;32m    601\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 602\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    603\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(X) \u001B[38;5;129;01mand\u001B[39;00m (X\u001B[38;5;241m.\u001B[39mindices\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc \u001B[38;5;129;01mor\u001B[39;00m X\u001B[38;5;241m.\u001B[39mindptr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39mintc):\n\u001B[1;32m    604\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo support for np.int64 index based sparse matrices\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/sklearn/base.py:546\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    545\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m--> 546\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    547\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[1;32m    548\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    877\u001B[0m         array \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(array, dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    878\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 879\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[1;32m    881\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    882\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[1;32m    883\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185\u001B[0m, in \u001B[0;36m_asarray_with_order\u001B[0;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[1;32m    182\u001B[0m     xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(array)\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m xp\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy.array_api\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;66;03m# Use NumPy API to support order\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(array, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: 'test'"
     ]
    }
   ],
   "source": [
    "clf.predict_log_proba(\"test\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"
     ]
    },
    {
     "data": {
      "text/plain": "     cosine_to_orig  embeddings_rank\nThe        0.757326                1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>The</th>\n      <td>0.757326</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from lexnorm.generate_extract import modules\n",
    "from lexnorm.generate_extract import candidate_generation\n",
    "importlib.reload(modules)\n",
    "\n",
    "modules.word_embeddings(\"the\", vectors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "data": {
      "text/plain": "        cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\nLeah          0.220881              0.0            0.0                  0.0   \nYea           0.780648              7.0            0.0                  0.0   \nYeah          0.834787              2.0            0.0                  0.0   \nnah           0.798594              5.0            0.0                  0.0   \noh            0.817392              4.0            0.0                  0.0   \n...                ...              ...            ...                  ...   \nilysfm        0.867017              2.0            0.0                  0.0   \nilysm         1.000000              0.0            0.0                  1.0   \nlysm          0.855508              4.0            0.0                  0.0   \nsilly         0.200586              0.0            0.0                  0.0   \nsmiley        0.340538              0.0            0.0                  0.0   \n\n        from_split  norms_seen  spellcheck_rank  in_lexicon  length  \\\nLeah           0.0         0.0              5.0         0.0       4   \nYea            0.0         0.0              0.0         0.0       3   \nYeah           0.0         0.0              0.0         0.0       4   \nnah            0.0         0.0              0.0         0.0       3   \noh             0.0         0.0              0.0         1.0       2   \n...            ...         ...              ...         ...     ...   \nilysfm         0.0         0.0              0.0         0.0       6   \nilysm          0.0         7.0              0.0         0.0       5   \nlysm           0.0         0.0              0.0         0.0       4   \nsilly          0.0         0.0              2.0         1.0       5   \nsmiley         0.0         0.0              1.0         1.0       6   \n\n        same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\nLeah           0.0             18.0              1.0              1.0   \nYea            0.0             18.0              1.0              1.0   \nYeah           0.0             18.0              1.0              1.0   \nnah            0.0             18.0              1.0              1.0   \noh             0.0             18.0              1.0              1.0   \n...            ...              ...              ...              ...   \nilysfm         1.0              7.0              0.0              1.0   \nilysm          1.0              7.0              0.0              1.0   \nlysm           0.0              7.0              0.0              1.0   \nsilly          0.0              7.0              0.0              1.0   \nsmiley         0.0              7.0              0.0              1.0   \n\n        orig_length  initial_capital  lowercase  uppercase  \nLeah            4.0                1          0          0  \nYea             4.0                1          0          0  \nYeah            4.0                1          0          0  \nnah             4.0                0          1          0  \noh              4.0                0          1          0  \n...             ...              ...        ...        ...  \nilysfm          5.0                0          1          0  \nilysm           5.0                0          1          0  \nlysm            5.0                0          1          0  \nsilly           5.0                0          1          0  \nsmiley          5.0                0          1          0  \n\n[3030660 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>initial_capital</th>\n      <th>lowercase</th>\n      <th>uppercase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Leah</th>\n      <td>0.220881</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Yea</th>\n      <td>0.780648</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Yeah</th>\n      <td>0.834787</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>nah</th>\n      <td>0.798594</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>oh</th>\n      <td>0.817392</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>ilysfm</th>\n      <td>0.867017</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>ilysm</th>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>lysm</th>\n      <td>0.855508</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>silly</th>\n      <td>0.200586</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>smiley</th>\n      <td>0.340538</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3030660 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexnorm.models import normalise\n",
    "\n",
    "importlib.reload(normalise)\n",
    "\n",
    "train1 = normalise.prep_train(os.path.join(DATA_PATH, \"hpc/train_processed_annotated.txt\"))\n",
    "# dev.loc[(dev['process'] == 35) & (dev['tweet'] == 0) & (dev['tok'] == 2)]\n",
    "# dev[dev.index.map(lambda x: isinstance(x, float))]\n",
    "train1 = train1[0]\n",
    "train1filtered = train1.loc[train1.index.map(lambda x: not any(c.isupper() for c in x))]\n",
    "train1\n",
    "# TODO ARGHHHH maybe just revert to ignoring uppercase suggestions - this is a mess. Come back with a clearer head. Remove uppercase suggestions and try again"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "          cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\nnah             0.798594              3.0            NaN                  NaN   \noh              0.817392              2.0            NaN                  NaN   \nuh              0.792014              4.0            NaN                  NaN   \nye ah                NaN              NaN            NaN                  NaN   \nye-ah                NaN              NaN            NaN                  NaN   \n...                  ...              ...            ...                  ...   \npoppn           0.861424              1.0            NaN                  NaN   \npopppin         0.820347              4.0            NaN                  NaN   \npropping        0.259834              NaN            NaN                  NaN   \npupping         0.272816              NaN            NaN                  NaN   \ntopping         0.379635              NaN            NaN                  NaN   \n\n          from_split  norms_seen  spellcheck_rank  in_lexicon  length  \\\nnah              NaN         NaN              NaN         NaN       3   \noh               NaN         NaN              NaN         1.0       2   \nuh               NaN         NaN              NaN         1.0       2   \nye ah            1.0         NaN              4.0         NaN       5   \nye-ah            NaN         NaN              5.0         NaN       5   \n...              ...         ...              ...         ...     ...   \npoppn            NaN         NaN              NaN         NaN       5   \npopppin          NaN         NaN              NaN         NaN       7   \npropping         NaN         NaN              5.0         1.0       8   \npupping          NaN         NaN              9.0         1.0       7   \ntopping          NaN         NaN              7.0         1.0       7   \n\n          same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\nnah              NaN             18.0              1.0              1.0   \noh               NaN             18.0              1.0              1.0   \nuh               NaN             18.0              1.0              1.0   \nye ah            1.0             18.0              1.0              1.0   \nye-ah            1.0             18.0              1.0              1.0   \n...              ...              ...              ...              ...   \npoppn            NaN              NaN              NaN              1.0   \npopppin          1.0              NaN              NaN              1.0   \npropping         1.0              NaN              NaN              1.0   \npupping          NaN              NaN              NaN              1.0   \ntopping          NaN              NaN              NaN              1.0   \n\n          orig_length  correct  process  tweet  tok     gold  \nnah               4.0      NaN       63      0    2     yeah  \noh                4.0      NaN       63      0    2     yeah  \nuh                4.0      NaN       63      0    2     yeah  \nye ah             4.0      NaN       63      0    2     yeah  \nye-ah             4.0      NaN       63      0    2     yeah  \n...               ...      ...      ...    ...  ...      ...  \npoppn             6.0      NaN       24     36  600  popping  \npopppin           6.0      NaN       24     36  600  popping  \npropping          6.0      NaN       24     36  600  popping  \npupping           6.0      NaN       24     36  600  popping  \ntopping           6.0      NaN       24     36  600  popping  \n\n[2988229 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>correct</th>\n      <th>process</th>\n      <th>tweet</th>\n      <th>tok</th>\n      <th>gold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>nah</th>\n      <td>0.798594</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>oh</th>\n      <td>0.817392</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>uh</th>\n      <td>0.792014</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>ye ah</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>ye-ah</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>63</td>\n      <td>0</td>\n      <td>2</td>\n      <td>yeah</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>poppn</th>\n      <td>0.861424</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>24</td>\n      <td>36</td>\n      <td>600</td>\n      <td>popping</td>\n    </tr>\n    <tr>\n      <th>popppin</th>\n      <td>0.820347</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>24</td>\n      <td>36</td>\n      <td>600</td>\n      <td>popping</td>\n    </tr>\n    <tr>\n      <th>propping</th>\n      <td>0.259834</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>24</td>\n      <td>36</td>\n      <td>600</td>\n      <td>popping</td>\n    </tr>\n    <tr>\n      <th>pupping</th>\n      <td>0.272816</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>24</td>\n      <td>36</td>\n      <td>600</td>\n      <td>popping</td>\n    </tr>\n    <tr>\n      <th>topping</th>\n      <td>0.379635</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>24</td>\n      <td>36</td>\n      <td>600</td>\n      <td>popping</td>\n    </tr>\n  </tbody>\n</table>\n<p>2988229 rows × 19 columns</p>\n</div>"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/train_annotated.txt\"), index_col=0, keep_default_na=False, na_values=\"\")\n",
    "# dev.loc[(dev['process'] == 35) & (dev['tweet'] == 0) & (dev['tok'] == 2)]\n",
    "dev"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "data": {
      "text/plain": "      cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\n2 2         0.000000              0.0            0.0                  0.0   \n2-2         0.339055              0.0            0.0                  0.0   \n150         0.931679              6.0            0.0                  0.0   \n250         0.941498              3.0            0.0                  0.0   \n400         0.939982              4.0            0.0                  0.0   \n...              ...              ...            ...                  ...   \n1974        0.945421              4.0            0.0                  0.0   \n1976        0.934110              9.0            0.0                  0.0   \n1977        0.944008              6.0            0.0                  0.0   \n1978        0.951944              2.0            0.0                  0.0   \n1981        0.940626              7.0            0.0                  0.0   \n\n      from_split  norms_seen  spellcheck_rank  in_lexicon  length  same_order  \\\n2 2          0.0         0.0              2.0         0.0       3         1.0   \n2-2          0.0         0.0              3.0         0.0       3         1.0   \n150          0.0         0.0              0.0         0.0       3         0.0   \n250          0.0         0.0              0.0         0.0       3         0.0   \n400          0.0         0.0              0.0         0.0       3         0.0   \n...          ...         ...              ...         ...     ...         ...   \n1974         0.0         0.0              0.0         0.0       4         0.0   \n1976         0.0         0.0              0.0         0.0       4         0.0   \n1977         0.0         0.0              0.0         0.0       4         0.0   \n1978         0.0         0.0              0.0         0.0       4         0.0   \n1981         0.0         0.0              0.0         0.0       4         0.0   \n\n      orig_norms_seen  orig_in_lexicon  orig_same_order  orig_length  \\\n2 2               1.0              0.0              1.0          2.0   \n2-2               1.0              0.0              1.0          2.0   \n150               2.0              0.0              1.0          4.0   \n250               2.0              0.0              1.0          4.0   \n400               2.0              0.0              1.0          4.0   \n...               ...              ...              ...          ...   \n1974              1.0              0.0              1.0          4.0   \n1976              1.0              0.0              1.0          4.0   \n1977              1.0              0.0              1.0          4.0   \n1978              1.0              0.0              1.0          4.0   \n1981              1.0              0.0              1.0          4.0   \n\n      initial_capital  lowercase  uppercase  \n2 2                 0          0          0  \n2-2                 0          0          0  \n150                 0          0          0  \n250                 0          0          0  \n400                 0          0          0  \n...               ...        ...        ...  \n1974                0          0          0  \n1976                0          0          0  \n1977                0          0          0  \n1978                0          0          0  \n1981                0          0          0  \n\n[955 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>initial_capital</th>\n      <th>lowercase</th>\n      <th>uppercase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2 2</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2-2</th>\n      <td>0.339055</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>0.931679</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>250</th>\n      <td>0.941498</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>400</th>\n      <td>0.939982</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1974</th>\n      <td>0.945421</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1976</th>\n      <td>0.934110</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1977</th>\n      <td>0.944008</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1978</th>\n      <td>0.951944</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1981</th>\n      <td>0.940626</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>955 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train1filtered.loc[train1filtered.index.to_series().isin(dev.index.to_series())==False]\n",
    "# TODO: the difference in predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "data": {
      "text/plain": "         cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\nLeah           0.220881              0.0            0.0                  0.0   \nYea            0.780648              7.0            0.0                  0.0   \nYeah           0.834787              2.0            0.0                  0.0   \nHahn           0.188633              0.0            0.0                  0.0   \nHannah         0.186623              0.0            0.0                  0.0   \n...                 ...              ...            ...                  ...   \nCamilla        0.393767              0.0            0.0                  0.0   \nCamille        0.365450              0.0            0.0                  0.0   \nCarmela        0.363765              0.0            0.0                  0.0   \nElysium        0.071589              0.0            0.0                  0.0   \nIlysm          0.856666              3.0            0.0                  0.0   \n\n         from_split  norms_seen  spellcheck_rank  in_lexicon  length  \\\nLeah            0.0         0.0              5.0         0.0       4   \nYea             0.0         0.0              0.0         0.0       3   \nYeah            0.0         0.0              0.0         0.0       4   \nHahn            0.0         0.0              6.0         0.0       4   \nHannah          0.0         0.0              7.0         0.0       6   \n...             ...         ...              ...         ...     ...   \nCamilla         0.0         0.0              1.0         0.0       7   \nCamille         0.0         0.0              2.0         0.0       7   \nCarmela         0.0         0.0              6.0         0.0       7   \nElysium         0.0         0.0              3.0         0.0       7   \nIlysm           0.0         0.0              0.0         0.0       5   \n\n         same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\nLeah            0.0             18.0              1.0              1.0   \nYea             0.0             18.0              1.0              1.0   \nYeah            0.0             18.0              1.0              1.0   \nHahn            0.0             67.0              0.0              1.0   \nHannah          0.0             67.0              0.0              1.0   \n...             ...              ...              ...              ...   \nCamilla         0.0              2.0              0.0              1.0   \nCamille         0.0              2.0              0.0              1.0   \nCarmela         0.0              2.0              0.0              1.0   \nElysium         0.0              7.0              0.0              1.0   \nIlysm           0.0              7.0              0.0              1.0   \n\n         orig_length  initial_capital  lowercase  uppercase  \nLeah             4.0                1          0          0  \nYea              4.0                1          0          0  \nYeah             4.0                1          0          0  \nHahn             4.0                1          0          0  \nHannah           4.0                1          0          0  \n...              ...              ...        ...        ...  \nCamilla          6.0                1          0          0  \nCamille          6.0                1          0          0  \nCarmela          6.0                1          0          0  \nElysium          5.0                1          0          0  \nIlysm            5.0                1          0          0  \n\n[39919 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>initial_capital</th>\n      <th>lowercase</th>\n      <th>uppercase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Leah</th>\n      <td>0.220881</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Yea</th>\n      <td>0.780648</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Yeah</th>\n      <td>0.834787</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Hahn</th>\n      <td>0.188633</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>67.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Hannah</th>\n      <td>0.186623</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>67.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Camilla</th>\n      <td>0.393767</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Camille</th>\n      <td>0.365450</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Carmela</th>\n      <td>0.363765</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Elysium</th>\n      <td>0.071589</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Ilysm</th>\n      <td>0.856666</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>39919 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.loc[train1.index.to_series().isin(dev.index.to_series())==False]\n",
    "# the difference is entirely from embeddings and spellcheck module putting out stuff that isn't lowercase!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "data": {
      "text/plain": "6876"
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for tweet in raw:\n",
    "    for tok in tweet:\n",
    "        if is_eligible(tok):\n",
    "           counter += 1\n",
    "\n",
    "counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"5\".islower()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "data": {
      "text/plain": "Leah       True\nYea        True\nYeah       True\nHahn       True\nHannah     True\n           ... \nCamilla    True\nCamille    True\nCarmela    True\nElysium    True\nIlysm      True\nLength: 42595, dtype: bool"
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.loc[((train1.embeddings_rank > 0) | (train1.spellcheck_rank > 0)) & (train1.lowercase == 0)].index.to_series().isin(train1.loc[train1.index.to_series().isin(dev.index.to_series())==False].index.to_series())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "data": {
      "text/plain": "         cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\nLeah           0.220881              0.0            0.0                  0.0   \nYea            0.780648              7.0            0.0                  0.0   \nYeah           0.834787              2.0            0.0                  0.0   \nHahn           0.188633              0.0            0.0                  0.0   \nHannah         0.186623              0.0            0.0                  0.0   \n...                 ...              ...            ...                  ...   \nCamilla        0.393767              0.0            0.0                  0.0   \nCamille        0.365450              0.0            0.0                  0.0   \nCarmela        0.363765              0.0            0.0                  0.0   \nElysium        0.071589              0.0            0.0                  0.0   \nIlysm          0.856666              3.0            0.0                  0.0   \n\n         from_split  norms_seen  spellcheck_rank  in_lexicon  length  \\\nLeah            0.0         0.0              5.0         0.0       4   \nYea             0.0         0.0              0.0         0.0       3   \nYeah            0.0         0.0              0.0         0.0       4   \nHahn            0.0         0.0              6.0         0.0       4   \nHannah          0.0         0.0              7.0         0.0       6   \n...             ...         ...              ...         ...     ...   \nCamilla         0.0         0.0              1.0         0.0       7   \nCamille         0.0         0.0              2.0         0.0       7   \nCarmela         0.0         0.0              6.0         0.0       7   \nElysium         0.0         0.0              3.0         0.0       7   \nIlysm           0.0         0.0              0.0         0.0       5   \n\n         same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\nLeah            0.0             18.0              1.0              1.0   \nYea             0.0             18.0              1.0              1.0   \nYeah            0.0             18.0              1.0              1.0   \nHahn            0.0             67.0              0.0              1.0   \nHannah          0.0             67.0              0.0              1.0   \n...             ...              ...              ...              ...   \nCamilla         0.0              2.0              0.0              1.0   \nCamille         0.0              2.0              0.0              1.0   \nCarmela         0.0              2.0              0.0              1.0   \nElysium         0.0              7.0              0.0              1.0   \nIlysm           0.0              7.0              0.0              1.0   \n\n         orig_length  initial_capital  lowercase  uppercase  \nLeah             4.0                1          0          0  \nYea              4.0                1          0          0  \nYeah             4.0                1          0          0  \nHahn             4.0                1          0          0  \nHannah           4.0                1          0          0  \n...              ...              ...        ...        ...  \nCamilla          6.0                1          0          0  \nCamille          6.0                1          0          0  \nCarmela          6.0                1          0          0  \nElysium          5.0                1          0          0  \nIlysm            5.0                1          0          0  \n\n[39278 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>initial_capital</th>\n      <th>lowercase</th>\n      <th>uppercase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Leah</th>\n      <td>0.220881</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Yea</th>\n      <td>0.780648</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Yeah</th>\n      <td>0.834787</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>18.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Hahn</th>\n      <td>0.188633</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>67.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Hannah</th>\n      <td>0.186623</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>67.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Camilla</th>\n      <td>0.393767</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Camille</th>\n      <td>0.365450</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Carmela</th>\n      <td>0.363765</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Elysium</th>\n      <td>0.071589</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Ilysm</th>\n      <td>0.856666</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>39278 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.loc[((train1.embeddings_rank > 0) | (train1.spellcheck_rank > 0)) & (train1.lowercase == 0) & (train1.index.map(lambda x: not x.isnumeric()))]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: perhaps just give up and do not generate non-lowercase suggestions for\n",
    "\"漢\".isalnum()\n",
    "# CHINESE, ARABIC, KOREAN seen as alphanumeric in python!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "data": {
      "text/plain": "         cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\ncan                 1.0              NaN            1.0                  1.0   \nyou                 1.0              NaN            1.0                  1.0   \nopen                1.0              NaN            1.0                  1.0   \nthe                 1.0              NaN            1.0                  1.0   \nlink                1.0              NaN            1.0                  1.0   \n...                 ...              ...            ...                  ...   \nthere               1.0              NaN            1.0                  1.0   \ncalling             1.0              NaN            1.0                  1.0   \nyall                1.0              NaN            NaN                  1.0   \nthots               1.0              NaN            NaN                  1.0   \nlol                 1.0              NaN            1.0                  1.0   \n\n         from_split  norms_seen  spellcheck_rank  in_lexicon  length  \\\ncan             NaN        72.0              NaN         1.0       3   \nyou             NaN       274.0              NaN         1.0       3   \nopen            NaN         8.0              NaN         1.0       4   \nthe             NaN       515.0              NaN         1.0       3   \nlink            NaN         4.0              NaN         1.0       4   \n...             ...         ...              ...         ...     ...   \nthere           NaN        24.0              2.0         1.0       5   \ncalling         NaN         1.0              0.0         1.0       7   \nyall            NaN         NaN              NaN         NaN       4   \nthots           NaN         5.0              NaN         NaN       5   \nlol             NaN       205.0              NaN         1.0       3   \n\n         same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\ncan             1.0             72.0              1.0              1.0   \nyou             1.0            274.0              1.0              1.0   \nopen            1.0              8.0              1.0              1.0   \nthe             1.0            515.0              1.0              1.0   \nlink            1.0              4.0              1.0              1.0   \n...             ...              ...              ...              ...   \nthere           1.0             24.0              1.0              1.0   \ncalling         1.0              1.0              1.0              1.0   \nyall            1.0              NaN              NaN              1.0   \nthots           1.0              5.0              NaN              1.0   \nlol             1.0            205.0              1.0              1.0   \n\n         orig_length  correct raw_tok_index     gold  \ncan              3.0      1.0          35_0      can  \nyou              3.0      1.0          35_1      you  \nopen             4.0      1.0          35_2     open  \nthe              3.0      1.0          35_3      the  \nlink             4.0      1.0          35_4     link  \n...              ...      ...           ...      ...  \nthere            5.0      1.0        32_156    there  \ncalling          7.0      1.0        32_157  calling  \nyall             4.0      NaN        32_158    y'all  \nthots            5.0      1.0        32_159    thots  \nlol              3.0      1.0        32_160      lol  \n\n[6876 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>correct</th>\n      <th>raw_tok_index</th>\n      <th>gold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>can</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>72.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>72.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>35_0</td>\n      <td>can</td>\n    </tr>\n    <tr>\n      <th>you</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>274.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>274.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>35_1</td>\n      <td>you</td>\n    </tr>\n    <tr>\n      <th>open</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>35_2</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>the</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>515.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>515.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>35_3</td>\n      <td>the</td>\n    </tr>\n    <tr>\n      <th>link</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>35_4</td>\n      <td>link</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>there</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>24.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>24.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>32_156</td>\n      <td>there</td>\n    </tr>\n    <tr>\n      <th>calling</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>32_157</td>\n      <td>calling</td>\n    </tr>\n    <tr>\n      <th>yall</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>32_158</td>\n      <td>y'all</td>\n    </tr>\n    <tr>\n      <th>thots</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>32_159</td>\n      <td>thots</td>\n    </tr>\n    <tr>\n      <th>lol</th>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>205.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>205.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>32_160</td>\n      <td>lol</td>\n    </tr>\n  </tbody>\n</table>\n<p>6876 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/dev_annotated.txt\"), index_col=0, keep_default_na=False, na_values=\"\")\n",
    "dev.loc[dev.from_original_token == 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [
    {
     "data": {
      "text/plain": "              index  process  tweet  tok\n0                ah        0      0    4\n1               why        0      0    8\n2               sub        0      0    9\n3              ozil        0      0   10\n4             opolo        0      0   14\n...             ...      ...    ...  ...\n26392            of       63     28   11\n26393           the       63     28   12\n26394        summer       63     28   13\n26395        wearin       63     28   14\n26396  chinchilla's       63     28   16\n\n[26397 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>process</th>\n      <th>tweet</th>\n      <th>tok</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ah</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>why</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sub</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ozil</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>opolo</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26392</th>\n      <td>of</td>\n      <td>63</td>\n      <td>28</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>26393</th>\n      <td>the</td>\n      <td>63</td>\n      <td>28</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>26394</th>\n      <td>summer</td>\n      <td>63</td>\n      <td>28</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>26395</th>\n      <td>wearin</td>\n      <td>63</td>\n      <td>28</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>26396</th>\n      <td>chinchilla's</td>\n      <td>63</td>\n      <td>28</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n<p>26397 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train.from_original_token == 1].sort_values([\"process\", \"tweet\", \"tok\"]).loc[:, [\"process\", \"tweet\", \"tok\"]].reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "            cosine_to_orig  embeddings_rank  from_clipping  \\\nRuhr              0.150083              NaN            NaN   \nbreh              0.881024              7.0            NaN   \nbro               0.873462              8.0            NaN   \nbrother           0.444352              NaN            NaN   \nbruh              1.000000              NaN            NaN   \n...                    ...              ...            ...   \nlocate                 NaN              NaN            NaN   \nloctite                NaN              NaN            NaN   \nloiter                 NaN              NaN            NaN   \nstalactite             NaN              NaN            NaN   \n1405603                NaN              NaN            NaN   \n\n            from_original_token  from_split  norms_seen  spellcheck_rank  \\\nRuhr                        NaN         NaN         NaN              2.0   \nbreh                        NaN         NaN         NaN              NaN   \nbro                         NaN         NaN         NaN              NaN   \nbrother                     NaN         NaN        26.0              NaN   \nbruh                        1.0         NaN         NaN              NaN   \n...                         ...         ...         ...              ...   \nlocate                      NaN         NaN         NaN              1.0   \nloctite                     1.0         NaN         NaN              NaN   \nloiter                      NaN         NaN         NaN              2.0   \nstalactite                  NaN         NaN         NaN              5.0   \n1405603                     1.0         NaN         NaN              NaN   \n\n            in_lexicon  length  same_order  orig_norms_seen  orig_in_lexicon  \\\nRuhr               NaN       4         NaN              NaN              NaN   \nbreh               NaN       4         NaN              NaN              NaN   \nbro                NaN       3         NaN              NaN              NaN   \nbrother            1.0       7         NaN              NaN              NaN   \nbruh               NaN       4         1.0              NaN              NaN   \n...                ...     ...         ...              ...              ...   \nlocate             1.0       6         NaN              NaN              NaN   \nloctite            NaN       7         1.0              NaN              NaN   \nloiter             1.0       6         NaN              NaN              NaN   \nstalactite         1.0      10         NaN              NaN              NaN   \n1405603            NaN       7         1.0              NaN              NaN   \n\n            orig_same_order  orig_length      raw  tok_id  \nRuhr                    1.0          4.0     bruh       0  \nbreh                    1.0          4.0     bruh       0  \nbro                     1.0          4.0     bruh       0  \nbrother                 1.0          4.0     bruh       0  \nbruh                    1.0          4.0     bruh       0  \n...                     ...          ...      ...     ...  \nlocate                  1.0          7.0  loctite    6874  \nloctite                 1.0          7.0  loctite    6874  \nloiter                  1.0          7.0  loctite    6874  \nstalactite              1.0          7.0  loctite    6874  \n1405603                 1.0          7.0  1405603    6875  \n\n[738491 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>raw</th>\n      <th>tok_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Ruhr</th>\n      <td>0.150083</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>breh</th>\n      <td>0.881024</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>bro</th>\n      <td>0.873462</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>brother</th>\n      <td>0.444352</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>26.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>bruh</th>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>locate</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>loctite</td>\n      <td>6874</td>\n    </tr>\n    <tr>\n      <th>loctite</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>loctite</td>\n      <td>6874</td>\n    </tr>\n    <tr>\n      <th>loiter</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>loctite</td>\n      <td>6874</td>\n    </tr>\n    <tr>\n      <th>stalactite</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>loctite</td>\n      <td>6874</td>\n    </tr>\n    <tr>\n      <th>1405603</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>1405603</td>\n      <td>6875</td>\n    </tr>\n  </tbody>\n</table>\n<p>738491 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexnorm.generate_extract import process\n",
    "import pandas as pd\n",
    "import os\n",
    "from lexnorm.definitions import DATA_PATH\n",
    "import importlib\n",
    "importlib.reload(process)\n",
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/dev_processed.txt\"), index_col=0, keep_default_na=False, na_values=\"\")\n",
    "process.create_index(dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "            cosine_to_orig  embeddings_rank  from_clipping  \\\nbreh              0.881024              7.0            NaN   \nbro               0.873462              8.0            NaN   \nbrother           0.444352              NaN            NaN   \nbruh              1.000000              NaN            NaN   \nbruhhh            0.887914              4.0            NaN   \n...                    ...              ...            ...   \nlocate                 NaN              NaN            NaN   \nloctite                NaN              NaN            NaN   \nloiter                 NaN              NaN            NaN   \nstalactite             NaN              NaN            NaN   \n1405603                NaN              NaN            NaN   \n\n            from_original_token  from_split  norms_seen  spellcheck_rank  \\\nbreh                        NaN         NaN         NaN              NaN   \nbro                         NaN         NaN         NaN              NaN   \nbrother                     NaN         NaN        26.0              NaN   \nbruh                        1.0         NaN         NaN              NaN   \nbruhhh                      NaN         NaN         NaN              NaN   \n...                         ...         ...         ...              ...   \nlocate                      NaN         NaN         NaN              1.0   \nloctite                     1.0         NaN         NaN              NaN   \nloiter                      NaN         NaN         NaN              2.0   \nstalactite                  NaN         NaN         NaN              4.0   \n1405603                     1.0         NaN         NaN              NaN   \n\n            in_lexicon  length  same_order  orig_norms_seen  orig_in_lexicon  \\\nbreh               NaN       4         NaN              NaN              NaN   \nbro                NaN       3         NaN              NaN              NaN   \nbrother            1.0       7         NaN              NaN              NaN   \nbruh               NaN       4         1.0              NaN              NaN   \nbruhhh             NaN       6         1.0              NaN              NaN   \n...                ...     ...         ...              ...              ...   \nlocate             1.0       6         NaN              NaN              NaN   \nloctite            NaN       7         1.0              NaN              NaN   \nloiter             1.0       6         NaN              NaN              NaN   \nstalactite         1.0      10         NaN              NaN              NaN   \n1405603            NaN       7         1.0              NaN              NaN   \n\n            orig_same_order  orig_length      raw      prev     next  tok_id  \\\nbreh                    1.0          4.0     bruh  @cdutra5      get       0   \nbro                     1.0          4.0     bruh  @cdutra5      get       0   \nbrother                 1.0          4.0     bruh  @cdutra5      get       0   \nbruh                    1.0          4.0     bruh  @cdutra5      get       0   \nbruhhh                  1.0          4.0     bruh  @cdutra5      get       0   \n...                     ...          ...      ...       ...      ...     ...   \nlocate                  1.0          7.0  loctite       gel  1405603    6874   \nloctite                 1.0          7.0  loctite       gel  1405603    6874   \nloiter                  1.0          7.0  loctite       gel  1405603    6874   \nstalactite              1.0          7.0  loctite       gel  1405603    6874   \n1405603                 1.0          7.0  1405603   loctite      0.8    6875   \n\n               gold  \nbreh        brother  \nbro         brother  \nbrother     brother  \nbruh        brother  \nbruhhh      brother  \n...             ...  \nlocate      loctite  \nloctite     loctite  \nloiter      loctite  \nstalactite  loctite  \n1405603     1405603  \n\n[724672 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>raw</th>\n      <th>prev</th>\n      <th>next</th>\n      <th>tok_id</th>\n      <th>gold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>breh</th>\n      <td>0.881024</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>@cdutra5</td>\n      <td>get</td>\n      <td>0</td>\n      <td>brother</td>\n    </tr>\n    <tr>\n      <th>bro</th>\n      <td>0.873462</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>@cdutra5</td>\n      <td>get</td>\n      <td>0</td>\n      <td>brother</td>\n    </tr>\n    <tr>\n      <th>brother</th>\n      <td>0.444352</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>26.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>@cdutra5</td>\n      <td>get</td>\n      <td>0</td>\n      <td>brother</td>\n    </tr>\n    <tr>\n      <th>bruh</th>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>@cdutra5</td>\n      <td>get</td>\n      <td>0</td>\n      <td>brother</td>\n    </tr>\n    <tr>\n      <th>bruhhh</th>\n      <td>0.887914</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>@cdutra5</td>\n      <td>get</td>\n      <td>0</td>\n      <td>brother</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>locate</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>loctite</td>\n      <td>gel</td>\n      <td>1405603</td>\n      <td>6874</td>\n      <td>loctite</td>\n    </tr>\n    <tr>\n      <th>loctite</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>loctite</td>\n      <td>gel</td>\n      <td>1405603</td>\n      <td>6874</td>\n      <td>loctite</td>\n    </tr>\n    <tr>\n      <th>loiter</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>loctite</td>\n      <td>gel</td>\n      <td>1405603</td>\n      <td>6874</td>\n      <td>loctite</td>\n    </tr>\n    <tr>\n      <th>stalactite</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>loctite</td>\n      <td>gel</td>\n      <td>1405603</td>\n      <td>6874</td>\n      <td>loctite</td>\n    </tr>\n    <tr>\n      <th>1405603</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>1405603</td>\n      <td>loctite</td>\n      <td>0.8</td>\n      <td>6875</td>\n      <td>1405603</td>\n    </tr>\n  </tbody>\n</table>\n<p>724672 rows × 19 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using create_index to index into corresponding normalisations list for each candidate - dev.gold\n",
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/dev_processed_nocap_neighbours.txt\"), index_col=0, keep_default_na=False, na_values=\"\")\n",
    "dev = process.create_index(dev)\n",
    "\n",
    "from lexnorm.data import normEval\n",
    "from lexnorm.generate_extract.filtering import is_eligible\n",
    "\n",
    "raw, norm = normEval.loadNormData(os.path.join(DATA_PATH, \"raw/dev.norm\"))\n",
    "eligible_norms = []\n",
    "for raw_tweet, norm_tweet in zip(raw, norm):\n",
    "    for raw_tok, norm_tok in zip(raw_tweet, norm_tweet):\n",
    "        if is_eligible(raw_tok):\n",
    "            eligible_norms.append(norm_tok)\n",
    "dev[\"gold\"] = dev.apply(lambda x: eligible_norms[x.tok_id], axis=1)\n",
    "dev"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                    raw            gold\ndeese              dese           these\nsemen             summn       something\nbeside           bestie     best friend\nbrenneh          niggra          nigger\ndatatype        datpiff        the piff\ncricut              diy  do it yourself\na                    ya            your\nbottle           lottle             lot\nbows               nows          now is\ntidewater   whatdoiwear  what do i wear\nbreath           brutha         brother\naah                 yah             you\nchizz             shizz            shit\nhappily      happylgovo           happy\ncal                 gal             guy\naffi                nuh            know\nbauni               ntn         nothing\ncabanatuan          mnl     my new love\nbajakk        poooollll            pool\ndammit         goddamit     god damn it\nbetcha           getcha         get you\navicci           skepta      sunglasses\ncreators           devs       developer\nhitch            witchu        with you\ndrika               nem            they\nf kn                fkn         fucking\naim                 sim           seems\nhavefun         satnite  saturday night\ninfinity         nuffin         nothing\ndies               diss            this\napish              hapi           happy\nbu                  hbu   how about you\nessayer          yessss             yes\nas                  vas             was\nbedsore          redsox         red sox\ncup                 sup       what's up\nsurpass          wassup       what's up\na                    za            that\ncams               cums           comes\nant                 dnt         doesn't\nchat               shat            shit\naight               yea             you\n2sleep              slp           sleep\naid                 dia           their\nfckin            fuccin         fucking\nbrah                cuh         see you\nfinna            trynna       trying to\nbuff               nuff          enough\nempting             pre        preorder\nborder            order                \na                    da            that\na                     v            very\nannotate        cannnot           can't\nall                 ull        you will\nagent             icant         i can't\nbreath           brotha         brother\ndhul               wada           water\nch                  chu             you",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw</th>\n      <th>gold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>deese</th>\n      <td>dese</td>\n      <td>these</td>\n    </tr>\n    <tr>\n      <th>semen</th>\n      <td>summn</td>\n      <td>something</td>\n    </tr>\n    <tr>\n      <th>beside</th>\n      <td>bestie</td>\n      <td>best friend</td>\n    </tr>\n    <tr>\n      <th>brenneh</th>\n      <td>niggra</td>\n      <td>nigger</td>\n    </tr>\n    <tr>\n      <th>datatype</th>\n      <td>datpiff</td>\n      <td>the piff</td>\n    </tr>\n    <tr>\n      <th>cricut</th>\n      <td>diy</td>\n      <td>do it yourself</td>\n    </tr>\n    <tr>\n      <th>a</th>\n      <td>ya</td>\n      <td>your</td>\n    </tr>\n    <tr>\n      <th>bottle</th>\n      <td>lottle</td>\n      <td>lot</td>\n    </tr>\n    <tr>\n      <th>bows</th>\n      <td>nows</td>\n      <td>now is</td>\n    </tr>\n    <tr>\n      <th>tidewater</th>\n      <td>whatdoiwear</td>\n      <td>what do i wear</td>\n    </tr>\n    <tr>\n      <th>breath</th>\n      <td>brutha</td>\n      <td>brother</td>\n    </tr>\n    <tr>\n      <th>aah</th>\n      <td>yah</td>\n      <td>you</td>\n    </tr>\n    <tr>\n      <th>chizz</th>\n      <td>shizz</td>\n      <td>shit</td>\n    </tr>\n    <tr>\n      <th>happily</th>\n      <td>happylgovo</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>cal</th>\n      <td>gal</td>\n      <td>guy</td>\n    </tr>\n    <tr>\n      <th>affi</th>\n      <td>nuh</td>\n      <td>know</td>\n    </tr>\n    <tr>\n      <th>bauni</th>\n      <td>ntn</td>\n      <td>nothing</td>\n    </tr>\n    <tr>\n      <th>cabanatuan</th>\n      <td>mnl</td>\n      <td>my new love</td>\n    </tr>\n    <tr>\n      <th>bajakk</th>\n      <td>poooollll</td>\n      <td>pool</td>\n    </tr>\n    <tr>\n      <th>dammit</th>\n      <td>goddamit</td>\n      <td>god damn it</td>\n    </tr>\n    <tr>\n      <th>betcha</th>\n      <td>getcha</td>\n      <td>get you</td>\n    </tr>\n    <tr>\n      <th>avicci</th>\n      <td>skepta</td>\n      <td>sunglasses</td>\n    </tr>\n    <tr>\n      <th>creators</th>\n      <td>devs</td>\n      <td>developer</td>\n    </tr>\n    <tr>\n      <th>hitch</th>\n      <td>witchu</td>\n      <td>with you</td>\n    </tr>\n    <tr>\n      <th>drika</th>\n      <td>nem</td>\n      <td>they</td>\n    </tr>\n    <tr>\n      <th>f kn</th>\n      <td>fkn</td>\n      <td>fucking</td>\n    </tr>\n    <tr>\n      <th>aim</th>\n      <td>sim</td>\n      <td>seems</td>\n    </tr>\n    <tr>\n      <th>havefun</th>\n      <td>satnite</td>\n      <td>saturday night</td>\n    </tr>\n    <tr>\n      <th>infinity</th>\n      <td>nuffin</td>\n      <td>nothing</td>\n    </tr>\n    <tr>\n      <th>dies</th>\n      <td>diss</td>\n      <td>this</td>\n    </tr>\n    <tr>\n      <th>apish</th>\n      <td>hapi</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>bu</th>\n      <td>hbu</td>\n      <td>how about you</td>\n    </tr>\n    <tr>\n      <th>essayer</th>\n      <td>yessss</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>as</th>\n      <td>vas</td>\n      <td>was</td>\n    </tr>\n    <tr>\n      <th>bedsore</th>\n      <td>redsox</td>\n      <td>red sox</td>\n    </tr>\n    <tr>\n      <th>cup</th>\n      <td>sup</td>\n      <td>what's up</td>\n    </tr>\n    <tr>\n      <th>surpass</th>\n      <td>wassup</td>\n      <td>what's up</td>\n    </tr>\n    <tr>\n      <th>a</th>\n      <td>za</td>\n      <td>that</td>\n    </tr>\n    <tr>\n      <th>cams</th>\n      <td>cums</td>\n      <td>comes</td>\n    </tr>\n    <tr>\n      <th>ant</th>\n      <td>dnt</td>\n      <td>doesn't</td>\n    </tr>\n    <tr>\n      <th>chat</th>\n      <td>shat</td>\n      <td>shit</td>\n    </tr>\n    <tr>\n      <th>aight</th>\n      <td>yea</td>\n      <td>you</td>\n    </tr>\n    <tr>\n      <th>2sleep</th>\n      <td>slp</td>\n      <td>sleep</td>\n    </tr>\n    <tr>\n      <th>aid</th>\n      <td>dia</td>\n      <td>their</td>\n    </tr>\n    <tr>\n      <th>fckin</th>\n      <td>fuccin</td>\n      <td>fucking</td>\n    </tr>\n    <tr>\n      <th>brah</th>\n      <td>cuh</td>\n      <td>see you</td>\n    </tr>\n    <tr>\n      <th>finna</th>\n      <td>trynna</td>\n      <td>trying to</td>\n    </tr>\n    <tr>\n      <th>buff</th>\n      <td>nuff</td>\n      <td>enough</td>\n    </tr>\n    <tr>\n      <th>empting</th>\n      <td>pre</td>\n      <td>preorder</td>\n    </tr>\n    <tr>\n      <th>border</th>\n      <td>order</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>a</th>\n      <td>da</td>\n      <td>that</td>\n    </tr>\n    <tr>\n      <th>a</th>\n      <td>v</td>\n      <td>very</td>\n    </tr>\n    <tr>\n      <th>annotate</th>\n      <td>cannnot</td>\n      <td>can't</td>\n    </tr>\n    <tr>\n      <th>all</th>\n      <td>ull</td>\n      <td>you will</td>\n    </tr>\n    <tr>\n      <th>agent</th>\n      <td>icant</td>\n      <td>i can't</td>\n    </tr>\n    <tr>\n      <th>breath</th>\n      <td>brotha</td>\n      <td>brother</td>\n    </tr>\n    <tr>\n      <th>dhul</th>\n      <td>wada</td>\n      <td>water</td>\n    </tr>\n    <tr>\n      <th>ch</th>\n      <td>chu</td>\n      <td>you</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# continuing from last cell, get all raw, gold pairs that were not generated by candidate generation:\n",
    "\n",
    "dev[\"correct\"] = dev.index.values == dev.gold\n",
    "dev.groupby(\"tok_id\").filter(lambda s: s.correct.sum() == 0).drop_duplicates([\"raw\", \"gold\"]).loc[:, [\"raw\", \"gold\"]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "               cosine_to_orig  embeddings_rank  from_clipping  \\\nbreh                 0.881024              7.0            NaN   \nbro                  0.873462              8.0            NaN   \nbrother              0.444352              NaN            NaN   \nbruh                 1.000000              NaN            NaN   \nbruhhh               0.887914              4.0            NaN   \n...                       ...              ...            ...   \noutcrop's                 NaN              NaN            1.0   \noutcropped                NaN              NaN            1.0   \noutcropping          0.360041              NaN            1.0   \noutcropping's             NaN              NaN            1.0   \noutcroppings         0.381839              NaN            1.0   \n\n               from_original_token  from_split  norms_seen  spellcheck_rank  \\\nbreh                           NaN         NaN         NaN              NaN   \nbro                            NaN         NaN         NaN              NaN   \nbrother                        NaN         NaN        26.0              NaN   \nbruh                           1.0         NaN         NaN              NaN   \nbruhhh                         NaN         NaN         NaN              NaN   \n...                            ...         ...         ...              ...   \noutcrop's                      NaN         NaN         NaN              NaN   \noutcropped                     NaN         NaN         NaN              NaN   \noutcropping                    NaN         NaN         NaN              NaN   \noutcropping's                  NaN         NaN         NaN              NaN   \noutcroppings                   NaN         NaN         NaN              NaN   \n\n               in_lexicon  length  same_order  ...  orig_length   raw  \\\nbreh                  NaN       4         NaN  ...          4.0  bruh   \nbro                   NaN       3         NaN  ...          4.0  bruh   \nbrother               1.0       7         NaN  ...          4.0  bruh   \nbruh                  NaN       4         1.0  ...          4.0  bruh   \nbruhhh                NaN       6         1.0  ...          4.0  bruh   \n...                   ...     ...         ...  ...          ...   ...   \noutcrop's             1.0       9         1.0  ...          3.0   out   \noutcropped            1.0      10         1.0  ...          3.0   out   \noutcropping           1.0      11         1.0  ...          3.0   out   \noutcropping's         1.0      13         1.0  ...          3.0   out   \noutcroppings          1.0      12         1.0  ...          3.0   out   \n\n                   prev  next tok_id     gold correct  wiki_uni wiki_bi_prev  \\\nbreh           @cdutra5   get      0  brother   False         9          0.0   \nbro            @cdutra5   get      0  brother   False      1121          0.0   \nbrother        @cdutra5   get      0  brother    True    269718          0.0   \nbruh           @cdutra5   get      0  brother   False        16          0.0   \nbruhhh         @cdutra5   get      0  brother   False         1          0.0   \n...                 ...   ...    ...      ...     ...       ...          ...   \noutcrop's           get    yo      2      out   False         8          0.0   \noutcropped          get    yo      2      out   False        48          0.0   \noutcropping         get    yo      2      out   False       829          0.0   \noutcropping's       get    yo      2      out   False         1          0.0   \noutcroppings        get    yo      2      out   False       516          0.0   \n\n               wiki_bi_next  \nbreh               0.000000  \nbro                0.000000  \nbrother            0.000043  \nbruh               0.000000  \nbruhhh             0.000000  \n...                     ...  \noutcrop's          0.000000  \noutcropped         0.000000  \noutcropping        0.000000  \noutcropping's      0.000000  \noutcroppings       0.000000  \n\n[100 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>...</th>\n      <th>orig_length</th>\n      <th>raw</th>\n      <th>prev</th>\n      <th>next</th>\n      <th>tok_id</th>\n      <th>gold</th>\n      <th>correct</th>\n      <th>wiki_uni</th>\n      <th>wiki_bi_prev</th>\n      <th>wiki_bi_next</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>breh</th>\n      <td>0.881024</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>@cdutra5</td>\n      <td>get</td>\n      <td>0</td>\n      <td>brother</td>\n      <td>False</td>\n      <td>9</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>bro</th>\n      <td>0.873462</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>@cdutra5</td>\n      <td>get</td>\n      <td>0</td>\n      <td>brother</td>\n      <td>False</td>\n      <td>1121</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>brother</th>\n      <td>0.444352</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>26.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>@cdutra5</td>\n      <td>get</td>\n      <td>0</td>\n      <td>brother</td>\n      <td>True</td>\n      <td>269718</td>\n      <td>0.0</td>\n      <td>0.000043</td>\n    </tr>\n    <tr>\n      <th>bruh</th>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>@cdutra5</td>\n      <td>get</td>\n      <td>0</td>\n      <td>brother</td>\n      <td>False</td>\n      <td>16</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>bruhhh</th>\n      <td>0.887914</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>bruh</td>\n      <td>@cdutra5</td>\n      <td>get</td>\n      <td>0</td>\n      <td>brother</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>outcrop's</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>out</td>\n      <td>get</td>\n      <td>yo</td>\n      <td>2</td>\n      <td>out</td>\n      <td>False</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>outcropped</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>out</td>\n      <td>get</td>\n      <td>yo</td>\n      <td>2</td>\n      <td>out</td>\n      <td>False</td>\n      <td>48</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>outcropping</th>\n      <td>0.360041</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>11</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>out</td>\n      <td>get</td>\n      <td>yo</td>\n      <td>2</td>\n      <td>out</td>\n      <td>False</td>\n      <td>829</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>outcropping's</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>13</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>out</td>\n      <td>get</td>\n      <td>yo</td>\n      <td>2</td>\n      <td>out</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>outcroppings</th>\n      <td>0.381839</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>12</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>out</td>\n      <td>get</td>\n      <td>yo</td>\n      <td>2</td>\n      <td>out</td>\n      <td>False</td>\n      <td>516</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexnorm.generate_extract import process\n",
    "importlib.reload(process)\n",
    "test = dev[0:100].copy()\n",
    "\n",
    "process.add_ngram_orig_features(test, os.path.join(DATA_PATH, \"processed\"))\n",
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "from lexnorm.data.word_ngrams import counter_from_pickle\n",
    "\n",
    "wiki_unigram_counter = counter_from_pickle(\n",
    "        os.path.join(DATA_PATH, \"processed/wiki_unigram_counter.pickle\")\n",
    "    )\n",
    "wiki_bigram_counter = counter_from_pickle(\n",
    "    os.path.join(DATA_PATH, \"processed/wiki_bigram_counter.pickle\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/dev_processed_nocap_neighbours.txt\"), index_col=0, keep_default_na=False, na_values=\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prep_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mprep_test\u001B[49m(dev)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'prep_test' is not defined"
     ]
    }
   ],
   "source": [
    "prep_test(dev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import joblib\n",
    "clf = joblib.load(\"../models/rf.joblib\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.66313951e-01, 2.89970261e-03, 1.37841431e-01, 2.02185631e-01,\n       6.09071404e-05, 3.77073327e-01, 6.85489567e-03, 6.99705725e-03,\n       3.42001435e-02, 6.45510729e-03, 1.95442102e-02, 6.20882100e-03,\n       0.00000000e+00, 3.33648150e-02])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['cosine_to_orig', 'embeddings_rank', 'from_clipping',\n       'from_original_token', 'from_split', 'norms_seen',\n       'spellcheck_rank', 'in_lexicon', 'length', 'same_order',\n       'orig_norms_seen', 'orig_in_lexicon', 'orig_same_order',\n       'orig_length'], dtype=object)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_names_in_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from lexnorm.definitions import DATA_PATH\n",
    "dev = pd.read_csv(os.path.join(DATA_PATH, \"hpc/dev_processed_nocap_neighbours.txt\"), index_col=0, keep_default_na=False, na_values=\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "from lexnorm.models import random_forest\n",
    "from joblib import load\n",
    "importlib.reload(random_forest)\n",
    "clf = load(os.path.join(DATA_PATH, \"../models/rf.joblib\"))\n",
    "pred_probs = random_forest.predict_probs(clf, os.path.join(DATA_PATH, \"hpc/dev_processed_nocap.txt\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "        cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\nyou're        0.452694              NaN            NaN                  NaN   \nup            0.353898              NaN            NaN                  NaN   \ni             0.747761              NaN            NaN                  NaN   \nyou           0.776511              3.0            NaN                  NaN   \ncu            0.310109              NaN            NaN                  NaN   \n...                ...              ...            ...                  ...   \nyall          0.753364              7.0            NaN                  NaN   \nyoj           0.760222              6.0            NaN                  NaN   \nyoj           0.760222              6.0            NaN                  NaN   \nuou           0.775654              4.0            NaN                  NaN   \nyou're        0.452694              NaN            NaN                  NaN   \n\n        from_split  norms_seen  spellcheck_rank  in_lexicon  length  \\\nyou're         NaN         2.0              NaN         1.0       6   \nup             NaN         NaN              8.0         1.0       2   \ni              NaN         NaN              2.0         1.0       1   \nyou            NaN       266.0              NaN         1.0       3   \ncu             NaN         NaN              5.0         1.0       2   \n...            ...         ...              ...         ...     ...   \nyall           NaN         NaN              NaN         NaN       4   \nyoj            NaN         NaN              NaN         NaN       3   \nyoj            NaN         NaN              NaN         NaN       3   \nuou            NaN         NaN              NaN         NaN       3   \nyou're         NaN         2.0              NaN         1.0       6   \n\n        same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\nyou're         1.0              2.0              NaN              1.0   \nup             1.0              2.0              NaN              1.0   \ni              NaN              2.0              NaN              1.0   \nyou            1.0              2.0              NaN              1.0   \ncu             1.0              2.0              NaN              1.0   \n...            ...              ...              ...              ...   \nyall           NaN              2.0              NaN              1.0   \nyoj            NaN              2.0              NaN              1.0   \nyoj            NaN              2.0              NaN              1.0   \nuou            1.0              2.0              NaN              1.0   \nyou're         1.0              2.0              NaN              1.0   \n\n        orig_length raw  process  tweet  tok     probs  \nyou're          1.0   u       14      2    4  0.645051  \nup              1.0   u       16      8   20  0.153187  \ni               1.0   u       29      0   13  0.230261  \nyou             1.0   u       55      4   10  0.837055  \ncu              1.0   u       39      6    7  0.153187  \n...             ...  ..      ...    ...  ...       ...  \nyall            1.0   u       19      8   13  0.233204  \nyoj             1.0   u       16      8   28  0.229051  \nyoj             1.0   u       49      6    1  0.229051  \nuou             1.0   u        5      9   10  0.304017  \nyou're          1.0   u       26      4    8  0.645051  \n\n[1240 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>raw</th>\n      <th>process</th>\n      <th>tweet</th>\n      <th>tok</th>\n      <th>probs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>you're</th>\n      <td>0.452694</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>u</td>\n      <td>14</td>\n      <td>2</td>\n      <td>4</td>\n      <td>0.645051</td>\n    </tr>\n    <tr>\n      <th>up</th>\n      <td>0.353898</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>u</td>\n      <td>16</td>\n      <td>8</td>\n      <td>20</td>\n      <td>0.153187</td>\n    </tr>\n    <tr>\n      <th>i</th>\n      <td>0.747761</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>u</td>\n      <td>29</td>\n      <td>0</td>\n      <td>13</td>\n      <td>0.230261</td>\n    </tr>\n    <tr>\n      <th>you</th>\n      <td>0.776511</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>266.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>u</td>\n      <td>55</td>\n      <td>4</td>\n      <td>10</td>\n      <td>0.837055</td>\n    </tr>\n    <tr>\n      <th>cu</th>\n      <td>0.310109</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>u</td>\n      <td>39</td>\n      <td>6</td>\n      <td>7</td>\n      <td>0.153187</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>yall</th>\n      <td>0.753364</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>u</td>\n      <td>19</td>\n      <td>8</td>\n      <td>13</td>\n      <td>0.233204</td>\n    </tr>\n    <tr>\n      <th>yoj</th>\n      <td>0.760222</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>u</td>\n      <td>16</td>\n      <td>8</td>\n      <td>28</td>\n      <td>0.229051</td>\n    </tr>\n    <tr>\n      <th>yoj</th>\n      <td>0.760222</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>u</td>\n      <td>49</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0.229051</td>\n    </tr>\n    <tr>\n      <th>uou</th>\n      <td>0.775654</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>u</td>\n      <td>5</td>\n      <td>9</td>\n      <td>10</td>\n      <td>0.304017</td>\n    </tr>\n    <tr>\n      <th>you're</th>\n      <td>0.452694</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>u</td>\n      <td>26</td>\n      <td>4</td>\n      <td>8</td>\n      <td>0.645051</td>\n    </tr>\n  </tbody>\n</table>\n<p>1240 rows × 19 columns</p>\n</div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs.loc[pred_probs.raw == \"u\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# fig = plt.figure(figsize=(15, 10))\n",
    "clf = load(os.path.join(DATA_PATH, \"../models/rf.joblib\"))\n",
    "clf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- frac_norms_seen <= 0.488\n",
      "|   |--- from_original_token <= 0.500\n",
      "|   |   |--- norms_seen_orig <= 40.500\n",
      "|   |   |   |--- in_feature_lex_orig <= 0.500\n",
      "|   |   |   |   |--- frac_norms_seen <= 0.134\n",
      "|   |   |   |   |   |--- wiki_bi_cand_next <= 0.274\n",
      "|   |   |   |   |   |   |--- norms_seen <= 0.500\n",
      "|   |   |   |   |   |   |   |--- weights: [148301.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- norms_seen >  0.500\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.002\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig <= 0.006\n",
      "|   |   |   |   |   |   |   |   |   |--- frac_norms_seen_orig <= 0.071\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [377.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- frac_norms_seen_orig >  0.071\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig >  0.006\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [8.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.002\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- norms_seen_orig <= 19.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_uni_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [4.000, 3.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_uni_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |--- norms_seen_orig >  19.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [5.000, 5.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [7.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- frac_norms_seen <= 0.030\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.052\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.052\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [6.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- frac_norms_seen >  0.030\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand <= 0.022\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [6.000, 8.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand >  0.022\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [11.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |--- wiki_bi_cand_next >  0.274\n",
      "|   |   |   |   |   |   |--- weights: [6.000, 1.000] class: 0.0\n",
      "|   |   |   |   |--- frac_norms_seen >  0.134\n",
      "|   |   |   |   |   |--- wiki_bi_prev_cand <= 0.044\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.005\n",
      "|   |   |   |   |   |   |   |--- frac_length <= 3.167\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- from_split <= 0.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |--- from_split >  0.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [7.000, 4.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- frac_norms_seen_orig <= 0.677\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.002\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.002\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [7.000, 4.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- frac_norms_seen_orig >  0.677\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [66.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- frac_length >  3.167\n",
      "|   |   |   |   |   |   |   |   |--- spellcheck_score <= -19.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [9.000, 4.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- spellcheck_score >  -19.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [7.000, 6.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next >  0.005\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.011\n",
      "|   |   |   |   |   |   |   |   |--- frac_length <= 1.583\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [6.000, 8.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- frac_length >  1.583\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_uni_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 32.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [1.000, 6.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_uni_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [4.000, 3.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.011\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [4.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [14.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |--- wiki_bi_prev_cand >  0.044\n",
      "|   |   |   |   |   |   |--- frac_norms_seen_orig <= 0.563\n",
      "|   |   |   |   |   |   |   |--- weights: [0.000, 10.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- frac_norms_seen_orig >  0.563\n",
      "|   |   |   |   |   |   |   |--- weights: [4.000, 8.000] class: 1.0\n",
      "|   |   |   |--- in_feature_lex_orig >  0.500\n",
      "|   |   |   |   |--- twitter_bi_cand_next <= 0.011\n",
      "|   |   |   |   |   |--- wiki_bi_prev_cand <= 0.000\n",
      "|   |   |   |   |   |   |--- norms_seen <= 0.500\n",
      "|   |   |   |   |   |   |   |--- weights: [443902.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- norms_seen >  0.500\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [5.000, 3.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [8.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [46.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [6.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |--- wiki_bi_prev_cand >  0.000\n",
      "|   |   |   |   |   |   |--- cosine_to_orig <= 0.884\n",
      "|   |   |   |   |   |   |   |--- twitter_uni_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen <= 0.500\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [7079.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen >  0.500\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [13.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [10.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- twitter_uni_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.023\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [136.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.023\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.007\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [21.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.007\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [5.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- cosine_to_orig >  0.884\n",
      "|   |   |   |   |   |   |   |--- length_orig <= 4.500\n",
      "|   |   |   |   |   |   |   |   |--- wiki_uni_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_uni_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [28.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_uni_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [6.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- wiki_uni_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [139.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- length_orig >  4.500\n",
      "|   |   |   |   |   |   |   |   |--- weights: [261.000, 0.000] class: 0.0\n",
      "|   |   |   |   |--- twitter_bi_cand_next >  0.011\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next <= 0.011\n",
      "|   |   |   |   |   |   |--- weights: [6.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next >  0.011\n",
      "|   |   |   |   |   |   |--- norms_seen <= 0.500\n",
      "|   |   |   |   |   |   |   |--- weights: [1921.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- norms_seen >  0.500\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.004\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_cand_next_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [8.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_cand_next_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [11.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.004\n",
      "|   |   |   |   |   |   |   |   |--- weights: [3.000, 5.000] class: 1.0\n",
      "|   |   |--- norms_seen_orig >  40.500\n",
      "|   |   |   |--- from_clipping <= 0.500\n",
      "|   |   |   |   |--- twitter_bi_cand_next <= 0.100\n",
      "|   |   |   |   |   |--- norms_seen <= 0.500\n",
      "|   |   |   |   |   |   |--- weights: [152642.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |--- norms_seen >  0.500\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.019\n",
      "|   |   |   |   |   |   |   |--- wiki_uni_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.001\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [69.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.001\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [4.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [22.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- wiki_uni_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- same_order <= 0.500\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.007\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [151.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.007\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [6.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- same_order >  0.500\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next_orig <= 0.001\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next_orig <= 0.001\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [292.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next_orig >  0.001\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [6.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next_orig >  0.001\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [1054.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next >  0.019\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.050\n",
      "|   |   |   |   |   |   |   |   |--- weights: [5.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.050\n",
      "|   |   |   |   |   |   |   |   |--- weights: [28.000, 0.000] class: 0.0\n",
      "|   |   |   |   |--- twitter_bi_cand_next >  0.100\n",
      "|   |   |   |   |   |--- same_order <= 0.500\n",
      "|   |   |   |   |   |   |--- weights: [384.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |--- same_order >  0.500\n",
      "|   |   |   |   |   |   |--- twitter_uni_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.001\n",
      "|   |   |   |   |   |   |   |   |--- weights: [14.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.001\n",
      "|   |   |   |   |   |   |   |   |--- weights: [8.000, 3.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- twitter_uni_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |--- weights: [68.000, 0.000] class: 0.0\n",
      "|   |   |   |--- from_clipping >  0.500\n",
      "|   |   |   |   |--- weights: [727993.000, 0.000] class: 0.0\n",
      "|   |--- from_original_token >  0.500\n",
      "|   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |--- frac_norms_seen <= 0.303\n",
      "|   |   |   |   |--- norms_seen <= 0.500\n",
      "|   |   |   |   |   |--- weights: [2206.000, 0.000] class: 0.0\n",
      "|   |   |   |   |--- norms_seen >  0.500\n",
      "|   |   |   |   |   |--- norms_seen <= 2.500\n",
      "|   |   |   |   |   |   |--- length_orig <= 1.500\n",
      "|   |   |   |   |   |   |   |--- weights: [224.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- length_orig >  1.500\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_prev_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- norms_seen <= 1.500\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- norms_seen >  1.500\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [13.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [23.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_prev_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- weights: [7.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |--- norms_seen >  2.500\n",
      "|   |   |   |   |   |   |--- length_orig <= 1.500\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [6.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [32.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- weights: [11.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- length_orig >  1.500\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.004\n",
      "|   |   |   |   |   |   |   |   |--- frac_norms_seen_orig <= 0.163\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [6.000, 3.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [31.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- frac_norms_seen_orig >  0.163\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [21.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.004\n",
      "|   |   |   |   |   |   |   |   |--- weights: [3.000, 3.000] class: 0.0\n",
      "|   |   |   |--- frac_norms_seen >  0.303\n",
      "|   |   |   |   |--- length <= 2.500\n",
      "|   |   |   |   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen <= 5.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [5.000, 4.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen >  5.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.000, 9.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- weights: [9.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- weights: [6.000, 5.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen <= 11.000\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_uni_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [9.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_uni_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [12.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [8.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen >  11.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [19.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |--- weights: [2.000, 7.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |--- weights: [6.000, 2.000] class: 0.0\n",
      "|   |   |   |   |--- length >  2.500\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |--- weights: [3.000, 9.000] class: 1.0\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |--- weights: [7.000, 4.000] class: 0.0\n",
      "|   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |--- twitter_bi_cand_next_orig <= 0.001\n",
      "|   |   |   |   |--- frac_norms_seen <= 0.065\n",
      "|   |   |   |   |   |--- weights: [14.000, 0.000] class: 0.0\n",
      "|   |   |   |   |--- frac_norms_seen >  0.065\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.000\n",
      "|   |   |   |   |   |   |--- frac_norms_seen <= 0.237\n",
      "|   |   |   |   |   |   |   |--- weights: [1.000, 5.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- frac_norms_seen >  0.237\n",
      "|   |   |   |   |   |   |   |--- weights: [0.000, 13.000] class: 1.0\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.000\n",
      "|   |   |   |   |   |   |--- weights: [3.000, 5.000] class: 1.0\n",
      "|   |   |   |--- twitter_bi_cand_next_orig >  0.001\n",
      "|   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |--- wiki_bi_cand_next_orig <= 0.004\n",
      "|   |   |   |   |   |   |--- weights: [15.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |--- wiki_bi_cand_next_orig >  0.004\n",
      "|   |   |   |   |   |   |--- weights: [8.000, 3.000] class: 0.0\n",
      "|   |   |   |   |--- twitter_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.004\n",
      "|   |   |   |   |   |   |--- wiki_bi_cand_next_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |--- weights: [24.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- wiki_bi_cand_next_orig >  0.000\n",
      "|   |   |   |   |   |   |   |--- weights: [6.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.004\n",
      "|   |   |   |   |   |   |--- weights: [118.000, 0.000] class: 0.0\n",
      "|--- frac_norms_seen >  0.488\n",
      "|   |--- frac_norms_seen <= 0.789\n",
      "|   |   |--- twitter_bi_prev_cand <= 0.010\n",
      "|   |   |   |--- norms_seen_orig <= 30.000\n",
      "|   |   |   |   |--- frac_norms_seen <= 0.618\n",
      "|   |   |   |   |   |--- frac_length <= 2.583\n",
      "|   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- twitter_uni_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- norms_seen_orig <= 5.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 10\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [4.000, 9.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- norms_seen_orig >  5.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [6.000, 12.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_uni_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [7.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [1.000, 11.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 11.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- frac_norms_seen <= 0.513\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- frac_norms_seen >  0.513\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [3.000, 9.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |--- wiki_uni_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- twitter_uni_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [6.000, 4.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_uni_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [9.000, 7.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- wiki_uni_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [10.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [8.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |--- frac_length >  2.583\n",
      "|   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |--- weights: [5.000, 9.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |--- spellcheck_score <= -10.000\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen_orig <= 7.500\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [5.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen_orig >  7.500\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [19.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- spellcheck_score >  -10.000\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [10.000, 3.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [6.000, 5.000] class: 0.0\n",
      "|   |   |   |   |--- frac_norms_seen >  0.618\n",
      "|   |   |   |   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |--- frac_length <= 1.134\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- length <= 2.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 16.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- length >  2.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- length_orig <= 6.500\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [4.000, 6.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- length_orig >  6.500\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [2.000, 12.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.001\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [3.000, 4.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- frac_length >  1.134\n",
      "|   |   |   |   |   |   |   |   |--- frac_length <= 2.933\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [9.000, 4.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [2.000, 5.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- frac_length >  2.933\n",
      "|   |   |   |   |   |   |   |   |   |--- spellcheck_score <= -19.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- norms_seen_orig <= 2.500\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [5.000, 9.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- norms_seen_orig >  2.500\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [4.000, 4.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- spellcheck_score >  -19.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [3.000, 8.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.000\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.001\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- frac_norms_seen <= 0.701\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [12.000, 6.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- frac_norms_seen >  0.701\n",
      "|   |   |   |   |   |   |   |   |   |   |--- spellcheck_score <= 1004.500\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [8.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- spellcheck_score >  1004.500\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [10.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [2.000, 3.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.001\n",
      "|   |   |   |   |   |   |   |   |--- weights: [4.000, 9.000] class: 1.0\n",
      "|   |   |   |   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |--- spellcheck_score <= -10.500\n",
      "|   |   |   |   |   |   |   |--- weights: [4.000, 3.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- spellcheck_score >  -10.500\n",
      "|   |   |   |   |   |   |   |--- length <= 2.000\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [4.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [2.000, 11.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [2.000, 13.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- length >  2.000\n",
      "|   |   |   |   |   |   |   |   |--- frac_length <= 1.267\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [2.000, 12.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- frac_length >  1.267\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_uni_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [1.000, 11.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_uni_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 15.000] class: 1.0\n",
      "|   |   |   |--- norms_seen_orig >  30.000\n",
      "|   |   |   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |--- weights: [6.000, 11.000] class: 1.0\n",
      "|   |   |   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |--- weights: [0.000, 22.000] class: 1.0\n",
      "|   |   |--- twitter_bi_prev_cand >  0.010\n",
      "|   |   |   |--- twitter_bi_cand_next <= 0.004\n",
      "|   |   |   |   |--- wiki_bi_prev_cand_orig <= 0.001\n",
      "|   |   |   |   |   |--- wiki_bi_cand_next_orig <= 0.000\n",
      "|   |   |   |   |   |   |--- wiki_bi_prev_cand <= 0.007\n",
      "|   |   |   |   |   |   |   |--- twitter_uni_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- weights: [1.000, 7.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- twitter_uni_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen <= 13.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [3.000, 4.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen >  13.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [5.000, 3.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- wiki_bi_prev_cand >  0.007\n",
      "|   |   |   |   |   |   |   |--- weights: [6.000, 0.000] class: 0.0\n",
      "|   |   |   |   |   |--- wiki_bi_cand_next_orig >  0.000\n",
      "|   |   |   |   |   |   |--- weights: [10.000, 2.000] class: 0.0\n",
      "|   |   |   |   |--- wiki_bi_prev_cand_orig >  0.001\n",
      "|   |   |   |   |   |--- weights: [1.000, 9.000] class: 1.0\n",
      "|   |   |   |--- twitter_bi_cand_next >  0.004\n",
      "|   |   |   |   |--- length_orig <= 2.500\n",
      "|   |   |   |   |   |--- frac_norms_seen <= 0.618\n",
      "|   |   |   |   |   |   |--- weights: [0.000, 51.000] class: 1.0\n",
      "|   |   |   |   |   |--- frac_norms_seen >  0.618\n",
      "|   |   |   |   |   |   |--- frac_norms_seen <= 0.670\n",
      "|   |   |   |   |   |   |   |--- weights: [2.000, 8.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- frac_norms_seen >  0.670\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- wiki_uni_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [1.000, 6.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- wiki_uni_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.000, 12.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- weights: [0.000, 17.000] class: 1.0\n",
      "|   |   |   |   |--- length_orig >  2.500\n",
      "|   |   |   |   |   |--- weights: [2.000, 11.000] class: 1.0\n",
      "|   |--- frac_norms_seen >  0.789\n",
      "|   |   |--- cosine_to_orig <= 0.937\n",
      "|   |   |   |--- frac_norms_seen <= 0.913\n",
      "|   |   |   |   |--- norms_seen <= 6.500\n",
      "|   |   |   |   |   |--- weights: [0.000, 14.000] class: 1.0\n",
      "|   |   |   |   |--- norms_seen >  6.500\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.000\n",
      "|   |   |   |   |   |   |--- weights: [8.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.000\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.001\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.001\n",
      "|   |   |   |   |   |   |   |   |--- length_orig <= 2.500\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.032\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [1.000, 14.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.032\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [4.000, 4.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [1.000, 11.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 35.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- length_orig >  2.500\n",
      "|   |   |   |   |   |   |   |   |   |--- cosine_to_orig <= 0.424\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [1.000, 9.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- cosine_to_orig >  0.424\n",
      "|   |   |   |   |   |   |   |   |   |   |--- frac_norms_seen_orig <= 0.062\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [3.000, 3.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- frac_norms_seen_orig >  0.062\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.001\n",
      "|   |   |   |   |   |   |   |   |--- weights: [6.000, 4.000] class: 0.0\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.001\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- weights: [1.000, 7.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- weights: [0.000, 43.000] class: 1.0\n",
      "|   |   |   |--- frac_norms_seen >  0.913\n",
      "|   |   |   |   |--- from_embeddings <= 0.500\n",
      "|   |   |   |   |   |--- weights: [0.000, 1935.000] class: 1.0\n",
      "|   |   |   |   |--- from_embeddings >  0.500\n",
      "|   |   |   |   |   |--- frac_length <= 2.292\n",
      "|   |   |   |   |   |   |--- length <= 3.500\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.009\n",
      "|   |   |   |   |   |   |   |   |--- weights: [0.000, 147.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.009\n",
      "|   |   |   |   |   |   |   |   |--- weights: [2.000, 17.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- length >  3.500\n",
      "|   |   |   |   |   |   |   |--- weights: [0.000, 550.000] class: 1.0\n",
      "|   |   |   |   |   |--- frac_length >  2.292\n",
      "|   |   |   |   |   |   |--- wiki_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |--- frac_norms_seen_orig <= 0.045\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [2.000, 10.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [1.000, 5.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next_orig <= 0.001\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.013\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.013\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 57.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next_orig >  0.001\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [2.000, 9.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- frac_norms_seen_orig >  0.045\n",
      "|   |   |   |   |   |   |   |   |--- weights: [1.000, 9.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- wiki_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.004\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.012\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.000, 17.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.012\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [2.000, 10.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.004\n",
      "|   |   |   |   |   |   |   |   |--- weights: [0.000, 179.000] class: 1.0\n",
      "|   |   |--- cosine_to_orig >  0.937\n",
      "|   |   |   |--- wiki_bi_prev_cand <= 0.001\n",
      "|   |   |   |   |--- length <= 1.500\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.000\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.002\n",
      "|   |   |   |   |   |   |   |   |--- weights: [0.000, 31.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.002\n",
      "|   |   |   |   |   |   |   |   |--- weights: [1.000, 8.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- weights: [0.000, 14.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- weights: [9.000, 2.000] class: 0.0\n",
      "|   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.000\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.068\n",
      "|   |   |   |   |   |   |   |--- wiki_uni_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen_orig <= 10.500\n",
      "|   |   |   |   |   |   |   |   |   |--- norms_seen_orig <= 9.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 23.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- norms_seen_orig >  9.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [4.000, 6.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen_orig >  10.500\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.002\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 75.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.002\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.004\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [2.000, 3.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.004\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 26.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- wiki_uni_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen <= 256.500\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.000, 87.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen >  256.500\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 39.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand <= 0.034\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [2.000, 18.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand >  0.034\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 12.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.068\n",
      "|   |   |   |   |   |   |   |--- weights: [0.000, 430.000] class: 1.0\n",
      "|   |   |   |   |--- length >  1.500\n",
      "|   |   |   |   |   |--- frac_norms_seen <= 0.867\n",
      "|   |   |   |   |   |   |--- wiki_bi_prev_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |--- weights: [8.000, 8.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |--- twitter_uni_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig <= 0.005\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 10.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_prev_cand_orig >  0.005\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [2.000, 8.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_uni_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.000, 10.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- wiki_bi_prev_cand >  0.000\n",
      "|   |   |   |   |   |   |   |--- weights: [5.000, 1.000] class: 0.0\n",
      "|   |   |   |   |   |--- frac_norms_seen >  0.867\n",
      "|   |   |   |   |   |   |--- twitter_uni_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |--- length <= 2.500\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen <= 28.500\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.000, 672.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- norms_seen >  28.500\n",
      "|   |   |   |   |   |   |   |   |   |--- norms_seen <= 36.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [5.000, 16.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 53.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- norms_seen >  36.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 119.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- length >  2.500\n",
      "|   |   |   |   |   |   |   |   |--- twitter_uni_cand <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- length_orig <= 5.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.153\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.153\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |--- length_orig >  5.500\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 5457.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_uni_cand >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.000, 1953.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- twitter_uni_cand >  0.000\n",
      "|   |   |   |   |   |   |   |--- frac_norms_seen <= 0.987\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- norms_seen <= 100.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- wiki_bi_prev_cand_orig >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 12.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- norms_seen >  100.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig <= 0.001\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [4.000, 3.000] class: 0.0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next_orig >  0.001\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 16.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.000, 78.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- frac_norms_seen >  0.987\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.002\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.002\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 302.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.002\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [1.000, 7.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.002\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.000, 2243.000] class: 1.0\n",
      "|   |   |   |--- wiki_bi_prev_cand >  0.001\n",
      "|   |   |   |   |--- norms_seen <= 24.500\n",
      "|   |   |   |   |   |--- frac_norms_seen_orig <= 0.980\n",
      "|   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.001\n",
      "|   |   |   |   |   |   |   |--- norms_seen <= 16.500\n",
      "|   |   |   |   |   |   |   |   |--- weights: [0.000, 12.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- norms_seen >  16.500\n",
      "|   |   |   |   |   |   |   |   |--- weights: [1.000, 6.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- wiki_bi_cand_next >  0.001\n",
      "|   |   |   |   |   |   |   |--- weights: [0.000, 24.000] class: 1.0\n",
      "|   |   |   |   |   |--- frac_norms_seen_orig >  0.980\n",
      "|   |   |   |   |   |   |--- length <= 4.500\n",
      "|   |   |   |   |   |   |   |--- weights: [0.000, 860.000] class: 1.0\n",
      "|   |   |   |   |   |   |--- length >  4.500\n",
      "|   |   |   |   |   |   |   |--- norms_seen <= 8.500\n",
      "|   |   |   |   |   |   |   |   |--- weights: [0.000, 978.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |--- norms_seen >  8.500\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next <= 0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [0.000, 34.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |   |--- wiki_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |   |--- weights: [2.000, 3.000] class: 1.0\n",
      "|   |   |   |   |   |   |   |   |--- twitter_bi_cand_next >  0.000\n",
      "|   |   |   |   |   |   |   |   |   |--- weights: [0.000, 293.000] class: 1.0\n",
      "|   |   |   |   |--- norms_seen >  24.500\n",
      "|   |   |   |   |   |--- weights: [0.000, 7363.000] class: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_text\n",
    "from joblib import load\n",
    "import os\n",
    "from lexnorm.definitions import DATA_PATH\n",
    "clf = load(os.path.join(DATA_PATH, \"../models/rf.joblib\"))\n",
    "print(export_text(clf.estimators_[0], spacing=3, decimals=3, show_weights=True, feature_names=clf.feature_names_in_.tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T18:48:01.963012Z",
     "end_time": "2023-05-05T18:48:03.329883Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', 'apply', 'capacity', 'children_left', 'children_right', 'compute_feature_importances', 'compute_partial_dependence', 'decision_path', 'feature', 'impurity', 'max_depth', 'max_n_classes', 'n_classes', 'n_features', 'n_leaves', 'n_node_samples', 'n_outputs', 'node_count', 'predict', 'threshold', 'value', 'weighted_n_node_samples']\n",
      "281\n",
      "20\n",
      "[962635 941573 939611 381696  95183  94909  94904  93946    958    549\n",
      "    542    276     46     37      9    230    266    233    132     66\n",
      "     35     31      6     25     66     61     53     24      9     15\n",
      "     29      8      5    101     33     24      9      7    409    355\n",
      "    345      5    340     46     38      8    294    288     99     94\n",
      "      5    189      6     10      5      5     54     38     32     20\n",
      "     12      5      7      6     16      9      7      5    274    259\n",
      "    206    190     90     83     62     41     24     19      5     17\n",
      "      9      8     21      5     16     21     15      9      6      6\n",
      "      7    100     57     50     36     30      6     14      5      9\n",
      "      7     43     16      8      8     53     38      9     29     24\n",
      "     19      5      5     15      6      9     15      6      9 286513\n",
      " 285280 280408 280361     47     10      5      5     37     32      5\n",
      "   4872   4585   4487   4468     19     11      8     98     82     16\n",
      "     11      5    287    114     24     18      6     90    173   1233\n",
      "      5   1228   1211     17     11      6      5      6 557915  97612\n",
      "  97313  96287   1026   1006     67     48     43      5     19    939\n",
      "    100     95      5    839    190    185      5    649     20      5\n",
      "     15    299    244     55     13      8      5     42 460303   1962\n",
      "   1806   1720   1411    309    239    146     93     88     73     63\n",
      "     35     23     12      5      7     28     20     11      9      8\n",
      "     10     15      5     70     31     23      6     17      8     39\n",
      "     34     23      5     18     11      5     86     70     60     20\n",
      "     13      7      6      7     40      6     34     22     16      5\n",
      "     11      6     12     10      5      5     16      7      9    156\n",
      "     26      9     17     12      5      7      5    130     20     13\n",
      "      7    110     22     17      5     88  21062    508    399    374\n",
      "    214    176    146    107    102     94     87     82     76     11\n",
      "      6      5     65     54     22     16      6     32     26     19\n",
      "      8     11      6      5      7      6     11      6      5      6\n",
      "      5      7      8      5     39      7     32      7     25     16\n",
      "      5     11      5      6      9     30     16      6     10     14\n",
      "      9      5     38      9     29     15      5     10     14      9\n",
      "      5    160    104     65     28     23      6     17      9      8\n",
      "      5     37     15      9      6     22     14      9      5      8\n",
      "     39     32     27     11     16      9      7      5      7     56\n",
      "      5     51     23     14      5      9      9     28     10     18\n",
      "      8     10     25     10     15    109     33     27     21     16\n",
      "      6     10      5      5      5      6      6     76     67     34\n",
      "     33      8     25     13      7      6     12      9  20554   2045\n",
      "    120      8    112      6    106     73     68     43     16     10\n",
      "      6     27      8     19     25      7     18      5     13      8\n",
      "      5      5     33      5     28   1925   1253    672    446    108\n",
      "     94     14    338    226     94     87     14      9      5     73\n",
      "     67     30     25      5     37      6      7    132     20     13\n",
      "      7    112  18509  12432    509     39     25     20      5     14\n",
      "      9      5    470    197     92     22     17      5     70     51\n",
      "     19      5     14    105     58     47     25     22     14      8\n",
      "    273  11923     30     25      8     17     12      6      6      5\n",
      "      5  11893  10198    563    444    119     42     10     32     77\n",
      "   9635   8421   4932   4724     25     19     13      8      5      6\n",
      "      6   4699   4474    225      5    220    208    196    176     20\n",
      "      5     15     12      7      5   3489   1214   1695     93     38\n",
      "     21     10      5      5     11     17      5     12     55   1602\n",
      "    184    179      5   1418   6077   1434     29     15     10      5\n",
      "     14   1405    564    841    621    220     24     19      5    196\n",
      "   4643]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 2000x2000 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import sklearn.tree\n",
    "\n",
    "print(dir(clf.estimators_[0].tree_))\n",
    "print(clf.estimators_[0].tree_.n_leaves)\n",
    "print(clf.estimators_[0].tree_.max_depth)\n",
    "print(clf.estimators_[0].tree_.n_node_samples)\n",
    "plt.figure(figsize=(20,20))\n",
    "sklearn.tree.plot_tree(clf.estimators_[0], max_depth=2, filled=True, proportion=True, rounded=True, class_names=[\"incorrect\", \"correct\"], feature_names=clf.feature_names_in_.tolist())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T19:09:52.296782Z",
     "end_time": "2023-05-05T19:09:53.405835Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'test.png'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf.estimators_[0],\n",
    "                  feature_names=clf.feature_names_in_.tolist(),\n",
    "                  class_names=[\"incorrect\", \"correct\"],\n",
    "                                proportion=True,\n",
    "                  filled=True, rounded=True,\n",
    "                  special_characters=True,\n",
    "                   out_file=None,\n",
    "                           )\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.format = \"png\"\n",
    "graph.render(\"test\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['cosine_to_orig', 'embeddings_rank', 'from_clipping',\n       'from_original_token', 'from_split', 'norms_seen',\n       'spellcheck_rank', 'in_lexicon', 'length', 'same_order',\n       'orig_norms_seen', 'orig_in_lexicon', 'orig_same_order',\n       'orig_length', 'twitter_uni', 'twitter_bi_prev', 'twitter_bi_next',\n       'wiki_uni', 'wiki_bi_prev', 'wiki_bi_next'], dtype=object)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_names_in_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'lexnorm.models.random_forest' from '/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/src/lexnorm/models/random_forest.py'>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensuring shuffling data works\n",
    "from lexnorm.models import normalise\n",
    "from lexnorm.models import random_forest\n",
    "import importlib\n",
    "importlib.reload(normalise)\n",
    "importlib.reload(random_forest)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting candidates with (joint) highest probabilities per token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 200 out of 200 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "clf = load(os.path.join(DATA_PATH, \"../models/rf.joblib\"))\n",
    "probs = random_forest.predict_probs(clf, os.path.join(DATA_PATH, \"hpc/dev_ngrams.txt\"))\n",
    "max_cands = probs.loc[probs.groupby([\"process\", \"tweet\", \"tok\"])[\"probs\"].transform(max) == probs.probs]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Highest probability candidates with probabilities below 0.5 not from original token - perhaps keep original token in this case?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "             cosine_to_orig  embeddings_rank  from_clipping  \\\nthames link             NaN              NaN            NaN   \nprowl ing               NaN              NaN            NaN   \nya                 0.465115              NaN            NaN   \nopen               0.209676              NaN            NaN   \nthemselves         0.827675              NaN            NaN   \n...                     ...              ...            ...   \ncan                0.228512              NaN            NaN   \nnot                0.173422              NaN            NaN   \nclaret a                NaN              NaN            NaN   \nkeep               0.752860              2.0            NaN   \nu                  0.612868              NaN            NaN   \n\n             from_original_token  from_split  norms_seen  spellcheck_rank  \\\nthames link                  NaN         1.0         NaN              NaN   \nprowl ing                    NaN         1.0         NaN              NaN   \nya                           NaN         NaN         NaN              3.0   \nopen                         NaN         NaN         NaN              6.0   \nthemselves                   NaN         NaN         NaN              3.0   \n...                          ...         ...         ...              ...   \ncan                          NaN         NaN         NaN             15.0   \nnot                          NaN         NaN         NaN             15.0   \nclaret a                     NaN         1.0         NaN              3.0   \nkeep                         NaN         NaN         NaN              NaN   \nu                            NaN         NaN         NaN              4.0   \n\n             in_lexicon  length  same_order  ...  process  tweet  tok  \\\nthames link         NaN      11         1.0  ...        2      0    6   \nprowl ing           NaN       9         1.0  ...       10      8    8   \nya                  NaN       2         NaN  ...       45      0    3   \nopen                1.0       4         NaN  ...        6      9    8   \nthemselves          1.0      10         NaN  ...       20      0   16   \n...                 ...     ...         ...  ...      ...    ...  ...   \ncan                 1.0       3         NaN  ...       27      6    2   \nnot                 1.0       3         NaN  ...       10      8   16   \nclaret a            NaN       8         1.0  ...       26      3   11   \nkeep                1.0       4         NaN  ...       38      3   19   \nu                   NaN       1         NaN  ...       26      2    7   \n\n             twitter_uni twitter_bi_prev twitter_bi_next wiki_uni  \\\nthames link            1        0.000000    0.000000e+00        1   \nprowl ing              1        0.000000    0.000000e+00        1   \nya              13065864        0.000222    1.025573e-05     6849   \nopen             6172092        0.000004    3.507725e-04   469082   \nthemselves       1362218        0.000062    2.422520e-05   177818   \n...                  ...             ...             ...      ...   \ncan             71160951        0.000198    1.545792e-07  1938264   \nnot            100452619        0.000356    1.124908e-06  4174421   \nclaret a               1        0.000000    0.000000e+00        1   \nkeep            16447532        0.013715    4.985550e-05   172136   \nu               54891268        0.000031    6.019172e-05    24958   \n\n             wiki_bi_prev  wiki_bi_next     probs  \nthames link      0.000000      0.000000  0.222608  \nprowl ing        0.000000      0.000000  0.191523  \nya               0.000730      0.000584  0.171454  \nopen             0.000000      0.000006  0.187157  \nthemselves       0.000000      0.000000  0.222408  \n...                   ...           ...       ...  \ncan              0.000000      0.000000  0.195511  \nnot              0.000270      0.000000  0.195336  \nclaret a         0.000000      0.000000  0.214866  \nkeep             0.008243      0.000000  0.195492  \nu                0.000000      0.000000  0.204574  \n\n[436 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>...</th>\n      <th>process</th>\n      <th>tweet</th>\n      <th>tok</th>\n      <th>twitter_uni</th>\n      <th>twitter_bi_prev</th>\n      <th>twitter_bi_next</th>\n      <th>wiki_uni</th>\n      <th>wiki_bi_prev</th>\n      <th>wiki_bi_next</th>\n      <th>probs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>thames link</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.222608</td>\n    </tr>\n    <tr>\n      <th>prowl ing</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>10</td>\n      <td>8</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.191523</td>\n    </tr>\n    <tr>\n      <th>ya</th>\n      <td>0.465115</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>45</td>\n      <td>0</td>\n      <td>3</td>\n      <td>13065864</td>\n      <td>0.000222</td>\n      <td>1.025573e-05</td>\n      <td>6849</td>\n      <td>0.000730</td>\n      <td>0.000584</td>\n      <td>0.171454</td>\n    </tr>\n    <tr>\n      <th>open</th>\n      <td>0.209676</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>6</td>\n      <td>9</td>\n      <td>8</td>\n      <td>6172092</td>\n      <td>0.000004</td>\n      <td>3.507725e-04</td>\n      <td>469082</td>\n      <td>0.000000</td>\n      <td>0.000006</td>\n      <td>0.187157</td>\n    </tr>\n    <tr>\n      <th>themselves</th>\n      <td>0.827675</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>20</td>\n      <td>0</td>\n      <td>16</td>\n      <td>1362218</td>\n      <td>0.000062</td>\n      <td>2.422520e-05</td>\n      <td>177818</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.222408</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>can</th>\n      <td>0.228512</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>27</td>\n      <td>6</td>\n      <td>2</td>\n      <td>71160951</td>\n      <td>0.000198</td>\n      <td>1.545792e-07</td>\n      <td>1938264</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.195511</td>\n    </tr>\n    <tr>\n      <th>not</th>\n      <td>0.173422</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>10</td>\n      <td>8</td>\n      <td>16</td>\n      <td>100452619</td>\n      <td>0.000356</td>\n      <td>1.124908e-06</td>\n      <td>4174421</td>\n      <td>0.000270</td>\n      <td>0.000000</td>\n      <td>0.195336</td>\n    </tr>\n    <tr>\n      <th>claret a</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>26</td>\n      <td>3</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.214866</td>\n    </tr>\n    <tr>\n      <th>keep</th>\n      <td>0.752860</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>38</td>\n      <td>3</td>\n      <td>19</td>\n      <td>16447532</td>\n      <td>0.013715</td>\n      <td>4.985550e-05</td>\n      <td>172136</td>\n      <td>0.008243</td>\n      <td>0.000000</td>\n      <td>0.195492</td>\n    </tr>\n    <tr>\n      <th>u</th>\n      <td>0.612868</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>26</td>\n      <td>2</td>\n      <td>7</td>\n      <td>54891268</td>\n      <td>0.000031</td>\n      <td>6.019172e-05</td>\n      <td>24958</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.204574</td>\n    </tr>\n  </tbody>\n</table>\n<p>436 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cands.loc[(max_cands.probs < 0.5) & (max_cands.from_original_token != 1)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linking gold tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "from lexnorm.data import normEval\n",
    "from lexnorm.generate_extract.filtering import is_eligible\n",
    "from lexnorm.generate_extract import process\n",
    "importlib.reload(process)\n",
    "max_cands = process.create_index(max_cands)\n",
    "max_cands = process.link_to_gold(max_cands, os.path.join(DATA_PATH, \"raw/dev.norm\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at how many non-raw candidates with highest probability are correct if probability below or above 0.5. Just from this random example, >=0.5: 371 correct, 24 incorrect. <0.5: 65 correct, 371 incorrect. In 332 of the latter case, the raw token was correct - seems to motivate being conservative!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "            cosine_to_orig  embeddings_rank  from_clipping  \\\nma nan                 NaN              NaN            NaN   \nmini i                 NaN              NaN            NaN   \nskills            0.834030              2.0            1.0   \nwild ing               NaN              NaN            NaN   \nyou               0.346203              NaN            NaN   \n...                    ...              ...            ...   \nsee               0.203486              NaN            NaN   \nrange ra               NaN              NaN            NaN   \nheart             0.760539              NaN            NaN   \nhis               0.234643              NaN            NaN   \nsouth bank             NaN              NaN            NaN   \n\n            from_original_token  from_split  norms_seen  spellcheck_rank  \\\nma nan                      NaN         1.0         NaN              NaN   \nmini i                      NaN         1.0         NaN              5.0   \nskills                      NaN         NaN         NaN              5.0   \nwild ing                    NaN         1.0         NaN              NaN   \nyou                         NaN         NaN         NaN              5.0   \n...                         ...         ...         ...              ...   \nsee                         NaN         NaN         NaN              1.0   \nrange ra                    NaN         1.0         NaN              NaN   \nheart                       NaN         NaN         NaN              4.0   \nhis                         NaN         NaN         NaN              4.0   \nsouth bank                  NaN         1.0         NaN              1.0   \n\n            in_lexicon  length  same_order  ...                    next  \\\nma nan             NaN       6         1.0  ...                    dund   \nmini i             NaN       6         1.0  ...                     aav   \nskills             1.0       6         1.0  ...                   level   \nwild ing           NaN       8         1.0  ...                    last   \nyou                1.0       3         NaN  ...                      :d   \n...                ...     ...         ...  ...                     ...   \nsee                1.0       3         NaN  ...                      to   \nrange ra           NaN       8         1.0  ...                  hearts   \nheart              1.0       5         NaN  ...                    hibs   \nhis                1.0       3         NaN  ...                 falkirk   \nsouth bank         NaN      10         1.0  ...  http://t.co/0v8cfj6sog   \n\n            twitter_uni  twitter_bi_prev  twitter_bi_next  wiki_uni  \\\nma nan                1         0.000000     0.000000e+00         1   \nmini i                1         0.000000     0.000000e+00         1   \nskills           738084         0.000832     5.256854e-04     72373   \nwild ing              1         0.000000     0.000000e+00         1   \nyou           374989834         0.000000     2.131311e-04    431347   \n...                 ...              ...              ...       ...   \nsee            43600979         0.000001     6.337243e-04    323620   \nrange ra              1         0.000000     0.000000e+00         1   \nheart           7957991         0.000000     0.000000e+00    167538   \nhis            40429274         0.000003     2.968146e-07  11999277   \nsouth bank            1         0.000000     0.000000e+00         1   \n\n           wiki_bi_prev wiki_bi_next     probs  tok_id       gold  \nma nan         0.000000     0.000000  0.212320       6      manan  \nmini i         0.000000     0.000000  0.203984      12      minii  \nskills         0.000124     0.000193  0.227671      43      skill  \nwild ing       0.000000     0.000000  0.222099      71    wilding  \nyou            0.000000     0.000000  0.219711      74        yoh  \n...                 ...          ...       ...     ...        ...  \nsee            0.000000     0.004984  0.248927    6791        zee  \nrange ra       0.000000     0.000000  0.222099    6809    rangera  \nheart          0.000000     0.000000  0.220209    6810     hearts  \nhis            0.000000     0.000002  0.206385    6811       hibs  \nsouth bank     0.000000     0.000000  0.222382    6855  southbank  \n\n[332 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>...</th>\n      <th>next</th>\n      <th>twitter_uni</th>\n      <th>twitter_bi_prev</th>\n      <th>twitter_bi_next</th>\n      <th>wiki_uni</th>\n      <th>wiki_bi_prev</th>\n      <th>wiki_bi_next</th>\n      <th>probs</th>\n      <th>tok_id</th>\n      <th>gold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ma nan</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>dund</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.212320</td>\n      <td>6</td>\n      <td>manan</td>\n    </tr>\n    <tr>\n      <th>mini i</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>aav</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.203984</td>\n      <td>12</td>\n      <td>minii</td>\n    </tr>\n    <tr>\n      <th>skills</th>\n      <td>0.834030</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>6</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>level</td>\n      <td>738084</td>\n      <td>0.000832</td>\n      <td>5.256854e-04</td>\n      <td>72373</td>\n      <td>0.000124</td>\n      <td>0.000193</td>\n      <td>0.227671</td>\n      <td>43</td>\n      <td>skill</td>\n    </tr>\n    <tr>\n      <th>wild ing</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>last</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.222099</td>\n      <td>71</td>\n      <td>wilding</td>\n    </tr>\n    <tr>\n      <th>you</th>\n      <td>0.346203</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>:d</td>\n      <td>374989834</td>\n      <td>0.000000</td>\n      <td>2.131311e-04</td>\n      <td>431347</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.219711</td>\n      <td>74</td>\n      <td>yoh</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>see</th>\n      <td>0.203486</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>to</td>\n      <td>43600979</td>\n      <td>0.000001</td>\n      <td>6.337243e-04</td>\n      <td>323620</td>\n      <td>0.000000</td>\n      <td>0.004984</td>\n      <td>0.248927</td>\n      <td>6791</td>\n      <td>zee</td>\n    </tr>\n    <tr>\n      <th>range ra</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>hearts</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.222099</td>\n      <td>6809</td>\n      <td>rangera</td>\n    </tr>\n    <tr>\n      <th>heart</th>\n      <td>0.760539</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>hibs</td>\n      <td>7957991</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>167538</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.220209</td>\n      <td>6810</td>\n      <td>hearts</td>\n    </tr>\n    <tr>\n      <th>his</th>\n      <td>0.234643</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>falkirk</td>\n      <td>40429274</td>\n      <td>0.000003</td>\n      <td>2.968146e-07</td>\n      <td>11999277</td>\n      <td>0.000000</td>\n      <td>0.000002</td>\n      <td>0.206385</td>\n      <td>6811</td>\n      <td>hibs</td>\n    </tr>\n    <tr>\n      <th>south bank</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>10</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>http://t.co/0v8cfj6sog</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.222382</td>\n      <td>6855</td>\n      <td>southbank</td>\n    </tr>\n  </tbody>\n</table>\n<p>332 rows × 26 columns</p>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cands.loc[(max_cands.probs < 0.5) & (max_cands.from_original_token != 1) & (max_cands.index.values != max_cands.gold) & (max_cands.raw == max_cands.gold)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['prev', 'next'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m random_forest\u001B[38;5;241m.\u001B[39mpredict_normalisations(\u001B[43mrandom_forest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_probs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDATA_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhpc/dev_processed_nocap.txt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msort_values([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprocess\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtweet\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtok\u001B[39m\u001B[38;5;124m\"\u001B[39m]))\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/src/lexnorm/models/random_forest.py:44\u001B[0m, in \u001B[0;36mpredict_probs\u001B[0;34m(model, data_path)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_probs\u001B[39m(model, data_path):\n\u001B[1;32m     38\u001B[0m     data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\n\u001B[1;32m     39\u001B[0m         data_path, index_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, keep_default_na\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, na_values\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     40\u001B[0m     )\u001B[38;5;241m.\u001B[39msample(\n\u001B[1;32m     41\u001B[0m         frac\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     42\u001B[0m         \u001B[38;5;66;03m# random_state=42,\u001B[39;00m\n\u001B[1;32m     43\u001B[0m     )\n\u001B[0;32m---> 44\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[43mprep_test\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m     probs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict_proba(features)\n\u001B[1;32m     46\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mcopy()\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/src/lexnorm/models/normalise.py:32\u001B[0m, in \u001B[0;36mprep_test\u001B[0;34m(unannotated_dataframe)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprep_test\u001B[39m(unannotated_dataframe):\n\u001B[0;32m---> 32\u001B[0m     test_X \u001B[38;5;241m=\u001B[39m \u001B[43munannotated_dataframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mraw\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprev\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mnext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprocess\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtweet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtok\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# \"twitter_uni\",\u001B[39;49;00m\n\u001B[1;32m     41\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# \"twitter_bi_prev\",\u001B[39;49;00m\n\u001B[1;32m     42\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# \"twitter_bi_next\",\u001B[39;49;00m\n\u001B[1;32m     43\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# \"wiki_uni\",\u001B[39;49;00m\n\u001B[1;32m     44\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# \"wiki_bi_prev\",\u001B[39;49;00m\n\u001B[1;32m     45\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;66;43;03m# \"wiki_bi_next\",\u001B[39;49;00m\n\u001B[1;32m     46\u001B[0m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     test_X\u001B[38;5;241m.\u001B[39mfillna(\u001B[38;5;241m0\u001B[39m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m test_X\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/core/frame.py:5399\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   5251\u001B[0m \u001B[38;5;129m@deprecate_nonkeyword_arguments\u001B[39m(version\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, allowed_args\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m   5252\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(  \u001B[38;5;66;03m# type: ignore[override]\u001B[39;00m\n\u001B[1;32m   5253\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5260\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5261\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5262\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   5263\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[1;32m   5264\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5397\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[1;32m   5398\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 5399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5400\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5401\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5404\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5405\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5406\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5407\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    326\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    327\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    329\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[1;32m    330\u001B[0m     )\n\u001B[0;32m--> 331\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/core/generic.py:4505\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   4503\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   4504\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4505\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[1;32m   4508\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/core/generic.py:4546\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[0;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[1;32m   4544\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m   4545\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4546\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4547\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[1;32m   4549\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[1;32m   4550\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6934\u001B[0m, in \u001B[0;36mIndex.drop\u001B[0;34m(self, labels, errors)\u001B[0m\n\u001B[1;32m   6932\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m   6933\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 6934\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(labels[mask])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6935\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[1;32m   6936\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['prev', 'next'] not found in axis\""
     ]
    }
   ],
   "source": [
    "random_forest.predict_normalisations(random_forest.predict_probs(clf, os.path.join(DATA_PATH, \"hpc/dev_processed_nocap.txt\")).sort_values([\"process\", \"tweet\", \"tok\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "from lexnorm.models.normalise import prep_train\n",
    "# trying svc\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "data = pd.read_csv(\n",
    "        os.path.join(DATA_PATH, \"hpc/train_processed_annotated_nocap.txt\"), index_col=0, keep_default_na=False, na_values=\"\"\n",
    "    ).sample(frac=1, random_state=42)\n",
    "train_X, train_y = prep_train(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "beguile         0.0\nindia           0.0\ncreased         0.0\nbestseller's    0.0\nbenefactors     0.0\n               ... \nandroid's       0.0\nderision        0.0\nonslaught       0.0\nmeteor's        0.0\nbutcher's       0.0\nName: correct, Length: 2977600, dtype: float64"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.s"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
