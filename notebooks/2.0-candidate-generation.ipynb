{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from lexnorm.data import lexicon\n",
    "from lexnorm.data import norm_dict\n",
    "from lexnorm.data.normEval import loadNormData\n",
    "from lexnorm.definitions import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['ah', 'why', 'sub', 'ozil', 'opolo', 'eyes', 'u', 'no', 'fit', 'open', 'have', 'a', 'very', 'sexy', 'header', 'rawr', 'i', 'miss', 'my', 'bie', 'where', 'wanna', 'out', 'wif', 'me', 'wonderful', 'day', 'like', 'swan', 'haha', 'cantik', 'julie', 'christie', '1968', 'photograph', 'by', 'richard', 'avedon', 'did', 'calum', 'slip', 'omfg', 'and', 'you', 'didnt', 'make', 'this', 'brah', 'friend', 'jack', 'storm', 'pshh', 'went', 'got', 'mine', 'done', 'regardless', 'im', 'sick', 'of', 'not', 'being', 'able', 'to', 'be', 'girl', 'syempre', 'in', 'the', 'right', 'age', 'hahaha', 'shit', 'rockin', 'go', 'head', 'show', 'that', 'bria', 'words', 'describe', 'exo', 'luhan', 'is', 'pain', 'chanyeol', 'sex', 'sehun', 'porn', 'ukip', 'has', 'had', 'two', 'councillors', 'elected', 'northern', 'ireland', 'today', 'marvellous', 'lol', 'cause', 'said', 'woulda', 'been', 'falling', 'along', 'with', 'yea', 'was', 'gonna', 'hit', 'up', 'but', 'guess', 'okay', 'well', 'at', 'least', 'know', 'other', 'blog', \"you've\", 'dying', 'hide', 'he', 'obvi', 'doesnt', 'understand', 'friends', 'grecia', 'just', 'love', 'way', 'are', 'your', 'fun', 'personality', 'how', 'arent', 'afraid', 'express', 'yourself', 'so', 'openly', 'on', 'youtube', 'usa', 'spalding', 'nba', 'street', 'ony', 'doing', 'piss', 'off', 'everyone', 'tl', 'haru', 'hana', 'q', 'something', \"can't\", 'do', 'despite', 'golden', 'maknae', 'jeongguk', 'talk', 'studying', 'laughs', 'dremel', 'sm844', 'crown', 'molding', 'guide', 'new', '4', 'conor', 'keelan', 'ff', 'polling', 'sixth', '737', 'first', 'preference', 'votes', 'eu', 'amo', 'vcs', 'esse', 'fandom', 'mim', 'beiji', 'directionas', 'investissement', 'cape', 'coral', 'murs', 'chinois', 'chinese', 'drywall', 'via', 'ight', 'what', 'nigga', 'heheheh', 'youu', 'ate', 'jean', 'feelin', 'brand', 'wolfnsheepclothing140', 'eating', 'cadbury', 'now', 'xd', 'galeris', 'tag', 'n', 'custa', 'nd', 'taeminho', 'lighstick', 'arrived', 'thanku', 'zoom', '2', 'c', 'an', 'sekret', 'mesage', 'will', 'appreciate', 'kno', 'dat', 'aint', 'bad', 'bitch', 'dats', 'knock', 'receptionist', 'florence', 'clinic', 'ft', 'omaha', 'alegent', 'creighton', 'health', 'largest', 'fai', 'srk', 'salmann', 'khann', 'auchhh', 'shoo', 'handsome', 'southbound', 'between', 'a47', 'near', 'hinckley', 'west', 'east', 'a5', 'from', 'cannock', 'towards', 'guys', 'picture', 'zayn', 'old', 'also', 'can', 'see', 'niall', 'standing', 'next', 'him', \"wouldn't\", 'crowd', 'good', 'mood', 'cus', 'music', 'wait', 'infact', 'most', 'zulu', 'nikkas', 'fore', 'skin', 'they', 'smell', 'stage', 'croke', 'park', 'dublin', '30', 'harrys', 'reaction', 'when', 'let', 'play', 'hes', 'cute', 'omg', 'expect', 'drive', 'california', 'for', 'court', 'back', 'seatbelt', 'ticket', 'fuhh', 'thattt', 'literally', 'made', 'whole', 'complete', 'g', 'ill', 'stay', 'home', 'b4', 'party', 'bunch', 'fake', 'mtfs', '0r', '0h', '0e', 'pss', 'cbs', '0', 'end', '1st', 'recap', 'their', 'number', 'havard', 'nordtveit', 'arsenal', 'youth', 'reserve', 'player', 'exclusive', 'footage', 'vincent', 'kompany', 'going', 'yaya', 'toure', 'after', 'telling', 'leaving', 'streaming', 'shakira', 'feat', 'residente', 'calle', 'gordita', 'nightlife', 'website', 'wtf', \"i've\", 'only', 'seen', 'weaver', 'more', 'blocks', 'than', 'lundquist', 'saves', 'ha', 'rds', 'john', 'mayer', 'xo', 'beyonce', 'cover', 'adore', 'remix', 'miley', 'cyrus', 'cedric', 'gervais', 'mom', \"let's\", 'watch', 'blues', 'clues', 'son', 'gon', 'kill', 'poll', 'which', 'would', 'cut', 'v', 'peppa', 'pig', 'eeak', 'meen', 'lyshaa', 'keep', 'save', 'relationship', 'seeing', 'oll', 'dogg', 'again', \"good'o\", 'luke', 'kylie', 'stylist', 'pls', 'sungjong', 'last', 'romeo', 'card', 'want', 'seongyeol', 'or', 'myungsoo', 'sg', 'dm', 'hemmings', 'mbf', 'bc', 'actually', 'them', 'christian', 'pace', 'pt', '26', 'amore', 'hai', 'vinto', 'tu', 'dan', 'kcu', 'alum', 'funny', 'songs', 'calls', 'himself', 'whiteboy', 'dj', 'sorry', 'bout', 'homie', 'check', 'dms', 'get', 'chance', 'who', \"i'm\", 'cosplaying', \"it's\", 'still', 'as', 'comicon', 'wear', 'condom', \"don't\", 'worry', 'about', 'pullin', 'woah', 'song', 'oppa', 'one', 'favourite', 'asu', 'wa', 'kuru', 'kara', 'jimin', 'it', 'if', 'asked', 'angpaos', 'jungkook', 'does', 'look', 'aunty', 'uncle', 'happy', 'bigger', 'angpao', 'alpukat', 'madu', 'yummy', 'manis', 'banget', 'wrap', 'our', 'month', 'moscato', 'host', 'tasting', 'mq', 'easy', 'doto', 'tap', 'centreville', 'chipotle', 'porter', 'yall', 'worried', 'fact', 'smoking', 'weed', 'wasnt', 'even', 'wearing', 'seat', 'belt', 'eminado', 'means', 'goodluck', 'surulere', 'patience', 'must', 'related', 'president', 'lil', '10', 'years', 'timeout', 'mango', 'some', 'fuckn', 'real', 'bjp', 'supporters', 'delighted', 'shourie', 'ji', 'putting', 'his', 'place', 'angy', 'knows', \"she's\", 'met', 'jake', 'badboy', 'temper', 'raaaaar', 'sugar', 'daddies', 'online', 'gurl', 'graduation', 'rehersal', 'takin', 'forever', 'thank', 'goodness', 'textin', 'sanity', 'believe', 'term', 'male', 'ballerina', 'ballerino', 'pokemon', 'dafuq', 'smh', '1', 'glass', 'wine', 'drunk', 'd', 'k', 'dolla', 'sign', 'gm', 'nah', 'niggah', 'time', 'try', 'fight', 'elction', 'winning', 'spirite', 'defeat', 'others', 'lmao', 'her', 'titys', 'really', 'krabby', 'patty', 'buns', \"they're\", 'allergic', 'face', 'insecure', 'bfs', 'showin', 'all', 'kinds', 'pda', 'cuz', 'came', 'around', 'corner', 'channing', 'tatum', 'jonah', 'hill', 'take', 'silly', 'selfies', 'fans', 'marwan', 'asmar', 'writes', 'road', 'ahead', 'looks', 'intractable', 'labour', 'weak', 'round', 'lizard', 'point', 'mention', 'o', 'e', 'dawwg', 'yeah', 'guy', 'saying', 'needto', 'enright', 'lonergan', 'cats', 'god', \"didn't\", 'sleep', 'oh', 'saw', 'everything', 'wat', 'sooner', 'later', 'ko', 'kna', 'blik', 'jga', 'goes', 'comes', 'method', 'ponning', 'school', 'hahhahaha', 'tell', 'voted', 'bnp', 'umbro', 'trackies', 'screw', '2014', 'congratulation', 'hey', 'cutie', 'chukkaeee', 'having', 'teacher', 'accept', 'late', 'work', 'probably', 'worst', 'thing', 'ever', 'little', 'hw', 'every', 'night', 'na', 'po', 'starts', 's', 'enda', 'r', 'example', 'saucer', 'admin', 'ching', 'louis', 'harry', 'liam', 'lls', 'niggas', 'fallin', 'short', 'bitches', 'neva', 'bro', 'dont', 'feel', 'tmrw', 'benitez', 'earth', 'leave', 'napoli', 'poch', 'behind', 'joint', 'ahhhh', 'kena', 'tweet', 'kalau', 'hisap', 'aca', 'ayudando', 'con', 'spam', 'rahway', 'nj', 'paramedic', 'robert', 'wood', 'johnson', 'university', 'hospital', 'perform', 'mobile', 'inte', 'momma', \"ain't\", 'live', 'second', 'class', 'prateik', 'babbar', 'bengali', 'film', 'much', 'better', 'bit', 'think', 'need', 'wash', 'posible', 'peace', 'till', 'j', 'leo', 'kat', 'come', 'replay', 'worries', 'weird', 'name', 'understandable', 'lebron', 'fan', 'gotta', 'any', 'flop', 'against', 'manny', 'pacquiao', 'af', 'money', \"dwp'14\", 'meeting', 'zedd', 'dressin', 'room', 'shenanigans', 'harrystyles', \"won't\", 'mess', 'hashtag', 'descent', \"there's\", 'unity', 'group', 'because', 'everybody', 'prick', 'sometimes', 'ima', 'fam', 'swoop', 'desain', 'kamar', 'anak', 'ceria', 'bright', 'children', 'design', 'ideas', 'public', 'bae', 'another', 'mt', 'fucking', 'jews', 'always', 'throwg', 'holocaust', 'privilg', 'ppls', 'faces', 'sum1', 'shld', 'put', 'camps', 'w8', 'locc', 'michael', 'jordan', 'fav', 'james', 'jos', 'buttler', 'senanayake', 'b', 'mathews', 'ov', 'tweetin', 'someone', 'favs', 'ur', 'alcon', 'receives', 'positive', 'chmp', 'opinion', 'simbrinz', 'treatment', 'glaucoma', \"that's\", 'rollingstone', 'kanye', 'marries', 'kim', 'kardashian', 'jst', 'zimuvuta', 'gwamba', 'shuld', 'say', 'its', 'amazing', 'fasta', 'pasta', 'microwave', 'cooker', 'cookerby', 'glance', 'center', 'maurkice', 'pouncey', 'taking', 'spot', 'midd', 'toilets', 'available', 'resourceful', 'man', 'fictional', 'characters', 'care', 'might', 'die', 'year', 'sebastian', 'jace', 'simon', 'alec', 'magnus', 'percy', 'annabeth', 'nico', 'karlie', 'kloss', 'chanel', 'haute', 'couture', 'amd', 'catalyst', 'introduces', 'eyefinity', 'mantle', 'notebooks', 'enduro', 'shoutout', 'lauren', 'nancy', 'favorite', 'fenwick', 'girls', 'idgaf', 'anything', 'anymore', 'long', 'ellie', 'goulding', 'texting', 'voyager', 'tbh', 'budur', 'isteeeee', 'eye', \"tiger'im\", 'benim', 'kamran', 'khan', 'geo', 'free', 'tv', 'programs', 'apna', 'zone', 'uma', 'wats', 'marshalls', 'toma', 'trailer', 'sdtg', 'shown', 'sa', 'primiere', 'ng', 'maybe', 'hoes', 'should', 'thankin', 'savin', 'tears', 'heart', 'pains', 'kylan', 'leavin', 'gd', 'knw', 'ds', 'attention', 'nt', 'mind', 'dumb', 'fack', 'pay', 'malaysia', 'airlines', 'academy', 'petaling', 'jaya', 'selangor', 'moment', 'type', 'haahaha', 'hahagaha', 'erm', 'lantak', 'la', 'people', 'talkin', 'reckless', 'true', 'savage', 'could', 'rasheeda', 'erica', 'realest', 'females', 'hip', 'hop', 'atl', 'rft', \"rt'ed\", 'tho', 'british', 'yolo', 'there', 'warmin', 'before', \"someone's\", 'nb', 'nice', 'jinka', 'grip', 'hu', 'subjects', 'ppe', 'we', 'unpeacekeeping', 'humen', 'retd', 'col', 'parha', 'rhy', 'hyn', 'best', 'fina', 'bck', \"it'l\", \"vee's\", 'style', 'mathata', 'ke', 'gore', 'nobody', 'evanescence', 'vs', 'linkin', 'refuses', 'commit', 'future', 'manchester', 'city', 'photoset', 'rape', 'tw', 'annalynne', 'mccord', 'revealed', 'she', 'abused', 'these', 'were', 'mad', 'catz', 't', '7', 'gaming', 'mouse', 'pc', 'mac', 'omygosh', 'ace', 'kori', 'called', 'mookie', 'life', 'tatts', 'gettin', 'gazzetta', 'says', 'silva', 'ibra', 'argued', 'wants', 'psg', 'thought', 'almost', 'heartattack', '5', 'havent', 'hahah', 'anit', 'gone', 'glock', '8', 'shots', 'rp', 'jfb', 'retweet', 'juseyo', \"shouldn't\", 'gave', 'dumbass', 'ppl', 'evry1s', 'bam', 'performing', '2moz', 'bgt', 'summer', 'myself', 'guitar', 'hot', 'thats', 'happening', 'making', 'happen', 'fuck', 'matty', 'whiny', 'shallow', 'nor', 'am', 'boring', 'silhouetto', 'scaramouche', 'fandango', 'maomao', 'hi', 'coach', 'gud', 'evening', 'mis', 'pray', 'ayu', 'strong', 'veces', 'simplemente', 'te', 'cansas', 'tweeting', 'else', 'frozen', 'nephew', 'auditorio', 'civico', 'del', 'estado', \"we're\", 'kings', 'europe', 'basketball', 'european', 'cups', 'reminder', 'jajaja', 'enorme', 'mirotic', 'ugly', 'brother', 'perrie', 'details', 'asap', 'soo', 'siked', 'messin', 'no1s', 'wifey', 'yo', 'canon', 'ef', 'l', 'usm', 'join', 'win', 'grand', 'prize', 'pass', 'xolo', 'lfc', 'liked', 'video', 'tomorrowland', '2013', 'alesso', 'full', 'set', 'layin', 'goin', 'rns', 'staff', 'sgt', 'rigby', 'dugsbaws', 'gonnae', 'jobby', 'tent', 'cowdenbeath', 'food', 'tammi', 'xxx', 'soon', 'followback', 'vesely', 'dati', 'sight', 'ngayon', 'lowkey', 'somtime', 'away', 'naaa', 'cuzz', 'buy', 'crepes', 'beef', 'dropped', 'cj', 'watson', 'without', 'dribbling', 'openfollow', 'kpopers', 'help', 'idc', 'whose', 'car', 'never', 'pump', 'own', 'gas', 'childish', 'cunts', 'nuneaton', 'abt', 'compliment', \"y'all\", 'crusty', 'asses', 'nvm', 'us', 'light', 'skinted', 'wimminz', 'teta', 'beso', 'rosita', 'such', 'bi', 'nas', 'buie', 'sectional', 'champion', 'discus', 'throw', 'sofa', 'sofaking', 'annoying', 'yees', 'laughing', 'tweets', 'lmfao', '50', 'greatest', 'rockstars', 'world', 'kerrang', 'aww', 'thanks', 'zayda', 'tabaruis', 'troll', 'account', 'same', 'told', 'mean', 'different', 'state', 'ive', 'start', 'over', 'switch', 'sec', 'thx', 'follow', 'arigatou', 'gozaimasu', 'truly', 'banterous', 'choice', 'loyal', 'please', 'ilysm', '31', 'zuccarello', 'shoves', 'gionta', 'into', 'goalie', 'definitely', 'interference', 'call', 'text', '3', 'yup', '6', 'nope', 'chillin', '9', 'naw', 'send', 'pic', 'sis', 'watz', 'wring', 'pretty', 'hard', 'involves', 'lot', 'math', 'sit', 'tele', 'cba', 'looking', 'chav', 'vid', '140524', 'lost', 'planet', 'concert', 'beautiful', 'suho', 'cr', 'bluemarine', 'nyaaaaa', 'used', 'crush', 'plus', 'cutee', 'hehehe', 'hatin', 'ass', 'cant', 'stand', 'atleti', 'lead', 'mistake', 'casillas', 'couldnt', 'find', 'screen shot', 'danielle', 'veilleux', 'ryan', 'holland', 'nyt', 'recommend', 'moto', 'emosh', 'pyaar', 'patient', 'fucc', 'slaccin', 'kurang', 'h', 'kakak', 'somebody', 'edge', 'tommorow', 'lagi', 'serius', 'hennessy', 'patron', 'likely', 'drinking', 'tht', 'alcohol', 'nasty', 'delete', 'twitter', 'then', 'bored', 'frnd', 'white', 'elephant', 'collcted', 'tryin', 'ma', 'wnts', 'plamy', 'days', 'wit', 'ooh', 'hope', 'hehe', 'idea', 'getting', 'tortillas', 'aguacates', 'loved', 'gym', 'session', 'watchin', 'fast', 'wheey', '39', 'lives', 'heysel', 'bless', 'x', 'meat', 'main', 'squad', 'mixed', 'dlineman', 'oline', 'men', 'wrs', 'running', 'hrs', 'hype', 'hell', 'gates', 'voice', 'give', 'dey', 'crack', 'asum', 'nukeproof', 'pulse', 'dh', 'comp', 'modell', 'uvp', '3599', 'deal', 'dare', '500grams', 'gain', 'lose', 'ligid', 'entrance', 'um', 'padung', 'dpt', 'pildi', 'dubb', 'fresh', 'building', 'too', 'tomorrow', 'chica', 'shine', 'makes', 'mclaren', '12c', 'spider', 'convertible', 'nose', 'lift', 'spyder', 'carbon', 'fiber', 'madrid', 'cup', 'ucl', 'atletico', 'cristiano', 'ronaldo', 'breaking', 'boko', 'haram', 'fighters', 'military', 'uniform', 'invade', 'borno', 'villages', 'killing', '35', 'gistreel', 'file', 'pho', 'download', 'fat', 'trel', 'tape', 'boi', 'chinx', 'drugz', 'green', 'camo', 'braided', 'headband', 'headbandby', 'fabulicious', 'elastic', 'headb', 'gmorning', 'sayang', 'hon', 'local', 'events', 'fundrasiers', 'entertainment', 'cusine', 'recreation', 'activities', \"they've\", 'released', 'yingluck', 'unkown', 'custody', 'holding', 'thumbs', 'asus', 'series', 'notebook', 'transfer', 'rumour', 'gossip', 'red', 'devils', 'star', 'heads', 'barca', 'gunners', 'target', 'milan', 'striker', 'idk', 'tryna', 'buck', 'fosho', 'mutuals', 'turn', 'yesshhh', 'plate', \"you're\", 'waiting', 'mixtape', 'amb', 'sass', 'finger', 'story', 'interfax', 'rebel', 'leader', 'eastern', 'ukraine', 'osce', 'observers', 'ap', 'ya', 'plz', 'thr', 'ruffalo', 'immediately', 'tells', 'bomer', \"he's\", 'speaking', 'basically', 'entire', 'minuman', 'botol', 'yg', 'tgh', 'itu', 'virgils', 'badass', 'wallingford', 'vt', 'weather', 'temp', 'f', 'humidity', '95', 'average', 'wind', 'speed', 'mph', 'directon', 'nne', 'pm', 'june', 'ramdan', 'small', 'imma', 'dawg', 'emak', 'mblow', 'eerie', 'feeling', 'signal', 'selection', 'bmi', 'commented', 'difficultly', 'interp', 'here', 'nigg', 'goalkeeper', 'lukasz', 'fabianski', 'joined', 'swansea', 'ed', 'sheeran', 'sing', 'official', \"i'd\", 'tana', 'beard', 'prolly', 'curl', 'fetal', 'position', 'dreams', 'fanclub', 'wmf', 'corvo', '1158186030', 'sauce', 'spoon', 'spoonby', 'aktiengese', 'hong', 'jong', 'hyun', \"girl's\", \"day's\", 'yura', 'married', 'season', 'actor', 'present', 'nk', 'juall', 'productt', 'agak2', 'dr', 'beli', 'luck', 'godbless', 'nle', 'takers', 'quick', 'judge', 'while', 'tonight', 'monkees', 'swinging', \"greensburg's\", 'palace', 'theatre', 'molaa', 'visto', 'las', 'conversaciones', 'de', 'whatsapp', 'mi', 'amigo', 'esta', 'app', 'ford', 'reasons', 'child', 'emma', 'styles', 'stone', 'gf', 'ni', 'finn', 'eh', 'basta', 'maganda', 'yebi', 'stp', 'confuse', 'ahhh', 'normal', 'webside', 'stge', 'theyre', 'playing', 'background', 'tf', 'bestfriend', 'sky', 'moon', 'spin', 'sure', 'irl', \"you'll\", 'ew', \"haven't\", 'instagram', 'mark', 'perfect', 'hair', 'colour', 'w', 'busan', 'sho', 'nuff', 'hold', 'funky', '24', 'those', 'catch', 'urself', 'smiling', 'reason', 'latest', 'congratulates', 'modi', 'vows', 'ties', 'level', 'ibnlive', 'ibnlivechinese', 'p', 'rapgenius', 'resigns', 'elliot', 'rodger', 'comments', 'entrepreneur', 'described', 'isla', 'vista', \"killer's\", 'manifest', 'stadionie', 'leicester', 'twerks', 'doin', 'signing', 'found', 'aussie', 'fuks', 'da', 'kidd', 'fuk', 'hashtags', 'may', '29', 'fg', 'establish', 'trauma', 'counselling', 'centres', 'following', 'blasts', 'federal', 'government', 'es', 'tutorial', 'installing', 'configure', 'kvm', 'centos', 'linux', 'graduating', 'appreciation', 'congrats', 'ily', 'thingy', 'newsfeed', 'id', 'stalk', 'profile', 'team', 'big', 'bahahaha', 'homies', 'wideouts', 'regularly', 'career', 'ask', 'stop', 'score', 'rosberg', 'wins', 'mercedes', 'teammate', 'lewis', 'hamilton', 'finishes', '2nd', \"bull's\", 'daniel', 'ricciardo', 'ends', '3rd', 'belieber', 'photo', 'avalanna', 'bracelet', 'sweet', 'football', 'sucks', 'abang', 'fadil', 'baby', 'hate', 'tt', 'down', 'totty', 'chasing', 'celebrate', 'chill', 'outttttt', 'ok', 'freezer', 'cole', 'haan', 'maya', 'angelou', \"director's\", 'vimeo', 'started', 'fw', 'worth', 'college', 'joga', 'thresh', 'adc', 'times', 'focus', 'isnt', 'step', 'vw', 'nurse', 'doe', 'broke', 'high', 'under', 'playlist', 'katoomba', 'falls', 'blue', 'mountains', 'australia', 'ian', 'geddes', 'digital', 'photographer', 'chicago', 'hmu', 'stainin', 'subtweeted', 'lolz', 'taniah', 'abg', 'jep', 'sepahtu', 'support', 'matter', 'haydn', 'symphony', 'bear', 'neville', 'marriner', 'martin', 'fields', 'jimmy', 'iovine', 'steps', 'interscope', 'replaced', 'janick', 'holdin', 'hayne', 'possible', 'seal', 'qld', 'jarryd', 'referring', 'imbo', 'whistle', 'bitvhes', 'apologizing', 'bitvh', '140529', 'smtown', 'update', 'messages', 'roll', 'smitefire', 'giving', 'unlock', 'codes', 'geb', 'giveaway', 'sunday', 'camas', 'sevilla', 'andalucia', 'spain', 'hala', 'cibeles', 'translated', 'lyrics', 'y', 'nada', 'mas', 'anthem', 'word', 'gross', 'rambling', 'cites', 'ce', 'avec', 'ta', 'chanson', 'tmh', 'things', 'et', 'ermenegildo', 'zegna', 'models', 'silk', 'tie', 'navy', 'acc', 'since', '2009', 'wth', '100k', 'hahahahha', 'hahahaha', 'pregnant', 'father', 'illa', 'potatohead', 'left', 'stumbled', 'gem', 'donghae', 'mouth', 'covered', 'siwon', 'rhythm', 'totally', 'imagining', 'kkk', 'kagepro', 'everywhere', 'sport', 'bafana', 'international', 'friendly', 'kick', 'juz', 'speeding', 'lyk', 'jay', 'yesterday', 'aap', 'bahuuut', 'lucky', 'ho', 'touchwood', 'top', 'liner', 'felt', 'deep', 'balls', 'introduction', 'node', 'js', 'mongodb', 'taemin', 'calling', 'hyungs', 'nike', 'advert', 'ooooohh', 'burn', 'survivooooor', 'hardeeeer', 'whos', 'finah', 'dinah', 'hq', 'baekhyun', 'exoplanet', 'supernova', 'flatshoes', 'animal', 'printing', 'bali', 'cek', 'pin', '27bf53b0', '087722042186', 'soooo', 'dam', 'barely', 'breathe', 'gne', 'thru', 'nite', 'smilers', 'vote', \"brenda's\", 'house', 'caxias', 'sul', \"r's\", 'saved', 'unfollowed', 'possibly', 'tumblr', 'starting', 'faal', 'wala', 'tota', 'whoopin', 'hoe', 'teachers', 'walking', 'heard', 'computers', 'during', 'hcc', 'babes', 'oohh', 'great', 'aur', 'whats', 'spurs', 'yes', '19', 'ready', 'consert', 'taryn', 'srry', 'plasma', 'luis', 'avril', 'lavigne', 'tour', '14', 'majlis', 'mohamed', 'nasheed', 'apply', 'makeup', 'hahahah', 'fredo', 'x69', 'squads', 'thot', 'bardo', 'smacked', 'manly', 'sports', 'ladies', 'gents', 'laughed', 'joke', 'kamu', 'cewek', 'sini', 'dong', 'hugh', 'loh', 'everyones', 'warning', 'vixx', 'due', 'watching', 'mc', 'dorm', 'rent', 'sad', 'case', 'brave', 'frontier', 'pheobe', 'senpai', 'staying', 'sigh', \"could've\", 'betetr', 'merit', 'ban', 'disability', 'abuse', 'uefa', 'throwing', 'paris', 'champions', 'league', 'foun', 'elin', 'danielson', 'gambogi', 'breakfast', 'meg', 'tetnus', 'shot', 'microwaved', 'bacon', 'idiot', 'liar', 'kentucky', 'newspaper', 'slams', 'mitch', \"mcconnell's\", 'obamacare', 'doublespeak', 'durk', 'otf', 'nunu', 'oc', 'honestly', 'black', 'magic', 'scary', 'tbt', 'sheikh', 'hasina', 'returns', 'prime', 'minister', 'returned', 'morning', 'hood', 'ashton', 'irwin', 'clifford', '5sos', 'uncomfortable', \"dm's\", '971', 'laylow', 'beat', 'lay', 'low', 'trust', 'bf', 'drinkin', 'henny', 'ankit', 'tollyimages', 'amritha', 'rao', 'amrita', 'swear', 'screamed', 'superwoman', 'singing', 'appadi', 'podu', 'representin', 'bangin', 'trippin', 'sip', 'caffeinated', 'stored', 'tha', 'purge', 'ets', 'metallic', 'paint', 'dlc', 'patch', 'macbook', 'lifting', 'weights', 'teach', 'sakta', 'dog', 'kyun', 'nahin', 'parmesean', 'garlic', 'louisiana', 'rub', 'ftw', 'sean', 'darragh', 'unbelievable', 'weekend', 'ion', 'many', 'equal', 'unloyal', 'screamin', 'blood', \"isn't\", 'stealing', 'chilln', 'trying', 'havnt', 'far', 'guard', 'av', 'though', 'johnny', \"knoxville's\", 'absolute', 'hero', 'nawaz', 'sharif', 'attending', 'narendra', 'monday', 'awnser', 'phone', 'woyld', 'tamgo', 'yet', 'maximum', 'likes', 'lovers', 'joaquim', 'abranches', 'soubhik', 'kidding', 'kali', 'pulls', 'jumping', 'missed', 'hollaback', 'gwen', 'stefani', 'describes', 'perfectly', 'fucka', 'boo', 'tired', 'frfr', 'birthday', 'brooo', 'wish', 'allah', 'blessing', 'glad', 'hiii', 'folllow', 'x30', 'strike', 'few', 'homerun', 'elive', 'anyways', 'agree', 'theres', 'yiyo', 'sarante', 'homenaje', 'willy', 'gonzales', 'click', 'listen', 'huhuhuhuhuh', 'postcard', 'polaroid', 'tlist', 'encanta', 'stars', 'jeesh', 'insta', 'benge', 'cost', 'living', 'nao', 'canso', 'desse', 'filme', 'weddings', 'aruba', 'ofc', 'bridesmaids', 'listening', 'vato', 'mustard', 'nokia', 'lumia', '1520', '25', 'thwre', 'cruing', 'fuckin', 'drug', 'butthurt', 'm', 'realise', 'showing', 'whn', 'qtr', 'lou', 'sushmita', 'mae', 'bernardino', '3058', 'tay', 'loves', 'legs', 'reinforcements', 'david', 'dimbleby', 'took', 'freddos', \"hasn't\", 'texted', 'yunho', 'sameee', 'heree', 'drake', 'cous', 'corrina', 'gwyn', 'etc', 'mary', 'fighting', 'coz', 'kev', 'rob', 'lindsey', 'mms', 'wah', 'snapchat', 'youngsters', 'bet', 'thinking', 'wahat', 'awks', 'yeaa', 'bye', 'felicia', 'ismail', 'cuneyt', 'oktay', 'demonstrates', 'balgo', 'honey', 'brown', 'weh', 'born', 'fi', 'cock', 'ito', 'magandang', 'question', 'nga', 'ba', 'yun', 'cigarette', 'lng', 'instead', 'beliebers', 'heldl', 'cying', 'dear', 'gma', 'tomlinson', 'direction', 'vibing', 'india', 'arie', 'glorietta', 'makati', 'metro', 'manila', '13', 'smiler', 'arianator', 'sir', 'tackle', 'problems', 'bend', 'becum', 'mental', 'onu', 'puerto', 'rican', 'pussy', 'cabron', 'radio', 'soml', 'talking', 'wut', 'outright', 'fool', 'avi', 'pops', 'breh', 'ocha', 'israel', 'separates', 'jerusalem', 'bank', 'empties', 'area', 'once', 'completely', 'person', 'rana', 'samaha', 'sweat', 'technique', 'techniqueeric', 'rakim', 'format', 'peep', 'shugga', 'shane', 'dis', 'dope', 'game', 'chicken', 'leg', 'finna', 'eat', 'facetime', 'stoopp', 'flexin', 'em', 'invite', 'chillaxing', 'abeokuta', 'ogba', 'selfie', 'awesome', 'ehhhh', 'forehead', 'oops', 'hahahahahaha', 'nakheel', 'awards', 'aed', 'bn', 'construction', 'contract', 'mall', 'property', 'developer', 'tue', 'indirectness', 'woman', 'receipt', 'hand', '390', 'wimmer', 'palker', 'mcfadden', 'foos', 'jhaud', 'heat', 'solar', 'sending', 'huntermoore', 'sloot', 'wer', 'pik', 'given', 'responsibility', 'chosing', 'tn', 'dinamalar', 'justin', 'biggest', 'dream', 'x14', 'swimmin', 'icymi', 'history', 'beth', 'phoenix', 'wwe', 'debut', 'abo', 'gainile', 'gape', 'kitso', 'akere', 'yessssiiiirrrrr', 'wonder', 'janoskians', 'announcement', 'excited', 'negde', 'gde', 'sunny', 'outside', 'civilisation', 'cody', 'apple', 'prepares', 'rule', 'vis', 'paywall', 'stepmom', 'either', \"we'll\", 'gey', 'rides', 'salt', 'wound', 'mtn', 'voir', 'autrement', 'exhibit', 'opening', 'saturday', 'gallery', 'arange', 'finca', 'dinning', 'table', 'wooden', 'material', 'furnitures', 'beauty', 'view', 'object', 'charging', 'thinkin', 'unplugging', 'forreal', 'beasiswa', 'utk', 'bassist', 'di', 'musicians', 'institute', 'hollywood', 'appear', 'decide', 'fall', 'happened', 'learnt', 'drums', 'lana', 'rey', 'summertime', 'sadness', 'shawn', 'mendes', 'seriously', 'nomore', 'dodgers', 'chris', 'withrow', 'ryu', 'mlb', 'certain', 'campaigning', 'message', 'nigel', 'farage', '2012', 'cross', 'uce', 'wkwkw', 'songong', 'kemaren2', 'bkn', 'jones', 'ye', 'tp', 'single', 'mulia', 'bin', 'immigrant', 'starring', 'joaquin', 'jeremy', 'renner', 'marion', 'cotillard', 'harkins', 'camelview', 'cnt', 'dress', 'pitbull', 'jacket', 'cold', 'begging', 'posted', 'photos', 'facebook', 'album', 'dreamland', 'aquapark', 'umm', 'al', 'quain', 'uae', 'yesss', 'lord', 'mama', 'side', 'notorious', 'eti', 'tumbuka', 'naku', 'zyewa', 'brixham', 'rugby', 'camp', 'rfc', 'demi', 'lovato', 'paul', \"o'grady\", '28th', 'cassillas', 'wid', 'goaal', 'ute', 'capt', 'amrinder', 'singh', 'priyanka', 'brought', 'shldnt', 'admission', \"rahul's\", 'failure', 'gusta', 'fabulosa', 'goodmorning', 'confirm', 'luiz', 'impending', 'nialls', 'twitcon', 'gorgeous', '140523', 'seoul', 'genie', 'looch', \"doesn't\", 'weise', 'destroyed', 'haa', 'fuckbag', 'predictable', 'laugh', 'ava', 'crying', 'ibaka', 'hurt', 'sneakers', 'neikeiishav', 'beach', 'haterz', 'wake', '9am', 'ikno', 'rite', 'bball', 'meaning', 'gentille', 'bieber', 'instagrams', 'usher', 'shooters', 'guns', 'soundin', 'whistles', 'oxy', 'mafia', 'uptownkye', 'shizz', 'ibalik', 'si', 'axel', 'pbb', 'aeg', 'be2003020w', '60cm', 'multifunction', 'built', 'electric', 'oven', 'be2003', 'won', 'wouldnt', 'kpop', 'fangirl', 'argument', 'invalid', 'yan', 'gomes', 'jason', 'giambi', 'rougher', 'slavery', 'finally', 'retweeted', 'moves', 'remember', 'stats', 'ev', 'points', 'junon', 'magazine', 'suga', 'baee', 'batwing', 'greyni', 'spandex', 'tanpa', 'syal', 'celestial', 'seasonings', 'sleepytime', 'extra', 'tea', '20', 'count', 'bag', 'sl', 'andreina', 'eliezer', 'usernames', 'ioi', 'puchong', '23', 'goal', 'waqa', 'scores', 'third', 'fiji', '77min', 'fij', 'png', 'dungey', 'repeat', 'dosent', 'managements', 'ddnt', 'fux', 'ktr', 'mi870621', 'stoner', 'everythings', 'amusing', 'whenever', 'scream', 'ughh', 'naked', 'irreplaceable', 'mf', 'smd', 'hello', 'newcastle', 'ai', 'deixa', 'garota', 'vai', 'kah', 'marty', \"ny's\", 'legendary', 'funhouse', 'arguably', 'birthed', 'dance', \"music's\", 'superstar', 'deez', 'nuts', 'michal', 'handzus', 'blackhawks', 'ot', 'sense', 'jazzys', 'bday', 'couple', 'apparently', \"selena's\", '100', 'results', 'log', 'disciple', 'tk', 'jacks', 'zuma', 'cabinet', 'concur', 'prev', 'figure', 'holy', 'fu k', 'scared', 'previous', 'jk', 'wont', 'fucks', 'alot', 'str8', 'runnin', 'buat', 'yang', 'lolos', 'enjoy', 'feedback', 'hardwork', 'yey', 'throws', 'confetti', 'tweep', 'goodbye', 'past', 'week', 'yoon', 'tae', 'woong', 'secrets', 'anyone', 'thunder', 'kai', 'undid', 'unbuttoned', 'buttons', 'shirt', 'srlsy', 'nflpa', 'boss', 'offensive', 'goodell', \"i'll\", 'awwww', 'vacant', 'seryoso', 'ikaw', 'pa', 'ahaha', 'gives', 'computer', 'screen', 'stupid', 'arabic', 'thots', 'wild', 'givin', 'headd', 'vents', 'jokin', 'flip', 'lsu', 'fck', 'greyson', 'x20', 'wizards', 'gortat', 'ariza', 'chemistry', 'terharu', 'cooyyyy', 'bahagia', 'laahhh', 'everyday', 'everynight', 'mma', 'legend', 'liddell', 'king', 'irish', 'daily', 'jai', 'babe', 'ministry', 'pastor', 'iowa', 'ride', 'wheres', 'internship', 'often', 'already', 'collide', 'burns', 'oakenfold', 'jes', \"west's\", \"kardashian's\", 'wedding', 'rehearsal', 'modern', 'kids', 'cate', 'blanchett', 'hedda', 'gabbler', 'hurricane', 'body', 'feels', 'jank', 'rn', 'dispicable', 'played', 'riding', 'slipin', 'slindin', 'pound', 'fells', 'leroy', 'juss', 'wet', \"you'd\", 'zac', 'efron', 'town', 'bt', 'insight', 'fr', 'outsider', 'yh', 'dearth', 'unlike', 'godfather', 'bukom', 'ard', 'pict', 'inbox', 'sctv', 'market', 'pondok', 'cabe', 'clary', 'stahp', 'takuma', 'ueda', 'daren', 'liew', 'geordie', 'planking', 'creep', 'magaluf', 'eptv', 'arriar', 'essa', 'lombra', 'donizildo', 'van', 'persie', 'forward', \"gaal's\", 'arrival', 'trafford', 'lool', 'jz', 'thng', 'abi', 'snaps', 'fingers', 'bebe', 'oku', 'loooooool', 'ayato', 'yui', 'pool', 'hilarious', 'hunt', 'racist', 'ini', 'org', 'setipe', 'calm', 'cool', 'woh', 'maine', 'khaa', 'liya', 'lovely', 'rwby', 'cosplays', 'woot', 'pepe', 'chavvy', 'hates', 'weiiiiird', 'report', 'releases', 'kidnapped', 'nigerian', 'xabi', 'alonso', 'vape', 'pens', 'indirect', 'fisrt', 'issue', 'america', 'wealthy', 'bullies', 'lie', 'mfs', 'ig', 'messed', 'lmaooo', 'jameela', 'jamil', 'adverts', 'grandparents', 'range', 'walkietalkie', 'alwayz', 'krillin', 'yiu', 'dude', 'hahahaaaa', 'lucu', 'kak', \"minho's\", 'naughty', 'tyler', 'josh', 'chills', 'tattooed', 'pleaseee', 'meek', 'mill', 'shy', 'glizzy', 'singer', 'commenting', 'geez', 'livestream', 'effing', 'cussin', 'silent', 'bossy', 'narry', 'hug', 'niam', 'scored', 'sweaty', 'ptdr', 'jassume', 'malades', 'takes', 'mins', 'bed', 'spinns', 'collab', 'packpack', 'stripe', 'silhouette', 'pattern', 'assalamualaikum', 'meet', 'gove', 'dolores', 'umbridge', 'conseal', 'huh', 'jazzy', 'preview', '140526', 'mbc', 'idol', 'futsal', 'championship', 'fruitxfruit', 'grabe', 'sana', 'bigyan', 'ako', 'para', 'key', 'shinee', 'grae', 'luff', 'gyo', 'marri', 'southamerica', 'dick', 'damn', 'mantabs', 'suhin', 'roostered', 'cockadoodledo', 'increible', 'acabo', 'espiar', 'amiga', 'por', 'aqui', 'funciona', 'genial', 'rumours', 'united', 'bruno', 'martins', 'indi', 'todays', 'read', 'dickens', 'added', 'hardwell', 'fragma', \"spaceman's\", 'miracle', 'sensation', 'mashup', 'wrong', 'vinz', 'tymrk', 'llc', 'auto', 'promoting', 'dieselization', 'ads', 'convention', 'tradeshow', 'stronger', 'coming', 'queen', 'slayy', 'somewhere', 'chick', 'several', 'received', 'towel', 'sinabi', 'nio', 'merong', 'waited', 'vip', 'tix', 'pero', 'ngaun', 'nakabili', 'kame', 'balotelli', 'mature', 'jawns', 'blow', 'paz', 'ngl', 'young', 'minded', 'alr', 'sally', 'realized', 'chode', 'chomper', 'pop', 'mommas', 'neighbour', 'hedge', 'german', 'proverb', 'preorder', \"rey's\", 'ultraviolence', 'realtlk', 'hea', '45', 'ang', 'aking', 'allowance', 'bow', 'sittin', 'studio', 'conservatives', '12005', '8619', 'elections', 'warwick', 'leamington', 'lib', 'dems', 'fifth', 'iggy', 'arse', 'bcs', 'popular', 'agency', 'act', 'oomf', 'acts', 'hottie', 'ashlynn', 'brooke', 'enjoying', 'thrusting', 'fuq', 'appt', 'libre', 'soy', 'libertad', 'sin', 'vuelta', 'atras', 'srsly', 'ohmygod', 'boy', 'is2g', 'raise', 'hands', 'tv5', 'gagos', 'unionists', 'both', 'convery', 'surplus', 'nuala', 'quota', 'tierna', 'wes', 'defending', 'athletico', 'titus', 'bramble', 'worthy', 'sleeve', 'book', 'hours', '1825', 'wasted', 'ab', 'kaam', 'par', 'bhi', 'lago', 'majdoor', 'vegan', 'stoked', 'gorgeousss', 'neco', 'exam', 'timetable', 'expo', 'answers', 'fany', 'jeti', 'slapped', 'seohyuns', 'butt', 'loool', 'waddup', 'yal', 'wht', 'repin', 'kzn', 'cakep', 'smart', 'teen', 'loko', 'astral', 'sunsplash', 'whoops', 'mentions', 'decided', 'nak', 'nangis', 'tengok', 'kawan', 'post', 'arctic', 'monkeys', 'finsbury', 'tangina', 'deny', 'ninoy', 'aquino', 'airport', 'mnl', 'terminal', '15', 'jiggas', 'boosie', 'personally', 'victimized', 'fine', 'owe', 'prove', 'yer', 'wagner', 'olha', 'caraio', 'followers', 'reach', 'replies', 'retweets', '655', 'fb', 'junior', 'bautista', 'tits', 'masturbating', 'squirting', 'chair', 'views', 'rating', 'durat', 'geeked', 'ray', 'allen', 'fanbase', 'add', 'muhtab', 'kindly', 'nw', 'ffn', 'shab', 'mehraj', 'ibadat', 'revision', 'brains', 'answered', 'basis', 'learned', 'adam', 'sandler', 'waterboy', 'becky', 'laura', 'lovley', 'xxxx', 'permit', 'issues', 'colaboration', 'bfd', 'postponed', 'inconvenience', '5000', 'posts', 'interior', 'rumah', 'nyaman', 'comfort', 'colorful', 'changed', 'stfu', 'ciye', 'ciyee', 'anniv', 'failed', 'ditomore', 'hungry', 'clue', 'sound', 'goood', 'pizza', 'rolls', 'pvd', 'fish', 'chips', 'sam', 'lts', 'course', 'menu', 'laro', 'daw', 'tayo', 'truth', 'feckkk', 'bash', 'write', 'fanfic', 'videos', 'windows', 'spotify', 'hulu', 'news', 'von', 'trapp', 'family', 'lodge', 'dfp', 'ecb', 'yorkshire', 'premier', 'doncaster', 'suffer', 'heavy', 'angel', 'diffffff', 'lololol', 'wbu', 'anytime', 'a l w a y s', 'girlfriend', 'nude', 'flow', 'putos', 'compare', 'fools', 'gold', \"acapulco's\", 'kangin', 'gomawo', 'cap', '140525', 'roomate', 'waves', 'whippin', 'bruh', 'hotter', 'ugh', 'malik', 'edwards', 'pissed', 'aku', 'kau', 'drivin', 'pickin', 'upp', 'mau', 'folbackk', 'rip', 'diet', 'boxes', 'krispy', 'kreme', 'mep', 'assorted', 'original', 'glazed', 'wew', 'alone', 'hol', 'paid', 'bring', 'napa', 'club', 'lacura', 'cash', 'friday', 'lookin', 'macklemore', 'uncontrolable', 'punch', 'pillow', 'vauxhall', 'vectra', 'signum', 'wiper', 'linkage', 'push', 'rod', 'nextday', 'delivery', 'option', 'almarhum', 'sultan', 'azlan', 'shah', 'taylor', 'lautner', '21', 'dapat', 'gif', 'half', 'relate', 'fwit', 'miami', 'adress', 'chaffey', 'pumba', 'africa', 'sang', 'hakuna', 'matata', 'parties', 'hayley', 'levi', 'probs', 'forney', 'lekan', 'bussing', 'xox', 'unfollow', 'xf', 'theme', 'dashboard', 'yisus', 'craist', 'christina', 'perri', 'announcements', 'longest', 'shut', 'beff', 'beefff', 'whatchu', 'hiccup', 'btcs', 'smile', 'dass', 'geocaching', 'container', 'geocachinggeo', 'pictures', 'foh', 'tysm', 'hsgdfhjfg', 'yours', 'gets', 'dieing', 'shri', 'gopinath', 'munde', 'taken', 'oath', 'undercover', 'rapper', \"suju's\", 'eunhyuk', \"shinee's\", \"a's\", 'jia', 'fei', 'spotted', \"exo's\", 'sekalian', 'siapa', 'tau', 'kita', 'jodoh', 'inf', 'responds', 'criticism', 'delayed', 'steaming', 'yau', 'tei', 'vendor', 'imessage', 'bbm', 'disfavor', 'microsofts', 'efforts', 'vme', 'restful', 'condone', 'epidemic', 'vyd', 'correction', 'webster', 'programme', 'tnt', '7pm', 'betwn', 'golf', 'chelsea', 'release', 'elephants', 'cass', 'shame', 'juicer', 'dusty', 'kettle', 'dayum', 'folks', 'directions', 'findom', 'purpose', 'serving', 'empty', 'meaningless', 'thang', 'fa', 'bish', 'whet', 'lmaoo', 'plans', 'sakit', 'dibdib', 'pagkikita', 'isabelle', 'samuel', 'lately', 'una', 'amistad', 'bullying', 'debe', 'ser', 'muy', 'aburrida', 'looove', 'mj', 'jt', 'kinda', 'kiddn', 'nana', 'smokin', 'blunt', 'peewee', 'longway', 'mm', 'delivers', 'bamm', 'pooh', 'kid', 'trial', 'faggots', 've', 'evidence', 'obl', 'afia', 'spy', 'armbanduhr', 'kamera', 'cam', 'camera', '4gb', 'plex', 'plexby', 'inc', 'visit', 'sellers', 'appstore', 'deserve', 'break', 'draw', 'innocent', 'scammer', 'jalah', 'porscha', \"5'7\", 'photobooth', 'cousin', 'recently', 'urge', 'sukhwinder', 'chaiyya', 'dom', 'botak', 'brothers', 'avicii', 'nicky', 'romero', 'audrio', 'tullow', 'oil', 'plc', 'norway', 'bsjfnskf', 'yess', 'booo', 'homee', 'lau', '2431', 'grateful', 'overtime', 'heh', 'super', 'feet', 'sj', 'members', 'feets', 'hahahahahahahahah', 'wore', 'lee', 'yeon', 'hee', 'jessica', 'nicki', 'minaj', 'pills', 'potions', 'become', 'teammates', 'sep', 'bothered', 'txt', 'dnt', 'thts', 'fry', 'plantain', 'meself', 'dem', 'nyam', 'horan', 'front', 'row', 'sweating', 'hgdsfs', 'kathryn', 'bernardo', 'janella', 'salvador', 'liza', 'soberano', 'julia', 'barretto', 'feelings', 'bedroom', 'barbie', 'isra', 'miraj', '27', 'rajab1435', 'moslem', 'skinny', '16', 'debacle', 'giro', 'stelvio', 'gavia', 'passes', 'trouble', 'eduard', 'vorganov', 'kris', 'moodboster', 'emo', 'haiss', '27k', 'control', 'loca', 'nowplaying', 'breath', 'matt', 'redman', '80', 'dave', 'ward', 'swerving', 'through', 'cars', 'gigi', 'hadid', 'pippen', 'winky', 'otherwise', 'ring', 'ding', 'stank', 'water', 'scents', 'amazed', 'shyt', 'sultanahmet', 'camii', 'mosque', 'needs', 'recognition', 'deserves', 'agreed', 'terms', 'general', 'clown', 'shopping', 'mum', 'ee', 'megan', 'batoon', 'hella', 'walked', 'neighbours', 'forget', 'pooper', 'scooper', 'sore', 'shakin', 'bakin', 'dead', 'gifs', 'whytsb', 'sox', 'broadcaster', 'jerry', 'remy', 'pleads', 'guilty', 'murder', \"girlfriend's\", 'stabbing', 'trend', '12', 'kst', 'share', 'nagtagumpay', 'siya', 'movin', 'twerk', 'emoji', 'fansites', 'merch', 'lightsticks', 'logo', 'stamps', 'venue', 'multiple', 'oomfs', 'everytime', 'attractive', 'friendship', 'hahahahaha', 'cnj', 'proud', 'od', 'ctying', 'domtvyal', 'nino', 'sleaze', 'aka', 'naeem', 'illness', 'spree', 'complain', 'unfollowing', 'idiots', 'fancam', 'machine', 'kyungsoo', 'dyo', 'slikaj', 'se', 'cigaretom', 'ustima', 'stavi', 'opis', 'suddenly', 'nothing', 'pete', \"fob's\", 'sao', 'paulo', 'brazil', 'thousands', 'pizzas', 'ras', 'tafari', 'exhibition', 'addis', 'abeba', 'national', 'museum', 'ty', 'tattered', 'dwnld', '754', 'presscon', 'trans', 'credit', 'rahul', 'dravid', 'vain', 'chuckled', 'fwiw', 'pessimistic', 'rivers', 'outlook', 'bidge', 'cambiame', 'el', 'dia', 'nam', 'goong', 'min', 'greatly', 'impressed', 'wife', 'jin', 'wwa', 'tickets', 'knew', 'craycray', 'ayebody', 'enemies', 'shawty', 'cities', 'moving', 'crazy', 'naiiyak', 'kay', 'noise', 'cancelling', 'headphones', 'expensive', 'counterparts', 'kobe', 'yuri', 'seohyun', 'sooyoung', 'taeyeon', 'cinta', 'slow', 'motion', 'bagi', 'suka', 'juwita', 'hawt', 'joe', 'yurself', '24th', 'fx', 'sudirman', 'lb', 'floor', 'entry', \"here's\", 'snippet', 'rtwt', 'emotionally', 'unstable', 'rell', 'ruga', 'harder', 'pause', 'gunplay', 'mee', 'pleasee', 'dayy', 'mob', 'embryology', 'nastier', 'dig', 'ish', 'sportseoul', 'gong', 'hyojin', 'wook', 'dating', 'dimension', 'mix', 'larissa', 'deejay', 'lynn', 'boylan', \"ireland's\", 'poppin', 'perfeito', 'imbecis', 'trey', 'songz', 'belong', 'risky', 'summerbee', 'honeythief', 'slap', 'kiss', 'senja', 'mblooo', 'khris', 'davis', '105', 'current', 'nori', '78', 'peter', 'mansbridge', 'legacy', 'knowlton', 'nash', 'akalem', 'te3mel', 'msh', '3yza', 'terod', '3alaya', 'pick', 'swifty', 'roflmao', 'pitch', 'cent', 'excuse', 'ol', 'cakes', 'briefly', 'exposed', \"go's\", \"thot's\", 'starbucks', 'insomina', 'bitter', 'imo', 'nfc', 'td', 'wilson', 'palmer', 'kaepernick', 'bradford', 'molson', 'habs', 'cupcakes', 'icings', 'higher', \"zayn's\", 'notes', 'double', 'chocolate', 'cookies', 'nutella', 'caramel', 'stuffed', 'chip', 'coo', 'minecraft', 'herobrine', 'sighting', 'sami', 'zayne', 'breeze', 'nxt', 'hopefully', 'parts', 'order', 'route', 'anna', 'passey', 'wears', 'nadine', 'merabi', 'similar', 'astray', 'frame', 'painted', 'build', 'owner', 'juni', 'camaro', 'terima', 'kasih', 'exempli', 'gratia', 'straight', 'almsman', 'contemporary', 'armuelles', 'panama', 'adzt', 'voting', 'garfield', 'minmin', 'regional', 'paper', 'poised', 'ph', 'gycj', 'shuit', 'hsit', 'shitihsthiaht', 'shitb', 'hay', 'yuk', 'comate', 'landaan', 'defo', 'prod', 'shortz', 'sb', 'hitt', 'episode', 'cabela', 'iridescent', 'ravi', 'bffs', 'asa', 'tooo', 'tunee', 'ahh', 'dun', 'daughter', 'kacang', 'jutek', 'prelude', 'tenshi', 'assista', 'reality', 'jbjb', 'orang', 'jan', 'lupa', 'slept', 'lastnight', 'wide', 'awake', 'ayeee', 'soff', 'wrng', 'kfc', 'fries', 'sajc', 'notifies', 'peoples', 'stuff', 'power', 'asshats', 'diss', 'constantly', 'mildly', 'quite', 'haja', 'karate', 'wudu', 'began', 'fart', 'jen', 'forwood', 'minding', 'klaroweak', 'shop', 'fangirled', 'dslr', 'mirrorless', 'interchangeable', 'lens', 'cc', 'youuu', 'especially', 'vanity', 'fixing', '150k', 'brazillian', 'skull', 'sayin', 'prayer', 'weekdays', 'weekends', 'chocka', 'watcha', 'watches', 'soccer', 'rightnow', 'bloke', 'kyle', 'strangely', 'gyllenhaal', 'donnie', 'darko', 'fave', 'lorde', 'gosh', 'rlly', 'depressed', 'laughinf', 'girlish', 'pink', 'english', 'study', 'sesh', 'halina', 'favre', 'celebrating', 'hurts', 'grande', 'merda', 'jogo', 'mais', 'mariokart', 'favorites', 'wow', 'user', 'misleading', 'dyke', 'chapstick', 'bordering', 'femme', 'bosh', 'culd', 'playin', 'loce', 'gona', 'cronicon', 'observer', 'page', 'triumphant', 'draws', 'hitlist', 'seats', 'strom', 'commons', 'amount', 'bouncing', 'walls', 'jorok', 'wahh', 'princes', 'fiona', 'test', 'spazzing', 'tepatin', 'jus', 'crank', 'nahhh', 'scrap', 'srs', 'sloppy', 'muscle', 'wristphone', 'smartwatch', 'ala', 'feature', '800', 'ribuan', 'argue', 'flatout', 'hoodie', 'wildly', 'zuck', 'aegyo', 'paker', 'ka', 'wyd', 'salah', 'leaves', 'jihadis', 'hardliners', 'fume', \"sharif's\", 'shower', 'dressed', 'nothin', 'fm', 'bharat', 'mata', 'jaden', 'triston', 'parrilla', 'dona', 'mundo', 'epd', 'blk', '30th', 'twenty', 'unknown', 'weapons', 'throating', 'edward', 'snowden', 'stranded', 'russia', 'huffington', 'mane', 'jang', 'nigeria', 'numerous', 'elder', 'basking', 'ocean', 'ignorance', 'luv', 'drink', 'modestly', 'corso', 'mediterraneo', 'torino', 'traffic', 'counter', 'trafficflow', 'shaquille', 'morgan', 'forgot', 'np', 'girlieo', 'rmx', 'hail', 'naija', \"e'concern\", 'permissible', 'joomla', 'monogenesis', 'services', 'ex', 'samiflabs', 'iym', 'jail', 'hahahahahhahaha', 'dmvan', 'nils', 'trip', 'hem', 'hiero', 'akxndknd', 'warm', 'milk', 'ambien', 'hailee', '1405254', 'strokes', 'strained', 'goodd', 'kitchen', 'ten', 'washed', 'fork', 'concentrate', 'fairness', 'ganda', 'devon', 'seron', 'cattitude', 'yas', 'noticed', 'scientists', 'achieve', 'reliable', 'quantum', 'teleportation', 'concept', 'data', 'shows', 'flash', 'stacys', 'kenia', 'subtweeting', 'kats', 'york', 'nyankees', 'ranked', 'experienced', 'ascend', 'kul', 'raptr', 'dood', 'stayed', 'ville', 'wowzers', 'toys', 'registered', '100mb', 'internet', 'guna', 'mb', 'je', 'haihhh', 'membazir', 'jeeeee', 'sped', 'benzy', 'envy', 'causin', 'frenzy', 'hackd', 'wuddup', 'nonton', 'wkwk', 'lu', 'hun', 'cie', 'kangen', 'gelo', 'alex', 'clowning', 'funniest', 'nath', 'arguing', 'patt', 'rapping', 'nick', 'doubles', 'meps', 'london', 'harradox', 'gary', 'oldman', 'en', 'grace', 'derrito', '4v4', 'snd', 'wager', 'scump', 'nadeshot', 'proofy', 'biggy', 'stressin', 'shoes', 'psh', 'bra', 'bouta', 'scoop', 'hills', 'ohmygad', 'minzy', 'posing', 'hahahahhaa', 'action', 'romance', 'train', 'pics', 'keeps', 'shutup', 'grown', 'bulls', 'joakim', 'noah', 'skips', 'practice', 'personal', 'fxck', 'smoked', 'smoke', 'favorited', 'cloudcast', 'mixcloud', 'kik', 'use', 'wld', 'interesting', 'salmond', 'fund', 'itself', 'investment', 'privatisation', 'management', 'sincerely', 'muaythai', 'standin', 'garie', 'nighas', 'famous', 'social', 'networks', 'jetski', 'ost', 'sbs', 'drama', 'surrounded', 'seunggi', 'ara', 'writin', 'bullshit', 'weeks', 'governor', 'andhra', 'pradesh', 'additional', 'job', 'telangana', 'lindsay', 'youtuber', 'grab', \"gf's\", 'infront', 'ohh', 'buht', 'dads', 'chillis', 'siblings', 'lewl', 'stack', 'intip', 'poster', 'terbaru', 'horor', 'kanibal', 'inferno', 'vittoria', 'wcw', 'hahahahahha', 'part', 'wheelchair', 'baba', 'kejri', 'appiled', 'bail', 'according', 'criminal', 'hhahah', 'tooooooo', \"what's\", 'unrest', 'economies', 'struggling', 'lakas', 'maka', 'qualities', 'winner', 'thiiisss', 'boooyyyy', 'deemm', 'niggaas', 'esp', 'manusia', 'ramah', 'erected', 'middle', 'phase', 'mamelodi', 'grieving', 'pressed', 'mommy', 'early', 'enuhh', 'suh', 'mah', 'pree', 'item', 'etsy', 'natural', 'whitby', 'sea', 'jet', 'sterling', 'silver', 'earrings', '625', 'murray', 'matosevic', 'halep', 'uk', 'wan', 'chai', 'considered', 'burgers', 'hk', 'fed', 'pj', 'wil', 'flowing', 'shid', 'seems', 'fyck', 'ut', 'telly', 'coke', 'gtfo', 'remove', 'bru', 'markit', 'pmi', 'prelim', 'exp', '55', '54', 'celoteh', 'promo', 'status', 'iklan', 'terkoneksi', 'favelas', 'pharaoh', 'favela', 'iw', 'lazy', 'map', 'mw2', 'supposed', 'attend', 'event', 'dormagen', 'cancelled', \"he'll\", 'followed', 'tips', 'flu', 'skip', 'braai', 'ade', 'gua', 'tak', 'kisah', 'ehmm', 'maksudnya', 'ktbffh', 'fear', 'zoo', 'hosted', 'moondawg', 'downloaded', 'diablo', 'hahahhahahaha', 'wae', 'uso', 'opener', 'brad', 'pathetic', 'slippin', 'woke', 'checked', 'satin', 'pleaseeeee', 'ginebra', 'puso', 'shon', 'minho', 'dukhwa', 'baes', 'reunited', 'woo', 'mv', 'move', 'block', \"b's\", 'kyung', 'hve', 'eve', 'amorsito', 'contestas', 'whap', 'donjazzy', 'korede', 'bello', 'pose', 'newbie', 'masih', 'imut', 'meanwhile', 'thi', 'wo', 'jo', 'shareef', 'kheench', 'layiii', 'fay', 'futur', 'whithout', 'hesitation', 'themselves', 'whore', 'tees', 'cotton', 'combed', '30s', 'regular', 'idr', '115k', 'size', 'sms', '323823b9', 'together', 'kuys', 'alam', 'naks', 'talor', 'crossing', 'adopted', 'anyway', 'footy', '92', 'grounds', 'fancy', '26th', 'july', 'burton', 'walsall', 'crewe', 'wolves', 'law', 'enforcement', 'officers', 'ceremony', 'rancho', 'cucamonga', 'victorville', 'press', 'dbhdjddn', 'interview', 'audi', 'marketing', 'director', 'jorg', 'dietzel', 'kind', 'hearted', 'choi', 'qpr', 'heathrow', 'prob', 'kagome', 'inuyasha', 'beckett', 'pitches', 'phillies', 'transformed', 'pitc', 'stress', 'tgk', 'indie', 'spotlight', 'korey', 'troyer', 'bantal', 'busuk', 'elias', 'foot', 'currently', 'perpustakaan', 'negara', 'classmate', 'itching', 'scratchin', 'dtfl', 'bonnaroo', 'xi', 'seungyoon', 'tablo', 'hahahha', 'galaxy', 'leggings', 'outer', 'space', 'mayweather', 'ti', 'tiny', 'hoein', 'nem', 'pull', 'zouis', 'sitting', 'scooby', 'doo', 'mystery', 'lighting', 'scrolling', 'andrew', 'bros', 'signin', 'record', 'lookout', 'lala', 'rory', 'idek', 'mewah', 'deluxe', 'rooftop', 'garden', 'sian', 'le', 'lah', 'ytd', 'pms', 'isit', 'everbody', 'wham', 'bohot', 'mazak', 'uda', 'li', 'ki', 'serious', 'lines', 'suppose', 'special', 'cure', 'cancer', 'brag', 'ohhh', 'hurry', 'messer', 'shmit', 'piqaisa', 'watty', 'writer', 'snow', 'ghad', 'entertain', 'soft', 'ashley', 'greene', 'roush', 'taps', 'trevor', 'bayne', 'biffle', 'sweetseventen', 'bang', 'semoga', 'makin', 'jago', 'sepakbolanya', 'youo', 'paolo', 'nutini', 'gay', 'watercolor', 'printable', 'scrapbooking', 'invitations', 'crafting', 'pers', 'mornin', 'sugah', 'muffins', '25th', 'daim', 'arkandayiz', 'kimmis', 'bikini', 'waab', 'waow', 'sat', 'stalking', 'bestfriends', 'unless', 'henry', 'clay', 'wanted', 'cavalier', 'choco', 'hazelnut', 'spread', '200g', 'physical', 'uber', 'gang', 'tara', 'maki', 'mamaya', 'desire', 'passed', 'comment', 'misandry', 'cedar', 'sanderson', 'catching', 'rare', 'x73', 'lames', 'popsicles', 'snl', 'reruns', 'kym', 'uko', 'fire', 'hart', 'problema', 'mga', 'tao', 'izzie', 'belle', 'finds', 'vc', 'topo', 'classificados', 'published', 'aappu', 'kannukku', 'theriyadhudioi', 'vare', 'siva', 'ohoi', 'rest', 'promotion', 'campaigns', 'mei', 'shuo', 'weibo', 'tmr', 'dwm', 'balmy', 'ina', 'mural', 'justice', 'yay', 'bb', 'jane', 'mag', 'load', 'cardio', \"wasn't\", 'thundercat', '2k', 'tomar', 'spongebob', 'butterfly', 'handle', 'ii', 'workk', 'diba', 'jkasb', 'bomb', 'fu', 'reckon', 'frank', 'sinatra', 'friggin', 'jam', 'missing', 'hm', 'breed', 'hoop', 'raw', 'livin', 'banger', 'youve', 'ears', 'addicted', 'extend', 'reciprocate', 'broads', 'catfished', 'dc', 'rappers', 'frivgawd', 'catfish', 'yep', 'confirmed', 'pre order', 'hannah', 'battles', 'deadly', 'disease', 'gue', 'males', 'kenal', 'sm', 'lo', 'seein', 'cat', 'wh', 'bby', 'bein', 'whether', 'dealin', 'movie', 'revolved', 'mostly', 'jackman', 'mcavoy', 'fassbender', 'patrick', 'stewart', 'sinyao', 'tuition', 'cheering', 'destination', 'kuala', 'lumpur', 'blackjack', 'thay', 'jongin', 'jumped', \"baek's\", 'hugged', \"kyungsoo's\", 'lifted', 'niccur', 'alomo', 'rules', 'kush', 'follback', 'yellow', 'bike', 'yixing', 'net', 'sachin', 'tendulkar', 'maharashtra', 'textbooks', 'chapter', 'erection', 'tenderly', 'kissing', 'cuddling', 'bottom', 'mmmmm', 'xx', 'quote', 'wizkid', 'davido', 'performance', 'trek', 'enough', 'favour', 'decima', 'oblock', '300', 'yu', 'otl', 'starving', 'harvest', 'etienne', 'francey', 'aready', 'bea', 'uncles', 'touched', 'angry', 'telekinesis', 'austin', 'mahone', 'ojt', 'hs', 'logitech', 'wireless', 'microphone', 'playstation', 'playsta', 'yy', 'h00y', 'fayo', 'salud', 'campeon', 'retarted', 'dum', 'uhhm', 'crib', 'change', 'sumn', 'presence', 'dipper', 'haters', 'nikkaz', 'herro', \"apink's\", 'virus', 'bows', 'reduced', 'ugg', 'australi', 'longer', 'atleast', 'boys', 'band', 'olds', 'guest', 'icarly', 'busy', 'asf', 'boutta', 'schleep', 'lots', 'kdrama', 'ibu', 'nenek', '136', 'ikuti', \"men's\", 'biore', 'heroes', 'karebosi', 'askin', 'reavis', 'blakely', 'dish', 'smc', 'thas', 'walkoff', 'slam', 'herndon', 'baylor', 'tongue', 'flippin', 'color', 'vivid', '1988', 'beyond', 'sectarian', 'divide', 'gerry', 'caroll', 'profit', 'councillor', 'belfast', 'breakthrough', 'sicker', 'aache', 'din', 'aa', 'rahe', 'hain', 'scooty', 'indicator', 'turned', 'yuh', 'actin', 'groupy', 'sexting', 'shap', 'thrift', 'quate', 'jgn', 'ngert', 'commemorate', 'wal', \"mi'raj\", 'delhi', 'dmu', '74024', 'reached', 'dli', '70', 'bo', 'greenlee', 'mound', 'wsr', 'threw', 'pitched', 'offseason', 'goku', 'searching', 'dragonbooty', 'convo', 'username', 'rather', 'eiichiro', 'oda', 'sensei', 'tonsillitis', 'operation', 'op', 'bir', 'haftada', \"got'u\", \"op'u\", 'kaybetmek', 'koydu', 'stunt', 'preggo', 'paying', 'lic', 'dstv', 'injury', 'accident', 'crk', 'rd', 'shadeland', 'ave', 'bitchin', 'bitchez', 'somethin', 'rewatching', 'soul', 'ema', 'cv', 'successful', 'xrated', 'cobra', 'cleveland', 'flyest', 'motonio', 'fly', 'searchcap', 'ripoff', 'yahoo', 'google', 'bing', 'webmaster', 'roadshow', 'below', 'powerful', 'yowapedal', 'yaoipedal', 'thirsty', 'fuack', 'alright', 'track', 'unfollowers', 'yamcha', 'fuckboy', 'dapatkan', 'gratis', 'hingga', '1000', 'setiap', 'hari', 'disini', 'eric', 'stonestreet', 'beefs', 'perceived', 'laundry', 'lieve', 'calo', 'euro', 'stabile', 'economia', 'biryhday', 'rizhal', 'rizky', 'loveyou', 'weirdest', 'drew', 'seeley', 'waverly', 'soundtrack', 'gim', 'mami', 'barao', 'dillashaw', 'lets', 'reply', 'wrked', 'n64', 'pikachu', 'console', 'expansion', 'pak', 'controllers', 'ebay', 'price', 'usd', '28', 'bids', 'wale', 'yanish', 'marshall', 'finals', 'nun', 'adharm', 'ghada', 'bharta', 'deepak', 'chorasia', 'jaise', 'paida', 'hota', 'bhagao', 'isey', 'defenders', 'lebrons', 'attacking', 'freak', 'busted', 'laughin', 'tip', 'shoulda', 'ripped', \"tiny's\", 'necklace', 'm5', 'months', 'ughhhhh', 'fernando', 'torres', 'liverpool', 'steven', 'gerrard', 'reveale', 'address', 'meri', 'marigold', 'dvd', 'tujhe', 'bhej', 'rah', 'mere', 'bhai', 'yaa', 'diggg', 'mufasa', 'bah', 'gemorning', 'bxtch', 'watched', 'dil', 'chahta', 'sydney', 'treat', 'mdm', 'lim', 'jn', 'muahaha', 'fucked', 'beatin', 'betta', \"la'che\", 'samantha', 'kecanduan', 'sehari', 'meimei', 'mwahaha', 'virginia', 'crap', 'elaborate', 'desabafa', 'com', 'deus', 'ele', 'entende', 'nibo', 'omeruo', 'z', '40m', 'fnk', '75', 'inside', 'trending', 'worldwide', 'smtownengsub', 'patton', 'boggs', 'squire', 'sanders', 'formerly', 'merger', 'businessnews', 'atlanta', 'ewnjap', '140528', 'apink', 'eunji', 'kbs', 'trot', 'lover', 'brodcast', '23rd', 'foolie', \"father's\", 'genes', 'cum', 'daughters', 'tall', 'whatz', 'secret', 'enormous', 'growth', 'aishwarya', 'rai', 'surgery', 'deffo', 'resist', 'brownies', 'knooow', 'actress', 'eun', 'weds', 'manager', 'excellent', 'quare', 'craic', 'tgi', \"friday's\", 'artic', 'wokingham', 'tories', 'wea', 'afgan', 'sunod', 'kong', 'babasahin', 'mina', 'esguerra', 'thoee', 'theyr', 'fucjing', 'tasha', 'xbox', 'gamertag', 'nearly', 'bota', 'esquisito', 'nisso', 'total', 'tuscany', 'spring', 'alessandro', 'ferretti', 'xiumin', 'buttercup', 'working', 'women', 'wrre', 'ninja', 'until', 'talkn', 'gleesh', 'sounded', 'chief', 'keef', 'diwn', 'syndrome', 'lmfaoooo', 'roy', 'cream', 'drop', 'ground', 'yellin', 'refer', 'belo', 'mbeya', 'yatinga', 'robo', 'fainal', 'nil', 'basin', 'ryeowook', 'hint', 'boba', 'fett', 'mumbai', 'suprised', 'namo', 'suprise', 'minimum', 'governance', 'apart', 'vaccations', 'cowok', 'keren', 'stans', 'putangina', 'hahahsahahaha', 'random', 'rightt', 'naa', 'run', 'fantasy', 'mini', 'managers', 'stc', 'cannot', 'fckn', 'thnx', 'connect', 'erg', 'toffe', 'vooral', 'yelling', 'ref', 'tackled', 'aw', 'utica', 'vut', 'jump', 'conclusions', 'attacks', 'base', 'personnel', 'feared', 'killed', 'polis', 'ape', 'ssh', 'kahkahkah', 'snapchated', 'luna', 'colombiana', 'cm', 'dotacion', '603258528', 'anni', 'ngalong', 'yeshh', 'voy', 'matar', 'dinner', 'goodevening', 'quoting', 'spongbob', 'smash', 'mewtwo', 'cozy', 'childrens', 'decor', 'lakers', 'kd', 'rings', 'yor', 'fakin', 'jands', 'depok', 'atp', 'analysis', 'djokovic', 'joins', 'federer', 'death', 'nadal', 'ferrer', 'co', 'announce', 'lovatics', 'hostel', 'pasukan', 'less', 'puyat', 'lifesciences', 'corp', 'nyse', 'medtronic', 'fak', 'besh', 'stockton', '51', 'justunfollow', 'trick', 'spinning', 'rated', 'mix032', 'union', 'tunein', 'winamp', \"app's\", 'knowing', 'pe', 'righ t', 'spend', 'hunnid', 'dollas', 'bcz', 'familiar', 'superman', 'rays', 'navier', 'eyewear', 'wen', 'clinching', 'title', '89', 'promotio', 'warris', 'closely', 'vladimir', 'putin', 'magically', 'appears', 'selamat', 'pagi', 'lewwwl', 'imagine', 'ungrateful', 'liquid', 'lolol', 'editing', 'mixing', 'tracks', 'mastering', 'seperate', 'package', 'rates', 'nat', 'ole', 'ola', 'fifa', 'olodum', 'damaging', 'prettier', 'cracknell', 'tory', 'paty', 'south', 'kenny', 'upset', 'nephews', 'bautizo', 'jenny', 'ran', 'jose', 'pickney', 'nuh', 'stick', 'adorable', 'tracksuit', 'laughter', 'ended', 'lik', 'carfax', 'happend', 'tila', 'tequila', 'bell', 'bashes', 'labels', 'irresponsible', 'manam', 'wos', 'hearty', 'congratulations', 'dearest', 'nagarjuna', 'garu', 'busog', 'naman', 'mortal', 'talaga', 'indians', 'indies', 'indian', 'involved', 'texas', 'kesha', 'til', 'exactly', 'squaded', 'ballin', 'glamorgan', 'leicestershire', 'commentary', 'scorecard', 'ne', 'feed', 'akademiks', 'avirex', 'stash', 'dada', 'artful', 'dodger', 'lrg', 'ecko', 'list', 'brookfield', 'lockdown', 'situation', 'tiger', 'notice', 'lion', 'cartier', 'queens', 'lucchese', 'omgg', \"weren't\", '5k', 'mvp', 'nudes', 'rccg', 'glory', \"house's\", 'answer', 'jonghyun', 'scalp', 'pala', 'liro', 'lirobel', 'stacy', 'keibler', 'flaunts', 'bump', 'babymoon', 'hubby', 'jared', 'pobre', 'un', 'nei', 'sotterranei', 'sotterraaaaanei', 'figured', 'caught', 'games', 'bindi', 'cornrowing', 'musty', 'attack', 'hibbert', 'respondo', 'role', 'sigo', 'forensic', 'expert', 'testify', 'senator', 'ndume', 'facing', 'charges', 'sponsoring', 'member', 'btob', 'liat', 'bantu', 'unearthed', 'trail', 'ibn', 'battuta', 'grosir', 'macam2', 'sepatu', 'termurah', 'nusantara', 'vans', 'dll', 'grandpa', 'ik', 'hbo', 'channels', 'celtic', 'mackay', 'moyes', 'coyle', 'complaing', 'ela', 'falava', 'anotava', 'procurava', 'decisions', 'myselff', \"thatsojack's\", 'surprise', 'sisi', 'victory', \"egypt's\", 'election', 'coup', 'abdel', 'fattah', 'tove', 'beequnique', 'ukg', 'bukkake', 'rio', 'hamasaki', 'promise', 'piers', 'shouting', 'each', 'spr', 'cpr', 'aid', 'epi', 'pen', 'certified', 'mgmt', 'walk', 'onto', 'leashes', 'warren', 'hernan', 'cattaneo', 'wmc', 'surprised', 'snuck', 'letso', 'dated', 'kgm', 'kissed', 'screamer', 'tottenham', 'whl', 'geylang', 'fc', '11', 'woodlands', 'wellington', 'siddiq', 'durimi', 'khairulnizam', 'jumahat', 'yuki', 'head ache', 'tomorro', 'directioners', 'problem', 'cuff', 'snoop', 'ctfu', 'ano', 'tpos', 'diretso', 'buzz', 'ulit', 'somtimes', 'tots', 'ruin', 'tas', '165rb', 'line', 'lifetime', 'voucher', 'asic', 'bitfury', 'bitcoin', 'mining', 'mh', 'wic', 'gal', 'globe', 'users', 'ohgosh', 'elf', \"who's\", 'bias', 'croker', 'cuteeee', 'sheesh', 'steve', 'steep', 'canyon', 'rangers', 'featuring', 'edie', 'brickell', 'ball', '487', 'cahill', 'thibaut', 'courtois', 'masuk', 'dalam', 'botwe', 'koraa', 'church', 'roses', 'funfair', 'mtchw', \"emily's\", 'nbd', 'assume', 'owa', 'ndaluma', 'cursive', 'poor', 'doodled', 'leedle', 'leeeee', 'zack', 'stokes', 'incheon', 'lamiel', 'simbora', 'gente', 'wee', 'orgasm', 'orgasim', 'fml', 'confused', 'fringed', 'pinata', 'multicolor', 'japan', 'settle', 'bronze', 'olympic', 'xuerui', 'shixian', 'wang', 'congratz', 'disrespect', 'acting', 'sakelah', 'kuy', 'muka', 'bangga', 'pegang', 'thomas', 'maklumlah', 'shawdy', 'laid', 'paymaster', 'held', 'responsible', 'bcos', 'security', 'office', 'presently', 'whitepaper', 'securing', 'domains', 'ssl', 'cants', 'reverbnation', 'charts', 'warner', 'robins', 'ga', 'knoxville', 'noteven', '16gb', 'gsm', 'unlocked', 'smartphone', 'fs', 'mobilepros1', 'waka', 'emotions', 'onions', 'link', 'niqqa', 'island', 'unhuh', 'divs', 'floorball', 'placing', 'match', 'ramos', 'giroud', 'crien', 'tiwa', 'fantaken', '140517', 'mino', '2ne1', 'aon', 'luvely', 'nay', 'dough', 'craving', 'balut', 'penoy', 'except', 'donzell', 'badly', 'popup', 'hati', 'fk', 'neeed', 'camila', 'funaki', \"dinah's\", 'aunt', 'rinatauveli', 'vids', 'greets', 'vanessa', 'hudgens', 'tisdale', 'selena', 'gomez', 'sarah', 'hyland', 'heey', 'important', 'x47', 'comin', 'follower', 'chances', 'lightly', 'sweetface', 'niece', 'dd', 'shriya', 'saran', 'hott', 'sizothi', 'twitpic', 'xhosa', 'boobs', 'huge', 'mkhaba', 'nizothini', 'kengoku', 'feminine', 'version', 'tanzanian', 'ihavnt', 'cx', 'informed', 'undestanrd', 'nyanyi', 'balot', 'pub', 'victorious', 'ruled', 'coalition', 'tanner', \"we've\", 'officially', 'widest', '59', 'sourires', 'contagieux', 'smiles', 'ptr', 'roland', 'emmerich', 'direct', 'stargate', 'reboot', 'effect', 'sleepy', 'waking', 'cycle', 'upsc', 'chaat', 'boro', 'eka', 'lage', 'chowringhee', 'aye', 'whataburger', 'bff', 'hini', '3mron', 'gguide', 'cos', 'ots', 'questions', 'shiavi', 'extremely', 'sorrrrrrrrrrrrry', 'yr', 'chest', 'bar', 'refaeli', 'grimmie', 'catchy', 'kennedy', 'nomi', '500px', 'arthur', 'knocked', 'dw', \"should've\", 'kicked', 'welp', 'strip', 'automatic', 'configuration', 'fone', '08135627853', 'htc', 'hd', 'a9191', 'keinget', 'sama', \"kenang'an\", 'alm', 'ayah', 'bikin', 'air', 'netes', 'dad', 'coolin', 'slight', 'bandana', 'neck', 'sexey', 'silenced', 'fired', 'mother', 'fukuyama', 'ludwig', 'mises', 'fmi', 'hayek', 'friedman', 'psdb', 'niners', 'signed', 'kevin', 'armo', 'youre', 'lush', 'compton', 'chiraq', 'boyfriend', 'above', 'ashtons', 'asdfghjkl', 'feeli', 'manmohan', 'gov', 'va', 'explotar', 'cabeza', 'saints', 'lmbo', 'droppin', 'baling', 'walang', 'wifi', 'iphone', 'discuss', 'aesthetics', 'beaut', 'isco', 'mmmm', 'lansi', 'lanyong', 'gojira', \"aren't\", 'rela', 'sukarelawan', 'mike', 'nkansah', 'ryt', 'americans', 'humour', 'stressing', 'yooara', 'biased', 'joining', 'sumlin', 'aggies', 'tone', 'hellup', 'nickname', 'sendo', 'callin', 'although', 'froch', 'chayse', 'wizz', 'fizz', 'hav', 'gemma', \"macklemore's\", 'whut', 'performed', 'thys', 'battle', 'ryte', 'responding', 'auro', 'spoilt', 'store', 'diecast', 'elliott', 'sadlers', 'dnp', 'bought', 'tons', 'giva', 'inch', 'period', '2day', 'marks', 'tryn', 'ahold', 'pepul', 'il', 'downgrding', 'highschool', 'taught', \"1's\", 'motto', 'crushed', 'tight', 'kinna', 'tough', 'doable', 'tune', 'tarrus', 'riley', 'creation', 'riddim', 'jukeboxx', 'productions', 'villain', 'allways', 'hall', 'geno', 'field', 'warmups', 'unis', 'boling', 'homestuck', 'equius', 'nepeta', 'slim', 'pickins', 'wings', 'podunkville', 'ms', 'missyou', 'comeing', 'cmon', 'pacers', 'psar', 'mlm', 'tluk', 'kmbaq', 'baq', 'hg', 'kattee', 'mens', 'layer', 'cow', 'leather', 'shoulder', 'briefcase', 'attache', 'laptop', 'pair', 'walks', 'sandwiched', 'bases', 'loaded', 'pedroia', 'tobi', 'centimeters', 'taller', 'jaylen', 'hatake', 'kakashi', 'bonus', 'sharingone', 'madara', 'bangers', 'tyneteeswear', 'technip', 'safeguards', 'hundreds', 'tyneside', 'jobs', 'leading', 'cables', 'represents', 'charlet', 'heritage', 'akwa', 'ibom', 'cano', 'cristales', 'colombia', 'tiard', 'lore', 'jokes', 'ongc', 'spuds', 'maiden', 'palar', 'probe', 'wise', 'tupac', 'amaru', 'shakur', \"where's\", 'eggs', 'sorrry', 'bbk', '8010', '76mm', 'lbs', 'cac', 'mass', 'meter', 'mustang', 'mete', 'platinum', 'hearing', 'deserved', 'refuse', 'moms', 'loose', 'bullsh t', 'taeny', 'flight', 'taenygenie', 'beside', 'chewin', 'loud', 'irudfkjlc', 'kuya', 'yanny', 'hugs', 'gigil', 'bugoy', 'farah', 'fishy', 'hahaa', 'freaking', 'jessy', 'unnie', 'montgomerie', 'leads', 'senior', 'pga', 'langer', 'reuters', 'colin', 'sank', 'birdi', 'azalea', 'roko', 'novelty', 'collectable', 'butane', 'cigar', 'lighte', 'pre calc', 'final', 'rough', 'lang', 'aso', 'andrei', 'bottles', 'airrr', 'snsd', 'seniors', 'eyy', 'lying', 'hahahh', 'guydirectioners', 'sympathise', 'ibs', 'citalopram', 'helped', 'biiiig', 'thigh', 'photoshop', 'shailene', 'woodley', 'casually', 'athens', 'pouya', 'wavy', 'joker', 'willie', 'cakap', 'padahal', 'kejriwal', 'tihar', '2mrw', 'uff', 'mayhem', 'chaos', 'cameras', 'mans', 'sleeping', 'stoopid', 'angelina', 'jolie', 'elle', 'review', 'realize', 'x105', 'kee', 'worship', 'tested', 'iont', 'hmm', 'bitlocker', 'versions', 'iirc', 'sjmthanks', 'hyuk', 'buti', 'sina', 'phineas', 'ferb', 'unli', 'vacation', 'classier', 'shorts', 'fringe', 'swifties', 'thankies', 'society', 'altaf', 'hussain', 'uhh', 'reveal', 'jealous', 'b2st', 'vocab', 'markus', 'actd', 'chaebol', 'relatd', 'sageuk', 'citi', 'louie', 'bus', '2011', 'triple', 'beam', 'dreamin', \"niall's\", \"liam's\", 'parents', 'des', \"tonight's\", 'maliks', 'romo', 'dez', 'kaitlyn', 'hibachi', 'gozaimashta', 'offline', 'bsck', 'drill', 'mash', 'smashes', 'farhan', 'ahmad', 'nizami', 'lecture', 'achievements', 'challenges', 'muslim', 'picc', 'blono', 'ridin', 'gotti', 'yadong', 'kmsl', 'bitxh', 'thankiu', 'clingy', 'lols', 'vespa', 'eijk', 'invited', 'cookouts', 'outrageous', 'some1', 'pretend', 'police', 'commissioner', 'batts', 'operations', 'led', 'chong', 'wei', 'badminton', 'upload', 'kyrie', 'irving', 'commercial', 'jackson', 'stays', 'garages', 'michel', 'gondry', 'anderson', 'someday', 'mansion', 'elan', 'lit', 'tonite', 'tellin', 'lance', 'stephenson', 'generic', 'teamed', 'rift', 'civilians', 'army', 'forces', 'revenge', 'plot', 'afg', 'vegas', '27th', 'shooting', 'halla', 'kokane', 'bo2', 'ghost', \"jimmy's\", 'hoagies', 'def', 'sprinkles', 'val', 'settings', 'rugi2', 'ak', 'strt', 'birmz', 'revise', '1966', 'liga', 'cl', 'rm', 'eurovision', 'austria', 'relegated', 'fulham', 'facup', 'england', 'suspect', 'congis', 'offshoot', 'segundon', 'agarro', 'wilo', 'tipa', 'pmsl', 'comfy', 'bug', 'wall', 'starin', 'popcorn', 'han', 'shyad', 'khar', 'chezy', 'adds', 'experiance', 'naah', 'meant', 'bruins', 'continues', 'finalists', 'nhl15', 'subban', 'bergeron', 'amfufu', 'kc', 'akong', 'beryllicious', 'megamall', 'mega', 'anton', 'diaz', 'ikr', 'indy', 'clips', 'rc', 'alfie', 'stan', 'sticking', 'bio', 'perf', 'kissn', 'tattoos', 'essay', 'howie', 'severino', 'visits', 'sitio', 'damayan', 'complex', 'tondo', 'learns', 'flirting', 'nerve', 'flirt', 'hourly', 'happpy', 'xoxo', 'fantastic', 'lettin', 'apperntly', 'swung', 'engaged', 'chibok', 'exemptions', 'huggin', 'aksi', 'tom', 'cruise', 'emily', 'menit', 'showcase', 'beats', 'mcs', 'spittin', 'freshness', 'suit', 'poohgutta', 'flex', 'hbd', 'cuzzo', 'chae', 'updates', 'rainy', 'wem', 'sagt', 'technical', 'pan', 'noch', 'larry', 'filmed', 'byee', 'tehe', \"africa's\", 'promises', 'boost', 'economy', 'jacob', 'shittin', 'lyke', 'portable', 'potty', 'mumpung', 'lmaooooo', 'izinto', 'ezisho', 'nguwe', 'kodwa', 'anc', 'seventh', 'created', 'bandanas', 'sica', 'beep', 'yoona', 'bounce', 'gah', 'arm', 'business', 'karan', 'thapad', 'moron', 'sed', 'kapatid', 'pistol', 'totin', 'cuss', 'patek', 'philippe', '76536660', '085278738770', 'hittin', 'hno', 'thryyre', 'headin', 'indirecting', 'eachother', 'nilikua', 'nalala', 'selo', 'blink', 'obsessed', 'fabulous', 'suck', 'homo', 'wnt', 'haircuts', 'cuts', 'hita', 'sista', 'substitution', 'eamon', 'byrne', 'stephen', 'courtney', 'daly', 'thz', 'chicano', 'movment', 'stoltz', 'recurring', 'nightmare', 'dumps', 'fox', 'anthony', 'gallo', 'rdinator', 'annual', 'thanx', 'chat', 'upcoming', 'french', 'rain', 'novak', 'iya', 'ciel', 'teresa', 'sand', 'sculpture', 'ek', 'deko', 'agar', 'mila', 'clearly', 'stretch', 'serge', 'perimeter', 'okc', 'rarely', 'acttually', '17', 'den', 'dutch', 'pot', 'bun', \"it'll\", 'wrk', 'bron', 'usually', 'awful', 'ways', 'clep', 'american', 'literature', 'pratice', 'tests', 'trees', 'unique', 'willing', 'professional', 'boxer', 'ova', 'kfans', 'korean', 'accent', 'rick', 'ross', 'devil', 'soldiers', 'policemen', 'buni', 'yadi', 'yobe', 'shoot', 'spiceworld', 'totp', 'mariah', 'carey', 'rich', 'quan', 'katt', 'williams', 'epps', 'duval', 'mourning', 'ame', 'fwm', 'waste', 'wright', 'zaza', 'sharmas', 'daant', 'dabas', 'janu', 'flyod', 'fights', 'los', 'solo', \"baekhyun's\", 'grandma', 'fanboy', 'saving', \"5'8\", 'woow', 'hear', 'smth', 'didn', 'snoke', 'heoin', 'somehow', 'anywayy', 'smally', '2many', 'chicks', 'viners', 'youtubers', 'kys', 'errm', 'raped', 'rapists', 'baru', 'netas', 'miliband', 'replying', 'jalepeno', 'pepper', 'dared', 'sware', 'coffee', 'scrolls', 'wann', 'menuju', 'gathering', 'zero', 'yoohoo', 'justins', 'atm', 'whattt', 'qaeda', 'hesitate', 'react', 'cook', 'baker', 'pq', 'corporation', 'producer', 'specialty', 'inorganic', 'performa', 'kin', 'papi', 'lamenting', 'awa', 'abby', 'amik', 'gambar', 'holds', 'har', 'awkward', 'turtle', 'koala', 'hyeriester', 'kouhai', 'fulfil', 'cry', 'broken', 'looooh', 'bamboo', 'dimsum', 'yass', 'gimmie', 'xp', 'divya', 'biswal', 'mortgage', 'uw', 'lab', 'deven', 'tatlong', 'araw', 'nalang', 'matatapos', 'yung', 'bookworm', 'influence', 'ouran', 'kyoya', 'dixk', 'fail', 'studyin', 'faceplant', 'selenas', 'tries', 'jelena', 'shippers', 'eager', 'irom', 'sharmila', 'svp', 'lunch', \"couldn't\", 'ans', 'akshay', 'kumar', 'fugly', 'ice', 'baskins', 'asia', 'alli', 'pocket', 'hueee', 'dann', 'ich', 'mal', 'gespannt', 'wie', 'million', 'ist', 'karangan', 'migos', 'carshow', 'dallas', 'turnt', 'beaten', 'four', 'five', 'copa', 'beer', 'barefoot', 'country', 'swayin', 'fadin', '9120', '912', 'caldo', 'engrosssssa', 'rede', 'globo', 'digo', 'khloe', 'function', 'sitten', 'ac', 'ship', 'smashwords', 'betsy', 'multichannel', 'preordered', 'tesco', 'blinkbox', 'library', 'namjoon', 'huhuhuu', 'nmd', 'era', 'jpn', '360', '8th', 'grade', 'soloist', 'releasing', 'follows', 'places', 'faculty', 'straddleback', 'holidays', 'burkina', 'faso', 'lies', 'cropped', 'tee', '75k', 'kuota', 'tiap', 'respond', '087780566955', '2af838cb', 'flashback', 'punk', 'concerned', 'bust', 'cryin', 'dry', 'include', 'cf', 'ehhh', 'comel', 'bhahahaha', 'scotty', 'heffernan', 'ugliest', 'paella', 'hobart', 'btchs', 'sum', 'retweeting', 'ones', 'versaemerge', 'fixed', 'stadium', 'sunderland', 'wner', 'usmc', 'semper', 'marines', 'lon', 'amor', 'ahahaha', 'brian', 'eno', 'strange', 'overtones', 'roommate', 'lady', 'chrissie', 'makarova', 'scrappy', 'stfd', 'carter', 'frappuccino', 'judgin', 'edit', 'fil', 'wellllll', 'fault', 'raining', 'arani', 'tamilnadu', 'winds', 'refreshing', 'hape', 'suegra', 'dere', 'xan', 'warmup', 'interested', 'toy', 'igual', 'wrry', 'thoughts', 'patama', 'thingys', 'soooooo', 'kiddie', 'tanaiste', 'taoiseach', 'tmw', 'reshuffle', 'tidaman12', 'circa', '1990', 'mr', 'hoppy', 'tubbies', 'rice', 'odu', 'tentatively', 'scheduled', 'lamedale', 'pumped', 'books', 'accidentally', 'ridge', 'lake', 'llamas', 'draco', 'dormiens', 'nunquam', 'titillandus', 'kyu', 'ahjumma', 'bags', 'beating', 'shade', 'wantin', 'fukk', 'wrote', 'yearbook', 'becuz', 'niga', 'response', 'logan', 'bumpin', 'fix', 'yur', 'headline', 'jokowi', 'tersangka', 'kasus', 'korupsi', 'transjakarta', 'satnite', 'absolutely', 'kelty', 'didny', 'ken', 'princess', 'dealema', 'gap', 'bom', 'touch', 'shout', 'crooz', 'jakcloth', 'kamis', 'merapaaaat', 'wohooo', 'milktea', 'otw', 'tummy', 'ting', 'shilpa', 'subhash', 'borse', 'interest', 'badla', 'sara', 'zamana', 'rajesh', 'vyas', 'indeed', 'awakening', 'article', 'discussion', 'agad', 'hahahaa', 'streets', 'dirt', 'hurtin', 'jajajajajaja', 'dije', 'highlights', 'nysc', 'fuel', 'tanker', 'kwara', 'sila', 'kapag', 'horrible', 'ato', 'kaga', 'terserah', 'glasses', 'dx', 'roots', 'hafto', 'statement', 'hermes', 'xxi', 'medan', 'sumatera', 'utara', 'penting', 'kami', 'sarkar', 'upa', 'govt', 'madam', 'yotv', 'mxm', 'ere', 'bale', 'britney', 'wma', 'rainha', 'merece', 'gna', 'overrated', 'siang', 'waaay', 'intense', 'ally', 'dancing', 'bachata', 'science', 'explain', 'overdose', 'naranasan', 'namin', 'sobrang', 'stories', 'battlestar', 'galactica', 'pilot', '5th', 'espn', 'australian', 'merica', 'grocery', 'display', 'tank', 'entirely', 'dollar', 'brain', 'oooooneee', 'dollarr', 'mccarthy', 'gbs', 'lock', 'csl', 'shxt', 'thanksfor', 'minute', 'cemburu', 'tiiddaakkkkk', 'aaaa', 'husband', 'heropanti', 'fdfs', 'marry', 'italy', 'rumor', 'countdown', 'connor', 'baddies', 'luh', 'muzzaik', 'jennifer', 'lopez', 'hoya', 'macaron', 'stressed', 'thesis', 'writing', 'presentation', 'viva', 'skype', 'bosan', 'tahap', 'babi', 'cast', 'victoria', 'normally', 'tastes', 'abit', 'watery', 'eugh', 'arrow', 'hwhat', 'higashi', 'hodgy', 'pinot', 'bianco', 'riesling', 'italico', 'sauvignon', 'blanc', 'singular', 'plural', 'wipe', 'aja', 'belom', 'gunna', 'minny', 'soil', 'dumpers', 'machines', 'seized', 'greater', 'noida', 'asking', 'wdlands', 'inter', 'nominated', 'perfoming', 'yn', 'imagines', 'lq', 'conference', 'charogne6', 'britax', 'tray', 'trayby', 'usabuy', 'mp', 'rbsb6', 'conducted', 'pulisteniks', 'punta', 'ballo', 'brgy', 'sipalay', 'neg', 'occ', 'toilet', 'learning', 'language', 'frankies', 'bennys', 'grammies', 'wolverine', 'russell', 'crowe', 'dougray', 'scott', 'hahaaha', 'tingnan', 'mo', 'manne', 'hammer', 'written', 'driving', 'force', 'rhetorics', 'hv', 'date', 'crips', 'bloods', 'rivalry', '140518', 'daehyun', 'loe', 'taiwan', '7daysbb', 'bew', 'tan', 'glaciar', 'piedras', 'blancas', 'prakasit', 'koosuwan', 'clearout', 'chics', 'fightin', 'lfsci', 'lists', 'aaand', 'misha', 'cooky', 'kath', 'photoshoot', 'catalogue', 'barista', 'enjoyed', 'ona', 'riverwalk', 'polaright', 'nim', 'thu', 'kpa', 'dyn', 'freinds', 'skinship', 'bntu', 'hashtagged', 'brf3', 'odd', 'foolin', 'script', 'kiddy', 'ip', 'smbd', 'exploit', 'glorious', 'honeypot', 'somthin', 'moly', 'ttatt', 'sometimey', 'wallin', 'ct', 'ansonia', 'serve', '200', 'kms', 'misurata', 'haier', 'chi', 'minh', 'disguised', 'japanese', 'company', 'prude', 'youll', 'booty', 'omegle', 'contradiction', '135k', '85jkt', '081222236015', '085776458548', 'faster', 'wifing', 'pochettino', 'papelbon', 'eskin', 'theechaco', 'aha', 'grilled', 'thrown', 'fellow', 'bights', 'funnyshit', 'comfortable', 'destiny', 'ahan', 'oki', 'bje', 'buz', 'gibi', 'milkshake', 'palmiye', 'cafe', 'cuddlez', 'sees', 'approching', 'x25', 'conyo', 'mfss', 'everythang', 'toony', 'fufu', 'rap', 'fuckz', 'burden', 'bcause', 'sumone', 'blame', 'manage', 'musical', 'genius', 'sengoku', 'basara', 'buying', 'whyy', 'blushy', 'sweettalking', 'indo', 'uses', 'khabar', 'kabar', 'muffin', 'dummy', 'iphones', 'unreal', 'baek', \"yeol's\", 'biggs', 'seaworld', 'charissa', 'bernabe', 'cornetto', 'affordable', 'taste', '151', 'dl', 'prabowo', 'pantas', 'jadi', 'presiden', 'ri', 'acl', 'expected', 'crash', 'wests', 'carthy', 'eliza', 'brewery', 'arts', 'centre', 'gig', 'exclusively', 'traxsource', 'krystle', 'b comes', 'magical', 'ep', 'flower', 'kiyo', 'teering', 'alergies', 'shaved', 'bald', 'nic', 'sale', '99c', 'bex', 'paladin', 'amazon', 'bruuh', 'dae', 'intay', 'agbuya', 'bareng', 'ada', 'kwarta', 'lefft', 'uan', 'wipes', 'cries', 'pity', 'acommo', 'durbs', 'boet', 'momento', 'fue', 'tyc', 'cadena', 'nacional', 'rashard', 'choose', 'theyve', 'terrorist', 'hafeez', 'saeed', 'warns', \"modi's\", 'wali', 'jamhooriyat', 'resolve', 'jali', 'manzoor', 'dhandli', 'tourney', 'hang', 'lmk', 'leiam', 'eccentric', 'osu', 'scientist', 'vindicated', 'melting', 'global', 'warming', 'predictions', 'toledo', 'blade', \"how's\", 'inlove', 'shorty', 'sacked', 'nayo', 'ciroc', 'comfirms', 'corvinus', 'vol', 'txted', 'earlier', 'foo', 'gabi', 'selter', 'struggles', 'requested', 'nightbot', 'kappa', 'idgad', 'pple', 'troublesome', 'ngelatih', 'deltras', 'ae', 'clarence', 'seedorf', 'dipecat', 'cont', 'info', 'subscribing', 'mail', 'temukan', 'olshop', 'notification', 'hahhaha', 'wuih', 'annie', 'acquires', 'distimo', 'raises', 'funding', 'observations', 'allergies', 'xmen', 'trends', 'vancouver', 'gull', 'jered', 'widmer', 'freja', 'beha', 'erichsen', 'benny', 'horne', 'russh', 'violations', 'housemates', 'tsk', 'sabia', 'arkansas', 'teamsters', 'appealing', 'beebe', 'abf', 'nlr', 'sonn', 'ifucking', 'passion', 'moe', 'setting', 'kohli', 'abd', 'lame', \"emoji's\", 'respect', 'nassau', 'junkanoo', 'wayy', 'smt', 'remind', 'fpo', 'artists', 'll', 'strength', 'summit', 'poors', 'favoriting', 'needy', 'eastside', '140527', 'cheon', 'yi', 'chanbar', 'ping', 'pong', 'armin', 'buuren', 'boleh', 'satu', 'berkacalah', 'wahai', 'kalian', 'sukanya', 'ngejudge', 'forbid', 'bringing', 'capture', 'memorable', 'moments', 'scottsdale', 'village', 'roastery', 'amanha', 'bem', 'que', 'podia', 'tocar', 'tanggal', 'bikn', 'project', 'lgi', 'nh', 'wkwkwk', 'opps', 'facial', 'stuntin', 'gen', 'ad', 'konti', 'hygiene', 'experiment', 'aobiome', 'happens', 'reporte', 'incanrwach', 'crykg', 'uploaded', 'comunion', 'arturo', 'rolando', 'web', 'pronounce', 'phonetic', 'phuk', 'phuket', 'learn', 'debs', 'magluto', 'almusal', 'gutom', '6473000376', 'booth', 'booths', 'iove', 'pringles', 'amerika', 'surgeons', '0527', 'pag', 'appreciated', 'awh', 'favo', 'eventually', 'dumbs', 'asc', 'claps', 'perogies', 'nomnomnomnom', 'regalan', 'evento', 'xfa', 'cheered', 'juarez', 'fse', 'conversation', 'tlkn', 'crip', 'rw', 'saranghae', 'hyung', 'nakakasad', 'umikot', 'amy', 'ucf', 'hits', 'coogs', 'filipino', 'bkuz', 'stuck', 'wrd', 'antoine', 'griezmann', 'juventus', 'cosmos', 'further', 'mszolekavee', 'weeknd', 'muh', 'fuckas', 'smokeshow', 'monfils', 'kennett', 'vast', 'swathe', 'grass', 'devoid', 'scratby', 'adjacent', 'sentence', 'abcd', 'akpos', 'freakin', 'epic', 'shazia', 'ilmi', 'blown', 'lid', 'inner', 'democracy', 'claim', 'dictator', 'carlo', 'ancelotti', 'reacts', 'iker', 'nessun', 'dorma', 'violin', 'showpiece', 'peninggi', 'badan', 'pelangsing', 'penggemuk', 'herbal', 'alami', '3153aea6', '08811470358', 'luk', 'senhora', 'linda', 'everton', 'hahahahahah', 'seven', 'eleven', 'gehd', 'demnit', '140116', 'defs', 'aaron', 'disneyland', 'flameyeol', 'inna', 'shevchenko', 'topless', 'protest', 'resistance', 'torture', '22yr', 'sells', 'n430k', 'onitsha', '22', 'chinelo', 'huma', 'pictured', 'dupla', 'insaciable', 'wade', 'huumm', 'wud', 'lived', 'location', 'clueless', 'outta', 'lg', 'aje', 'neng', 'scapegoating', 'shinseki', 'az', 'ridiculous', 'potus', 'repubs', 'submitted', 'bid', 'diego', 'digvijay', 'congress', 'sanjay', 'jha', 'intelligent', 'madriiiiddd', 'bloomin', 'starvin', 'cho', 'wip', 'este', 'chico', 'quiere', 'cena', 'indonesia', 'silakan', 'kesini', 'een', 'tanto', 'clean', 'boyband', 'philippines', 'marikina', 'reva', 'spilt', 'bowl', 'cereal', 'dxck', 'pleaser', 'mofo', 'insidous', 'stillll', 'scares', 'unfollower', 'faceeee', 'mames', 'acaner', 'ny', 'conversate', 'loooot', 'wk', 'hntayn', 'nlng', 'bigay', 'sau', 'lahat', 'kudve', 'chose', 'hiz', 'kal', 'kaha', 'sunetrac', 'cong', 'disowns', 'ajay', 'maken', 'sonia', 'similiar', 'niecy', 'mds', 'sust', 'grads', 'txtin', 'haffi', 'physically', 'loml', 'happyy', 'birthdayyy', 'august', 'blaming', 'fouls', 'touchy', 'asss', 'nome', \"why'd\", 'driver', 'rowdy', 'payin', '10pm', 'wasteman', 'wishing', 'lisa', 'jfc', 'rted', 'asddhkfhskdblabs', 'shedding', 'kawaii', 'factest', 'maulaw', 'ainy', 'haahahahha', 'macama', 'qaqaa', 'amiin', 'terimakassih', '18th', 'success', 'fair', 'doughty', 'oshie', 'twitters', 'banky', 'akon', 'chemicals', 'wearin', \"chinchilla's\", 'manan', 'dund', 'xaragdax', 'ter', 'uuliin', 'oroid', 'minii', 'aav', 'xezee', 'cagt', 'zogsoj', 'baisan', 'dese', 'summn', 'statistics', 'skill', 'unappreciated', 'wilding', 'nigjt', 'yoh', 'niya', 'ja', 'michelle', 'fonk', 'ignore', 'shadows', 'flawless', 'shettima', 'leaders', 'politicization', 'abduction', 'karma', 'realised', 'bestie', 'chillen', 'kardashia', 'died', 'niggra', 'summation', 'classified', 'directory', 'grille', 'atd', 'lexx', 'paramore', 'yellowcard', 'omo', 'flintandpyrite', 'ume', 'andrea', 'rangel', 'knits', 'revisit', 'thameslink', 'moorgate', 'closed', 'ago', 'icons', 'sem', 'psd', 'factor', 'x8', 'sweg', 'darlin', 'imran', 'pmln', 'heros', 'smyle', 'sadest', 'xxc', 'achieved', 'stratospheric', 'heights', 'coolness', 'tenerezza', 'babies', 'ery', 'wkeend', 'facts', 'babyface', 'helping', 'orrr', 'noo', 'hyoyeon', 'rebecca', 'crowdfunding', 'roundup', 'flowering', 'projects', 'tuaw', 'provides', 'readers', 'paquiao', 'ammmazing', 'actully', 'lawn', 'moved', 'canal', 'forgets', 'renew', 'certificate', 'os', 'software', 'mute', 'kimberley', 'walsh', 'confirms', 'cheryl', \"cole's\", \"britain's\", 'talent', 'appearance', 'contactmusic', 'comkimberley', 'confir', 'practising', 'parth', 'caring', 'imy', 'thug', 'udah', 'lama', 'nda', 'crashed', 'datpiff', 'soundcloud', 'genji', 'sunshelter', 'fami', 'titan', 'baseball', 'brv', 'advance', 'county', 'tri', 'jumpseat', '018', 'combat', 'firefighting', 'tony', 'kelleher', 'repost', 'plg', 'sensual', 'toribash', 'tango', 'wildfires', 'turkey', 'feather', 'fletching', 'archery', 'arrows', 'diy', 'pheasant', 'feathers', 'arro', '492', 'oookay', 'bean', 'headass', 'exercise', 'paakyat', 'thunderbird', 'phil', 'superei', 'ainda', 'wara', 'niyata', 'imortal', 'hahahahahahhahaha', 'meteorite', \"else's\", 'stoop', 'makapag', 'ipon', 'flavour', 'jskcosnxoancoamxis', 'ahhhhh', 'vinegar', 'caroline', 'wozniacki', 'breaks', 'silence', 'mcilroy', 'breakup', 'boakwon', 'suju', 'spiderman', 'carnage', 'mask', '300rb', 'lom', 'ama', 'ongkir', 'stock', 'slick', 'brownskin', 'lightskin', 'dunny', 'gage', 'impostors', 'lottle', 'jesus', 'intercesion', 'peole', 'wilshire', 'itq', 'swim', 'sauna', 'teddy', 'selca', 'tazz', 'needa', 'quit', 'aloud', 'aguilera', 'minogue', 'scorer', 'offense', 'jackin', 'bargin', 'giant', 'lovey', 'dovey', 'chan', 'whatever', 'valid', 'section', '82', 'sikugwirizana', 'ndi', 'zomwe', 'jb', 'akukamba', 'apa', 'shaah', 'heck', 'tarra', 'sparkles', 'haneda', 'bts7thheaven', 'tamara', 'deja', 'cosas', 'nenaaaaa', 'selling', 'bras', 'tampons', 'vag', 'slowly', 'growing', 'rage', 'symphonic', 'orchestra', 'prague', 'lirik', 'terjemahan', 'coulthard', 'beginning', 'program', 'gordon', 'ramsey', 'carcillo', 'epitome', 'jabroni', 'tagged', 'brewers', 'pitcher', 'yovani', 'gallardo', 'orioles', 'nows', 'pdx', 'unit', 'prowling', 'trader', \"joe's\", 'nob', 'glisan', 'locos', 'halaaa', 'awww', 'whatdoiwear', 'maison', 'margiela', 'resort', '2015', 'collection', 'cdfu', 'brutha', 'uofl', 'walz', 'becomes', 'asst', 'fiba', 'ky', 'wondering', 'babygirl', 'yah', 'ps', 'freezing', '6121', 'bramblewood', 'raleigh', 'ranch', 'ariana', 'ekxh', 'falaknuma', '12704', 'hwh', 'whisky', 'tipsy', 'realy', 'nid', 'meetin', 'openheart', 'yeoja', 'dulu', 'autofollback', 'france', 'picked', 'arms', 'newest', 'banner', 'award', 'homestay', 'bre', 'theeeekeofofwn', 'happylgovo', 'kf', 'particularly', 'marriage', 'liek', 'immigration', 'doesng', 'injured', 'odi', 'captain', 'alastair', \"sunday's\", 'sri', 'lanka', 'yalla', 'whoever', 'greg', 'lurk', 'wag', 'yhu', '50mm', '4part', 'magnetised', 'anodized', 'aluminium', 'pollinator', 'metal', 'herb', 'spice', 'grinder', 'looool', 'yute', 'ntn', 'yeeer', 'wearr', 'reherseal', 'tommy', 'redding', 'thotler', 'gini', 'gaduh', 'alrdy', 'zzzzz', 'mari', 'bongkaran', 'praise', 'galing', 'nangyare', 'wallpaper', 'perghhhh', 'laut', 'macam', 'swimming', 'poooollll', 'sergio', 'aguero', 'correa', 'kit', 'ceo', 'pokes', 'natty', 'bama', 'gooch', \"j'n\", 'putts', 'sence', 'ebook', 'naia', 'witch', 'carmen', 'parets', 'luque', 'scale', 'bhuth', 'jolokia', 'scoville', 'lk', 'advani', 'prep', \"kim's\", 'actual', 'greedy', 'previs', 'duke', 'dumont', 'jax', 'leh', 'hopes', 'meal', 'sfebe', 'henrik', 'lundqvist', 'richter', 'playoff', 'shutouts', 'havr', 'pao', 'awhile', 'nakakamiss', 'salam', 'communicated', 'sent', 'sliding', 'sriracha', 'plant', 'nuisance', 'irwindale', 'council', 'dismisses', 'lawsuit', 'three', 'spsl', 'teams', 'puyallup', 'bethel', 'beamer', 'wcd', 'softball', 'semifinals', '18dn', '4711', 'dep', 'hakeem', 'inam', 'ul', 'haq', 'jahania', 'daum', 'naeun', 'nev', 'goddamit', 'stefan', 'janoski', 'digi', 'floral', 'large', 'mexican', 'buchholz', 'placed', 'diarmuid', 'flynn', 'eliminated', 'campaign', 'presta', 'kkkkkk', 'msl', 'ecf', 'kilian', 'jornet', 'zegama', '3h48m40s', 'plan', 'caused', 'airball', 'layup', 'kaggs', 'cave', 'lip', 'sync', 'levitt', 'merchant', 'fallon', 'shocked', 'throught', 'melted', 'meron', 'kang', 'pahhheerraamm', 'bukit', 'bintang', 'sold', 'o2', 'arena', 'bakery', 'sweetest', 'singapore', 'credits', 'perhaps', 'tvj', 'cvm', 'rjr', 'finalised', 'cesc', 'utter', 'viru', 'permanent', 'foreign', 'policy', 'hamari', 'jagah', 'nepal', 'yahi', 'karta', 'theirselves', 'a9lan', 'human', 'golelhum', 'yaklo', 'teben', 'xoxoxxo', 'hahhahahahaha', 'quay', 'mold', 'astaghfirullah', 'ham', 'farrukh', 'shehar', 'islamabad', 'getcha', 'pickle', 'sayeng', 'vuldemurt', 'lowd', 'sassy', 'wezird', \"ca'nt\", 'tamed', 'herbs', 'ayurvedic', 'pimple', 'ehh', 'jap', 'ain', 'whr', 'rocky', 'balboa', 'lakala', 'dormir', 'nene', 'buen', 'espera', 'trocar', 'pegar', 'algo', 'comer', 'photobomb', 'adrian', 'jhene', 'aiko', 'performs', 'nauso', 'gusto', 'aina', 'x35', 'skepta', 'dissing', 'wiley', 'hat', 'freestyle', '1xtra', 'jheeze', 'youtbe', 'impressive', 'pg24', 'dwade', 'hitting', 'pointers', 'weequahic', 'toast', 'don', '1hunnit', 'filmz', 'typing', 'seret', 'dekat', 'dinding', 'arrives', 'bullet', 'proof', 'bmw', 'pakistani', 'morrison', 'essential', 'anais', 'nin', 'crusing', 'bok', 'daedae', 'lessons', 'adultwork', 'blizz', 'devs', 'sexed', 'corn', 'bread', 'mashed', 'potatoes', 'pies', 'nom', 'eighteen', 'ym', 'gdo', 'bisnis', 'aston', 'keepin', 'nap', 'witchu', 'borderline', 'abdullah', 'prez', 'avengers', 'punisher', 'animation', 'pun', 'sudah', 'melampau', 'kot', 'quil', 'dogs', 'gta', 'hahha', 'manamit', 'uhmmm', 'fkn', 'tickt', 'viv', 'dark', 'flustered', 'kenn', 'jaylin', '1am', '5am', 'swsh', 'shabu', 'krugman', 'healthcare', 'rationed', 'arsene', 'wenger', 'mtl', 'a1', 'matrix', 'sim', 'a2', 'upto', '2000', 'minutes', 'a3', 'unlimited', 'access', 'douche', 'nizamabad', 'passenger', '51434', 'nzb', '270', \"man's\", 'quality', 'influences', 'armour', 'ua', 'cleats', 'alert', 'deitrick', 'haddon', 'clareta', 'gospe', 'chanting', 'slightly', 'inehbriated', 'switc', 'hed', 'undo', 'vous', 'aimez', 'brenna', 'hers', 'rememberin', 'prayin', 'ultimate', 'sacrifice', 'savior', 'pk', 'arod', 'mmm', 'speechless', 'noma', 'kunjani', 'kule', 'gan', 'ntar', 'ane', 'sundul', \"bae's\", 'svu', 'intent', 'research', 'shizzle', 'nizzle', 'replied', 'au', 'tyaa', 'yaw', 'mamodou', 'sakho', 'captains', 'gv', 'scrummaster', 'csm', 'augusta', 'engsub', 'est', 'barrymoore', 'cameron', 'danced', 'underwear', 'yosh', '1000follow', '80rb', 'pulsa', 'xl', 'proses', '2b806641', 'western', 'trifling', 'rightfully', 'checkbox', 'privelege', 'privilage', 'exostan', 'bana', 'starlight', 'acura', 'tsx', 'jdm', 'oem', 'clear', 'fog', 'lights', 'eden', 'hazard', 'uploads', 'belgium', 'esn', 'imei', 'activations', 'rooted', 'lieder', 'ohne', 'worte', '67', 'flat', 'major', 'wort', 'meilleures', 'ventes', 'izak', 'lapland', 'auteur', 'tatted', 'lightskinned', 'theoretical', 'asshole', 'swearing', 'worse', 'sailor', 'diaporama', 'shaking', 'banana', 'clonedvd', 'ipod', 'convert', 'daredevils', 'sharjah', 'consecutive', 'feroz', 'kotla', 'boroko', 'haboyo', 'trash', 'wena', 'robale', 'kaygeo', 'lmfaooo', 'afford', 'nuffin', 'roller', 'coaster', 'wooohoo', 'teenage', 'sneak', 'dazzling', 'hapi', 'prosperity', 'tinz', 'offer', 'mate', 'odor', 'baho', 'teh', 'signs', 'testi', 'cust', 'sell', 'chicharito', 'welbz', 'legt', 'doesnot', 'fruit', 'phobia', 'cucumber', 'fab', 'suffered', 'inspite', 'lack', 'art', '370', 'provdes', 'protection', 'pol', 'ldrs', 'accountability', 'rejected', 'mcdonalds', 'optimus', 'runs', 'search', 'rechercher', 'lancomegrandiose', 'sur', '4888759250190336', '452740', 'vsg', 'montreal', 'palco', 'momo', 'cha', 'bekasi', 'survivorship', 'compendium', 'providers', 'melanie', 'doakan', 'smooth', 'dipsomaniac', 'sensible', 'sharepoint', 'ipad', 'kky', 'westbrook', 'hbu', 'btw', 'sodo', 'tek', 'tm', 'replacment', 'adapter', 'supply', 'hp', 'photosmart', '7520', 'printer', 'required', 'tetap', 'salut', 'untuk', 'simeone', 'result', 'x40', 'yessss', 'ticketless', 'masso', 'dari', 'lcw', 'comeback', 'ofcourse', 'fandoms', 'kapala', 'saiyan', 'vas', 'happenin', \"rt'd\", 'sante', 'avenida', 'boliches', '29640', 'fuengirola', 'strudel', 'webpage', 'using', 'seo', 'backlinking', 'ppc', 'hour', 'liveset', 'closeeee', 'turnup', 'miller', 'fourth', 'loss', 'skid', 'nine', 'redsox', 'kuwait', 'hawalli', 'governorate', 'lifeee', 'itv', 'studios', 'loveholic', 'blunts', 'feela', 'runnn', 'salute', 'meh', 'cyberia', 'townvilla', '5hs', 'cabello', 'malem', 'sampe', 'limit', 'wkwkwkwkwk', 'kept', \"bom's\", 'wifed', \"she'll\", 'nananana', 'moodbreaker', 'moodbooster', 'marketwatch', 'revive', 'itunes', 'kahli', \"hoya's\", 'guk', 'fanmeet', 'hiiii', 'doctors', 'appointment', 'classes', 'bbo', 'dubstep', 'awareness', 'dolce', 'gabbana', 'model', 'tulog', 'zzzz', 'meaningful', 'sup', 'fatass', 'jsy', 'lexus', 'wassup', 'serena', 'darion', 'relation', 'homeless', 'meth', 'addicts', 'showers', 'cocky', 'bizarre', 'marsden', '924', 'exact', 'timberlake', 'beckham', 'payne', 'triplets', 'ahahahaa', 'goodnight', 'ucr', 'beyonces', 'yaaass', '2days', 'wad', 'vvvvvvvv', 'barkat', 'whip', '18', '4g', 'za', 'curry', 'shrimp', 'speak', '4th', 'carried', 'epal', 'athar', 'mehehhe', \"nashlene's\", '10th', 'anniversary', 'sharlene', 'jailene', 'francos', 'dirty', 'unshaven', 'wateva', 'cums', 'healthy', 'bryant', 'shaq', \"o'neal\", 'payton', 'karl', 'malone', 'angeles', '8x10', 'thou', '14th', 'yin', 'andd', 'tecs', 'sus', 'scottish', 'unable', 'scotland', 'silverman', 'xanax', 'myth', 'assembly', 'polls', 'udit', 'raj', 'zee', 'flew', 'uggh', 'eww', 'riaz', 'khalil', 'americares', 'rehab', 'region', 'facilities', 'singles', 'semana', 'chino', 'roces', 'gil', 'arnaiz', 'opposite', 'lm', 'allowed', 'mammaye', 'denying', 'locale', 'stunning', 'celine', 'drinker', 'waitin', 'site', 'onew', 'gale', 'frodo', 'katniss', 'everdeen', 'presly', 'chapa', 'netflix', 'cherry', 'bh3', 'yao', 'ming', 'assembling', 'investors', 'ros', 'angeres', 'crippers', 'shes', 'geoff', 'sweatin', 'otha', 'pon', 'bruk', '630', 'toe', '60w', 'magsafe', 'pro', 'accounts', 'phan', 'passing', 'judgement', 'chisaki', 'miuna', 'awesomer', 'waynerooney', 'became', '1996', 'fabio', 'capello', 'mufc', 'sounds', 'tbf', 'ultra', 'thin', 'bumper', 'max', 't6', 'branford', 'coastal', 'wx', 'overcast', 'mist', 'outdoortemp', 'hum97', 'pct', 'avg', 'windspeed', 'ton', 'kaos', 'cupcake', 'orenjy', '45rb', 'reseller', 'welcome', '2a98eebc', 'gopro', 'curved', 'adhesive', 'mounts', 'mountsby', 'gwyneth', 'paltrow', 'celebs', 'dehumanizing', 'war', 'nonsense', 'incase', 'ay', 'makalahlwe', 'nyan', 'sleeps', 'bird', 'shat', 'brassard', 'centering', 'pouliot', 'moore', 'ffs', 'rolled', 'panic', 'drawing', 'camikum', 'balik', 'hiatus', 'thankyou', 'anyones', 'acesse', 'tech', 'associate', 'walker', '125th', 'sawtell', 'temperature', 'ssw', 'knots', 'dewpoint', 'achilles', 'slp', '1d', 'famly', 'robertson', 'indiana', 'batson', 'challenge', 'swearin', 'epson', 'workforce', '845', 'inkjet', 'copier', 'scanner', 'fax', 'prolems', 'ewa', 'utok', 'ug', 'oi', 'creekview', 'searched', 'bangtan', 'baromxkookie', 'resemblance', 'opinions', 'offspring', 'venga', 'cryme', 'ashanti', 'fuccin', 'cuh', 'corny', 'ambi', 'pur', '3volution', 'plug', 'device', 'dev', 'kearny', 'garage', 'door', 'discounts', 'doors', 'openers', '1x', 'strap', 'colle', 'shu', 'ouma', 'inori', 'gai', 'ayase', 'tsugumi', 'bot', 'loudest', 'quietest', 'clothes', 'dorky', 'grabbing', 'capital', 'safe', 'schulz', 'grube', 'hovsepian', 'tonyselznick', 'ins', 'careful', 'trynna', 'ifop', 'projection', 'fn', 'ump', 'eelv', 'fdg', \"lego's\", 'dragonball', 'inhumane', 'gnocchi', 'broccoli', 'rabe', 'vegetarian', 'eataly', 'nyc', \"wesley's\", 'icon', 'duffel', 'duramax', 'avoiding', 'wayne', 'afk', 'lul', 'zelo', 'blossom', 'ams', 'exs', 'houses', 'ragers', 'smf', 'nengok', 'wayeee', 'cinemas', 'gsc', 'klaroline', 'klaus', 'adding', 'pepl', 'killr', 'watford', 'heurelho', 'rafa', 'garros', 'junie', 'however', 'teamchill', 'broham', 'eatin', '7cec2ffe', 'gnti', 'saiki', 'fer', 'canada', 'mexico', 'fest', 'parkir', 'timur', 'senayan', 'asheville', 'morristown', '1797', 'renamed', 'north', 'carolina', 'ashe', 'blueberry', 'donut', 'definitley', 'movies', 'taha', 'pochey', 'zardari', 'bhejta', 'hae', 'yeh', 'machar', 'x2', 'canf', '500', 'miles', 'baskin', 'robbins', 'soda', 'fudgesicles', 'shutting', 'asda', 'suing', '2yrs', 'reall', 'anita', 'lmap', 'madhu', 'kishwar', 'managing', 'kiran', \"bedi's\", 'orali', 'bbg', 'mazkirah', 'hijabis', 'abs', 'adorexonly', 'nazak', 'breathing', 'shall', 'return', 'rolling', 'kembali', 'gelar', 'tur', 'pasca', 'kematian', \"l'wren\", 'adult', 'busters', 'jaunty', 'protein', 'pancakes', 'cory', 'sticks', 'lea', 'casts', 'believing', 'austerlitz', 'slavkov', 'brna', 'czech', 'republic', 'sia', 'kelly', 'jiu', 'cannnot', 'liao', 'mybe', 'ull', 'depart', 'kor', 'marquinhos', 'agent', 'advanced', 'talks', 'barcelona', 'defender', 'close', 'source', 'contemplation', 'imovie', 'versus', 'transplantation', 'fqauwh', 'ened', 'x5', 'segar', 'icant', 'chemist', 'aigooo', 'brotha', \"dottie's\", 'sarno', 'youngin', 'kesip', 'qm', 'juudh', 'rangera', 'hearts', 'hibs', 'falkirk', 'sasuke', 'itachi', 'kabuto', 'chu', 'handing', 'jaggery', 'wada', 'southbank', 'suckin', 'loctite', '1405603', 'plastic', 'syringe', 'epoxy', 'gel'])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw, norm = loadNormData(os.path.join(DATA_PATH, \"interim/train.txt\"))\n",
    "norm_dictionary = norm_dict.construct(os.path.join(DATA_PATH, \"interim/train.txt\"))\n",
    "norm_dictionary.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "lex = lexicon.build(\n",
    "        {\"english\", \"american\"},\n",
    "        {\"contractions\", \"proper-names\", \"upper\", \"words\"},\n",
    "        50,\n",
    "        1,\n",
    "    )\n",
    "\n",
    "lex = lexicon.refine(lex.union(lexicon.build_abbreviations()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of in lexicon with normalisation: 0.43\n",
      "Most common normalised raw phrases in lexicon: [(('nigga', 'nigger'), 57), (('niggas', 'niggers'), 52), (('ur', 'your'), 33), (('gonna', 'going to'), 29), (('bout', 'about'), 21), (('tho', 'though'), 17), (('wit', 'with'), 17), (('cause', 'because'), 16), (('wanna', 'want to'), 12), (('ur', \"you're\"), 12), (('cant', \"can't\"), 12), (('nd', 'and'), 11), (('yo', 'you'), 11), (('ill', \"i'll\"), 9), (('dis', 'this'), 9), (('yo', 'your'), 8), (('em', 'them'), 8), (('yea', 'yeah'), 7), (('its', \"it's\"), 7), (('rn', 'right now'), 6)]\n",
      "Most common un-normalised raw phrases not in lexicon: [(('haha', 'haha'), 81), (('bae', 'bae'), 45), (('x', 'x'), 44), (('2', '2'), 40), (('niall', 'niall'), 40), (('hahaha', 'hahaha'), 36), (('idk', 'idk'), 36), (('1', '1'), 34), (('rp', 'rp'), 33), (('exo', 'exo'), 31), (('wtf', 'wtf'), 26), (('t', 't'), 25), (('5', '5'), 25), (('zayn', 'zayn'), 23), (('2014', '2014'), 23), (('c', 'c'), 21), (('smh', 'smh'), 21), (('3', '3'), 21), (('4', '4'), 20), (('b', 'b'), 20)]\n",
      "Most common token normalisations not in lexicon: [(('haha', 'haha'), 81), (('bae', 'bae'), 45), (('x', 'x'), 44), (('2', '2'), 40), (('niall', 'niall'), 40), (('hahaha', 'hahaha'), 36), (('idk', 'idk'), 36), (('1', '1'), 34), (('rp', 'rp'), 33), (('exo', 'exo'), 31), (('gonna', 'going to'), 29), (('wtf', 'wtf'), 26), (('t', 't'), 25), (('5', '5'), 25), (('ima', \"i'm going to\"), 25), (('zayn', 'zayn'), 23), (('2014', '2014'), 23), (('c', 'c'), 21), (('smh', 'smh'), 21), (('3', '3'), 21)]\n"
     ]
    }
   ],
   "source": [
    "lexicon.evaluate(norm_dictionary, lex)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def original_token(tok):\n",
    "    # MONOISE\n",
    "    # needed if detect step is skipped, as all tokens will be replaced by one from the list of candidates\n",
    "    return {tok}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import gensim\n",
    "w2v_vectors = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        os.path.join(DATA_PATH, \"external/monoise_data/w2v_100.bin\"),\n",
    "        binary=True,\n",
    "        unicode_errors=\"ignore\",\n",
    "    )\n",
    "# load embeddings from van der goot. Used params -size 100 -window 5 -cbow 0 -binary 1 -threads 45\n",
    "# there are 400 length embeddings which supposedly give slight performance improvement, but too slow\n",
    "# unicode incompatibilities present so must ignore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_model = model = gensim.models.Word2Vec(sentences=raw, vector_size=100, window=5)\n",
    "# get keyed vectors only as finished training model\n",
    "train_vectors = train_model.wv\n",
    "w2v_vectors.add_vectors(train_vectors.index_to_key, train_vectors.vectors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('sureee', 0.906640350818634),\n ('suure', 0.8680776357650757),\n ('sureeee', 0.8335921168327332),\n ('suree,', 0.8297243118286133),\n ('sureee,', 0.8246626257896423),\n ('okkay', 0.8242574334144592),\n ('ohkayy', 0.8241530060768127),\n ('surre', 0.8228244185447693),\n ('alrighht', 0.8206066489219666),\n ('suree!', 0.817251980304718)]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lexnorm.models.filtering import is_eligible\n",
    "\n",
    "\n",
    "def word_embeddings(tok, vectors, threshold=0):\n",
    "    # TODO uni, bigram freqs?\n",
    "    # TODO implement word2vec with keras. Use newer embeddings. Experiment with different no. of candidates generated. Could even create twitter embeddings myself? Could clean up as VDG did before creating train embeddings. Cosine similarity threshold?\n",
    "    # MONOISE\n",
    "    # can use twitter embeddings from van der Goot - based on distributional hypothesis to find tokens with similar semantics\n",
    "    # could use cosine similarity as a feature for selection? Using here to get most similar candidates.\n",
    "    # ISSUE: antonyms also often present in same contexts.\n",
    "    candidates = set()\n",
    "    if tok in vectors:\n",
    "        candidates = set(vectors.similar_by_vector(tok))\n",
    "    return {c[0].lower() for c in candidates if is_eligible(c[0]) and c[1] >= threshold}\n",
    "\n",
    "# pretty much no tokens in train set not in twitter embeddings from vdg but can't assume this is the case\n",
    "# possible that tok will not be in vectors\n",
    "w2v_vectors.similar_by_vector(\"suree\")\n",
    "# pretty terrible performance for train_vectors - to be expected as such a low amount of data could literally just use external set as contains almost every word anyway and will be much more accurate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[('bitch', 28)]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lookup(tok, dictionary):\n",
    "    # TODO: external norm dicts?\n",
    "    # MONOISE\n",
    "    # lookup in list of all replacement pairs found in the training data (and external sources?)\n",
    "    # all norm tokens with raw token tok are included as candidates\n",
    "    return [(k, v) for k, v in dictionary.get(tok, {}).items()]\n",
    "\n",
    "lookup(\"bitch\", norm_dictionary)\n",
    "# norm_dictionary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def clipping(tok, lex):\n",
    "    # MONOISE\n",
    "    # all words in lexicon that have tok as a prefix (capturing abbreviation). May only consider for tok length above 2?\n",
    "    candidates = set()\n",
    "    if len(tok) < 2:\n",
    "        return set()\n",
    "    # TODO: length threshold? prune generated (only some degree of clipping allowed w.r.t. edit distance)?\n",
    "    return [t for t in lex if t.startswith(tok)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# TODO: number of candidates on average generated by each module and with all modules\n",
    "# TODO: which modules contribute the most / most unique correct candidates\n",
    "# TODO: for modules and whole, percentage of correct vs incorrect candidates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def split(tok, lex):\n",
    "    # MONOISE\n",
    "    # hypothesis splits on (every/some) position and check if both words are in lexicon. May only consider of tok length above 3?\n",
    "    candidates = set()\n",
    "    if len(tok) < 3:\n",
    "        return set()\n",
    "    for pos in range(1, len(tok)):\n",
    "        left = tok[:pos]\n",
    "        right = tok[pos:]\n",
    "        if left in lex and right in lex:\n",
    "            candidates.add(\" \".join([left, right]))\n",
    "    # TODO: recursive candidate generation on each left and right? Probably not... More than one split? Probably not either...\n",
    "    # TODO: length threshold?\n",
    "    return candidates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from spylls.hunspell import Dictionary\n",
    "\n",
    "def spellcheck(tok):\n",
    "    # TODO: no control over this - can I change in source code? Try and load in custom lexicon.\n",
    "    dictionary = Dictionary.from_files('en_US')\n",
    "    return {c.lower() for c in dictionary.suggest(tok)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# TODO: contextual features?\n",
    "# def generate_candidates(tweet):\n",
    "#     for token in tweet:\n",
    "#         ..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def generate_candidates(tok):\n",
    "    candidates = set()\n",
    "    candidates = candidates.union(original_token(tok))\n",
    "    candidates = candidates.union(word_embeddings(tok, w2v_vectors))\n",
    "    candidates = candidates.union(spellcheck(tok))\n",
    "    # obviously lookup on the train set will always give the correct answer!\n",
    "    # candidates = candidates.union(lookup(tok, norm_dictionary))\n",
    "    candidates = candidates.union(clipping(tok, lex))\n",
    "    candidates = candidates.union(split(tok, lex))\n",
    "    return candidates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 16\u001B[0m\n\u001B[1;32m      9\u001B[0m norm_dictionary \u001B[38;5;241m=\u001B[39m norm_dict\u001B[38;5;241m.\u001B[39mconstruct(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(DATA_PATH, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minterim/train.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# keys = sample(list(norm_dictionary.keys()), 100)\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# assert condition_normalisation.contingency(\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m#     raw, norm, lambda x: x[0] == \"a\", True\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# ) == condition_normalisation.contingency_from_dict(\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m#     norm_dictionary, lambda x: x[0][0] == \"a\"\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m a, b, c, d \u001B[38;5;241m=\u001B[39m \u001B[43mcondition_normalisation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontingency_from_dict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnorm_dictionary\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgenerate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# print(sum(a.values()) + sum(b.values()) + sum(c.values()) + sum(d.values()))\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# a2, b2, c2, d2 = condition_normalisation.contingency(raw, norm, lambda x: x[0] == \"a\", True)\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# print(sum(a.values()) + sum(b.values()) + sum(c.values()) + sum(d.values()))\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/src/lexnorm/evaluation/condition_normalisation.py:75\u001B[0m, in \u001B[0;36mcontingency_from_dict\u001B[0;34m(norm_dict, condition, result)\u001B[0m\n\u001B[1;32m     71\u001B[0m to_update \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     72\u001B[0m     pair \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpair\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m (pair[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m pair[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m     73\u001B[0m )\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pair[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m pair[\u001B[38;5;241m1\u001B[39m]:\n\u001B[0;32m---> 75\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mcondition\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpair\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     76\u001B[0m         p_unnormed\u001B[38;5;241m.\u001B[39mupdate([to_update] \u001B[38;5;241m*\u001B[39m count)\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "Cell \u001B[0;32mIn[21], line 17\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m      9\u001B[0m norm_dictionary \u001B[38;5;241m=\u001B[39m norm_dict\u001B[38;5;241m.\u001B[39mconstruct(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(DATA_PATH, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minterim/train.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# keys = sample(list(norm_dictionary.keys()), 100)\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# assert condition_normalisation.contingency(\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m#     raw, norm, lambda x: x[0] == \"a\", True\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# ) == condition_normalisation.contingency_from_dict(\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m#     norm_dictionary, lambda x: x[0][0] == \"a\"\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[1;32m     16\u001B[0m a, b, c, d \u001B[38;5;241m=\u001B[39m condition_normalisation\u001B[38;5;241m.\u001B[39mcontingency_from_dict(\n\u001B[0;32m---> 17\u001B[0m     norm_dictionary, \u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;129;01mnot\u001B[39;00m x[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m \u001B[43mgenerate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m )\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# print(sum(a.values()) + sum(b.values()) + sum(c.values()) + sum(d.values()))\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# a2, b2, c2, d2 = condition_normalisation.contingency(raw, norm, lambda x: x[0] == \"a\", True)\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# print(sum(a.values()) + sum(b.values()) + sum(c.values()) + sum(d.values()))\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[20], line 4\u001B[0m, in \u001B[0;36mgenerate_candidates\u001B[0;34m(tok)\u001B[0m\n\u001B[1;32m      2\u001B[0m candidates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[1;32m      3\u001B[0m candidates \u001B[38;5;241m=\u001B[39m candidates\u001B[38;5;241m.\u001B[39munion(original_token(tok))\n\u001B[0;32m----> 4\u001B[0m candidates \u001B[38;5;241m=\u001B[39m candidates\u001B[38;5;241m.\u001B[39munion(\u001B[43mword_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtok\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw2v_vectors\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      5\u001B[0m candidates \u001B[38;5;241m=\u001B[39m candidates\u001B[38;5;241m.\u001B[39munion(spellcheck(tok))\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# obviously lookup on the train set will always give the correct answer!\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# candidates = candidates.union(lookup(tok, norm_dictionary))\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[13], line 13\u001B[0m, in \u001B[0;36mword_embeddings\u001B[0;34m(tok, vectors, threshold)\u001B[0m\n\u001B[1;32m     11\u001B[0m candidates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tok \u001B[38;5;129;01min\u001B[39;00m vectors:\n\u001B[0;32m---> 13\u001B[0m     candidates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[43mvectors\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimilar_by_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtok\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {c[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mlower() \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m candidates \u001B[38;5;28;01mif\u001B[39;00m is_eligible(c[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;129;01mand\u001B[39;00m c[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m threshold}\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:914\u001B[0m, in \u001B[0;36mKeyedVectors.similar_by_vector\u001B[0;34m(self, vector, topn, restrict_vocab)\u001B[0m\n\u001B[1;32m    890\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msimilar_by_vector\u001B[39m(\u001B[38;5;28mself\u001B[39m, vector, topn\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, restrict_vocab\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    891\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Find the top-N most similar keys by vector.\u001B[39;00m\n\u001B[1;32m    892\u001B[0m \n\u001B[1;32m    893\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    912\u001B[0m \n\u001B[1;32m    913\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 914\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmost_similar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpositive\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mvector\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtopn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrestrict_vocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrestrict_vocab\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:852\u001B[0m, in \u001B[0;36mKeyedVectors.most_similar\u001B[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001B[0m\n\u001B[1;32m    850\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m topn:\n\u001B[1;32m    851\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dists\n\u001B[0;32m--> 852\u001B[0m best \u001B[38;5;241m=\u001B[39m \u001B[43mmatutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margsort\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdists\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtopn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mall_keys\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreverse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[38;5;66;03m# ignore (don't return) keys from the input\u001B[39;00m\n\u001B[1;32m    854\u001B[0m result \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    855\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex_to_key[sim \u001B[38;5;241m+\u001B[39m clip_start], \u001B[38;5;28mfloat\u001B[39m(dists[sim]))\n\u001B[1;32m    856\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m sim \u001B[38;5;129;01min\u001B[39;00m best \u001B[38;5;28;01mif\u001B[39;00m (sim \u001B[38;5;241m+\u001B[39m clip_start) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m all_keys\n\u001B[1;32m    857\u001B[0m ]\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/matutils.py:74\u001B[0m, in \u001B[0;36margsort\u001B[0;34m(x, topn, reverse)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reverse:\n\u001B[1;32m     73\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mx\n\u001B[0;32m---> 74\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m topn \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39msize \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mhasattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43margpartition\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39margsort(x)[:topn]\n\u001B[1;32m     76\u001B[0m \u001B[38;5;66;03m# np >= 1.8 has a fast partial argsort, use that!\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from lexnorm.evaluation import condition_normalisation\n",
    "from lexnorm.data import normEval\n",
    "import os\n",
    "from lexnorm.definitions import DATA_PATH\n",
    "from lexnorm.data import norm_dict\n",
    "from lexnorm.models.filtering import is_eligible\n",
    "from random import sample\n",
    "\n",
    "norm_dictionary = norm_dict.construct(os.path.join(DATA_PATH, \"interim/train.txt\"))\n",
    "# keys = sample(list(norm_dictionary.keys()), 100)\n",
    "# assert condition_normalisation.contingency(\n",
    "#     raw, norm, lambda x: x[0] == \"a\", True\n",
    "# ) == condition_normalisation.contingency_from_dict(\n",
    "#     norm_dictionary, lambda x: x[0][0] == \"a\"\n",
    "# )\n",
    "a, b, c, d = condition_normalisation.contingency_from_dict(\n",
    "    norm_dictionary, lambda x: not x[1] in generate_candidates(x[0])\n",
    ")\n",
    "\n",
    "# print(sum(a.values()) + sum(b.values()) + sum(c.values()) + sum(d.values()))\n",
    "\n",
    "# a2, b2, c2, d2 = condition_normalisation.contingency(raw, norm, lambda x: x[0] == \"a\", True)\n",
    "\n",
    "# print(sum(a.values()) + sum(b.values()) + sum(c.values()) + sum(d.values()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# TODO merge module that checks some tokens ahead of current token (perhaps only one)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      2\u001B[0m candidates \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature2\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeature3\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m----> 3\u001B[0m \u001B[43mcandidates\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtesting\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m]\n\u001B[1;32m      4\u001B[0m candidates\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# new_candidates = pd.DataFrame(columns=)\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:818\u001B[0m, in \u001B[0;36m_LocationIndexer.__setitem__\u001B[0;34m(self, key, value)\u001B[0m\n\u001B[1;32m    815\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_valid_setitem_indexer(key)\n\u001B[1;32m    817\u001B[0m iloc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miloc\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39miloc\n\u001B[0;32m--> 818\u001B[0m \u001B[43miloc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setitem_with_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1785\u001B[0m, in \u001B[0;36m_iLocIndexer._setitem_with_indexer\u001B[0;34m(self, indexer, value, name)\u001B[0m\n\u001B[1;32m   1782\u001B[0m     indexer, missing \u001B[38;5;241m=\u001B[39m convert_missing_indexer(indexer)\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m missing:\n\u001B[0;32m-> 1785\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setitem_with_indexer_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1786\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m   1788\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloc\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1789\u001B[0m     \u001B[38;5;66;03m# must come after setting of missing\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:2160\u001B[0m, in \u001B[0;36m_iLocIndexer._setitem_with_indexer_missing\u001B[0;34m(self, indexer, value)\u001B[0m\n\u001B[1;32m   2157\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_list_like_indexer(value):\n\u001B[1;32m   2158\u001B[0m         \u001B[38;5;66;03m# must have conforming columns\u001B[39;00m\n\u001B[1;32m   2159\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(value) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39mcolumns):\n\u001B[0;32m-> 2160\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot set a row with mismatched columns\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2162\u001B[0m     value \u001B[38;5;241m=\u001B[39m Series(value, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39mcolumns, name\u001B[38;5;241m=\u001B[39mindexer)\n\u001B[1;32m   2164\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj):\n\u001B[1;32m   2165\u001B[0m     \u001B[38;5;66;03m# We will ignore the existing dtypes instead of using\u001B[39;00m\n\u001B[1;32m   2166\u001B[0m     \u001B[38;5;66;03m#  internals.concat logic\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "candidates = pd.DataFrame(columns=[\"feature1\", \"feature2\", \"feature3\"])\n",
    "candidates.loc[\"testing\"] = [1, 3]\n",
    "candidates\n",
    "# new_candidates = pd.DataFrame(columns=)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import lexnorm.models.candidate_generation as candidate_generation\n",
    "import importlib\n",
    "import numpy as np\n",
    "from spylls.hunspell import Dictionary\n",
    "importlib.reload(candidate_generation)\n",
    "dictionary = Dictionary.from_files(\"en_US\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'candidate_generation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m train_data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame()\n\u001B[0;32m----> 2\u001B[0m candidates \u001B[38;5;241m=\u001B[39m \u001B[43mcandidate_generation\u001B[49m\u001B[38;5;241m.\u001B[39mcandidates_from_token(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbruh\u001B[39m\u001B[38;5;124m\"\u001B[39m, w2v_vectors, norm_dictionary, lex, dictionary)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# candidates.cosine_to_orig = candidates.index.map(lambda x: w2v_vectors.similarity(x, \"lol\") if x in w2v_vectors else 0)\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# w2v_vectors.similarity(candidates.index, \"lol\") if indexes in w2v_vectors else 0\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# candidates.index.to_series()\u001B[39;00m\n\u001B[1;32m      6\u001B[0m candidates\n",
      "\u001B[0;31mNameError\u001B[0m: name 'candidate_generation' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "candidates = candidate_generation.candidates_from_token(\"bruh\", w2v_vectors, norm_dictionary, lex, dictionary)\n",
    "# candidates.cosine_to_orig = candidates.index.map(lambda x: w2v_vectors.similarity(x, \"lol\") if x in w2v_vectors else 0)\n",
    "# w2v_vectors.similarity(candidates.index, \"lol\") if indexes in w2v_vectors else 0\n",
    "# candidates.index.to_series()\n",
    "candidates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d1 = pd.DataFrame(columns=[\"feature\"])\n",
    "d2 = pd.DataFrame(columns=[\"feature\"])\n",
    "d1.loc[\"key\"] = {\"feature\": np.nan}\n",
    "d2.loc[\"key\"] = {\"feature\": 1}\n",
    "d2.loc[\"key2\"] = {\"feature\": 3}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43md1\u001B[49m\u001B[38;5;241m.\u001B[39mcombine_first(d2)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'd1' is not defined"
     ]
    }
   ],
   "source": [
    "d1.combine_first(d2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"interim/candidates.txt\"), index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "              cosine_to_orig  embeddings_rank  from_clipping  \\\nbet                 0.458454              NaN            NaN   \nfind                0.681112              5.0            NaN   \ngee                 0.208263              NaN            NaN   \ngel                 0.280316              NaN            NaN   \ngem                 0.306635              NaN            NaN   \ngen                 0.236195              NaN            NaN   \ngent                0.192144              NaN            NaN   \nget                 1.000000              NaN            1.0   \ngetaway             0.245932              NaN            1.0   \ngetaway's                NaN              NaN            1.0   \ngetaways            0.175399              NaN            1.0   \ngethsemane          0.203536              NaN            1.0   \ngethsemane's             NaN              NaN            1.0   \ngets                0.708681              2.0            1.0   \ngetting             0.739619              0.0            1.0   \ngetty               0.276120              NaN            1.0   \ngetty's             0.386289              NaN            1.0   \ngettysburg          0.305030              NaN            1.0   \ngettysburg's             NaN              NaN            1.0   \ngetup               0.256726              NaN            1.0   \ngetup's                  NaN              NaN            1.0   \ngit                 0.484013              NaN            NaN   \ngo                  0.683375              4.0            NaN   \ngot                 0.723958              1.0            NaN   \ngt                  0.378428              NaN            NaN   \ngut                 0.372101              NaN            NaN   \ngwt                 0.700142              3.0            NaN   \njet                 0.217320              NaN            NaN   \nlet                 0.537128              NaN            NaN   \nmet                 0.302097              NaN            NaN   \nnet                 0.251704              NaN            NaN   \npet                 0.297810              NaN            NaN   \nset                 0.454948              NaN            NaN   \n\n              from_original_token  from_split  norms_seen  spellcheck_rank  \\\nbet                           NaN         NaN         NaN             15.0   \nfind                          NaN         NaN         NaN              NaN   \ngee                           NaN         NaN         NaN              3.0   \ngel                           NaN         NaN         NaN              9.0   \ngem                           NaN         NaN         NaN             12.0   \ngen                           NaN         NaN         NaN              6.0   \ngent                          NaN         NaN         NaN              2.0   \nget                           1.0         NaN        60.0             16.0   \ngetaway                       NaN         NaN         NaN              NaN   \ngetaway's                     NaN         NaN         NaN              NaN   \ngetaways                      NaN         NaN         NaN              NaN   \ngethsemane                    NaN         NaN         NaN              NaN   \ngethsemane's                  NaN         NaN         NaN              NaN   \ngets                          NaN         NaN         NaN              1.0   \ngetting                       NaN         NaN         NaN              NaN   \ngetty                         NaN         NaN         NaN              NaN   \ngetty's                       NaN         NaN         NaN              NaN   \ngettysburg                    NaN         NaN         NaN              NaN   \ngettysburg's                  NaN         NaN         NaN              NaN   \ngetup                         NaN         NaN         NaN              NaN   \ngetup's                       NaN         NaN         NaN              NaN   \ngit                           NaN         NaN         NaN              5.0   \ngo                            NaN         NaN         NaN              NaN   \ngot                           NaN         NaN         NaN              8.0   \ngt                            NaN         NaN         NaN              0.0   \ngut                           NaN         NaN         NaN             11.0   \ngwt                           NaN         NaN         NaN              NaN   \njet                           NaN         NaN         NaN             17.0   \nlet                           NaN         NaN         NaN             10.0   \nmet                           NaN         NaN         NaN             13.0   \nnet                           NaN         NaN         NaN              7.0   \npet                           NaN         NaN         NaN             14.0   \nset                           NaN         NaN         NaN              4.0   \n\n              in_lexicon  length  same_order  orig_norms_seen  \\\nbet                  1.0       3         NaN             60.0   \nfind                 1.0       4         NaN             60.0   \ngee                  1.0       3         NaN             60.0   \ngel                  1.0       3         NaN             60.0   \ngem                  1.0       3         NaN             60.0   \ngen                  1.0       3         NaN             60.0   \ngent                 1.0       4         1.0             60.0   \nget                  1.0       3         1.0             60.0   \ngetaway              1.0       7         1.0             60.0   \ngetaway's            1.0       9         1.0             60.0   \ngetaways             1.0       8         1.0             60.0   \ngethsemane           1.0      10         1.0             60.0   \ngethsemane's         1.0      12         1.0             60.0   \ngets                 1.0       4         1.0             60.0   \ngetting              1.0       7         1.0             60.0   \ngetty                1.0       5         1.0             60.0   \ngetty's              1.0       7         1.0             60.0   \ngettysburg           1.0      10         1.0             60.0   \ngettysburg's         1.0      12         1.0             60.0   \ngetup                1.0       5         1.0             60.0   \ngetup's              1.0       7         1.0             60.0   \ngit                  NaN       3         NaN             60.0   \ngo                   1.0       2         NaN             60.0   \ngot                  1.0       3         NaN             60.0   \ngt                   NaN       2         NaN             60.0   \ngut                  1.0       3         NaN             60.0   \ngwt                  NaN       3         NaN             60.0   \njet                  1.0       3         NaN             60.0   \nlet                  1.0       3         NaN             60.0   \nmet                  1.0       3         NaN             60.0   \nnet                  1.0       3         NaN             60.0   \npet                  1.0       3         NaN             60.0   \nset                  1.0       3         NaN             60.0   \n\n              orig_in_lexicon  orig_same_order  orig_length  correct  \\\nbet                       1.0              1.0          3.0      NaN   \nfind                      1.0              1.0          3.0      NaN   \ngee                       1.0              1.0          3.0      NaN   \ngel                       1.0              1.0          3.0      NaN   \ngem                       1.0              1.0          3.0      NaN   \ngen                       1.0              1.0          3.0      NaN   \ngent                      1.0              1.0          3.0      NaN   \nget                       1.0              1.0          3.0      1.0   \ngetaway                   1.0              1.0          3.0      NaN   \ngetaway's                 1.0              1.0          3.0      NaN   \ngetaways                  1.0              1.0          3.0      NaN   \ngethsemane                1.0              1.0          3.0      NaN   \ngethsemane's              1.0              1.0          3.0      NaN   \ngets                      1.0              1.0          3.0      NaN   \ngetting                   1.0              1.0          3.0      NaN   \ngetty                     1.0              1.0          3.0      NaN   \ngetty's                   1.0              1.0          3.0      NaN   \ngettysburg                1.0              1.0          3.0      NaN   \ngettysburg's              1.0              1.0          3.0      NaN   \ngetup                     1.0              1.0          3.0      NaN   \ngetup's                   1.0              1.0          3.0      NaN   \ngit                       1.0              1.0          3.0      NaN   \ngo                        1.0              1.0          3.0      NaN   \ngot                       1.0              1.0          3.0      NaN   \ngt                        1.0              1.0          3.0      NaN   \ngut                       1.0              1.0          3.0      NaN   \ngwt                       1.0              1.0          3.0      NaN   \njet                       1.0              1.0          3.0      NaN   \nlet                       1.0              1.0          3.0      NaN   \nmet                       1.0              1.0          3.0      NaN   \nnet                       1.0              1.0          3.0      NaN   \npet                       1.0              1.0          3.0      NaN   \nset                       1.0              1.0          3.0      NaN   \n\n             raw_tok_index  \nbet                    0_1  \nfind                   0_1  \ngee                    0_1  \ngel                    0_1  \ngem                    0_1  \ngen                    0_1  \ngent                   0_1  \nget                    0_1  \ngetaway                0_1  \ngetaway's              0_1  \ngetaways               0_1  \ngethsemane             0_1  \ngethsemane's           0_1  \ngets                   0_1  \ngetting                0_1  \ngetty                  0_1  \ngetty's                0_1  \ngettysburg             0_1  \ngettysburg's           0_1  \ngetup                  0_1  \ngetup's                0_1  \ngit                    0_1  \ngo                     0_1  \ngot                    0_1  \ngt                     0_1  \ngut                    0_1  \ngwt                    0_1  \njet                    0_1  \nlet                    0_1  \nmet                    0_1  \nnet                    0_1  \npet                    0_1  \nset                    0_1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n      <th>correct</th>\n      <th>raw_tok_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bet</th>\n      <td>0.458454</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>find</th>\n      <td>0.681112</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gee</th>\n      <td>0.208263</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gel</th>\n      <td>0.280316</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gem</th>\n      <td>0.306635</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gen</th>\n      <td>0.236195</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gent</th>\n      <td>0.192144</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>get</th>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>16.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>getaway</th>\n      <td>0.245932</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>getaway's</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>getaways</th>\n      <td>0.175399</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gethsemane</th>\n      <td>0.203536</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gethsemane's</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>12</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gets</th>\n      <td>0.708681</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>getting</th>\n      <td>0.739619</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>getty</th>\n      <td>0.276120</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>getty's</th>\n      <td>0.386289</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gettysburg</th>\n      <td>0.305030</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>10</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gettysburg's</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>12</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>getup</th>\n      <td>0.256726</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>getup's</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>1.0</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>git</th>\n      <td>0.484013</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>go</th>\n      <td>0.683375</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>got</th>\n      <td>0.723958</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gt</th>\n      <td>0.378428</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gut</th>\n      <td>0.372101</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>gwt</th>\n      <td>0.700142</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>jet</th>\n      <td>0.217320</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>let</th>\n      <td>0.537128</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>met</th>\n      <td>0.302097</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>net</th>\n      <td>0.251704</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>pet</th>\n      <td>0.297810</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n    <tr>\n      <th>set</th>\n      <td>0.454948</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>60.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>0_1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.set_index([\"raw_tok_index\", \"candidate\"], verify_integrity=True)\n",
    "# df.groupby([\"raw_tok_index\"]).sum()\n",
    "# df[np.isnan(df[\"norms_seen\"])].groupby(\"raw_tok_index\").sum()\n",
    "df[df[\"raw_tok_index\"] == \"0_1\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n",
      "/Users/elijoe/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:849: RuntimeWarning: invalid value encountered in divide\n",
      "  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]\n"
     ]
    },
    {
     "data": {
      "text/plain": "        cosine_to_orig  embeddings_rank  from_clipping  from_original_token  \\\na             0.406318              NaN            NaN                  NaN   \naah           0.734173              NaN            NaN                  NaN   \nagu           0.764286              1.0            NaN                  NaN   \nah            1.000000              NaN            1.0                  1.0   \naha           0.422756              NaN            1.0                  NaN   \n...                ...              ...            ...                  ...   \nrawer         0.301921              NaN            NaN                  NaN   \nrawr          1.000000              NaN            NaN                  1.0   \nrawrr         0.781826              0.0            NaN                  NaN   \nrawrrr        0.772067              1.0            NaN                  NaN   \nwrap          0.140178              NaN            NaN                  NaN   \n\n        from_split  norms_seen  spellcheck_rank  in_lexicon  length  \\\na              NaN         NaN              3.0           1       1   \naah            NaN         NaN              5.0           0       3   \nagu            NaN         NaN              NaN           0       3   \nah             NaN         8.0              NaN           1       2   \naha            NaN         NaN              6.0           1       3   \n...            ...         ...              ...         ...     ...   \nrawer          NaN         NaN              1.0           1       5   \nrawr           NaN         2.0              NaN           0       4   \nrawrr          NaN         NaN              NaN           0       5   \nrawrrr         NaN         NaN              NaN           0       6   \nwrap           NaN         NaN              5.0           1       4   \n\n        same_order  orig_norms_seen  orig_in_lexicon  orig_same_order  \\\na                0              8.0              1.0              1.0   \naah              1              8.0              1.0              1.0   \nagu              0              8.0              1.0              1.0   \nah               1              8.0              1.0              1.0   \naha              1              8.0              1.0              1.0   \n...            ...              ...              ...              ...   \nrawer            1              2.0              0.0              1.0   \nrawr             1              2.0              0.0              1.0   \nrawrr            1              2.0              0.0              1.0   \nrawrrr           1              2.0              0.0              1.0   \nwrap             0              2.0              0.0              1.0   \n\n        orig_length  \na               2.0  \naah             2.0  \nagu             2.0  \nah              2.0  \naha             2.0  \n...             ...  \nrawer           4.0  \nrawr            4.0  \nrawrr           4.0  \nrawrrr          4.0  \nwrap            4.0  \n\n[1286 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cosine_to_orig</th>\n      <th>embeddings_rank</th>\n      <th>from_clipping</th>\n      <th>from_original_token</th>\n      <th>from_split</th>\n      <th>norms_seen</th>\n      <th>spellcheck_rank</th>\n      <th>in_lexicon</th>\n      <th>length</th>\n      <th>same_order</th>\n      <th>orig_norms_seen</th>\n      <th>orig_in_lexicon</th>\n      <th>orig_same_order</th>\n      <th>orig_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>a</th>\n      <td>0.406318</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>aah</th>\n      <td>0.734173</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>agu</th>\n      <td>0.764286</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>ah</th>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>aha</th>\n      <td>0.422756</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>rawer</th>\n      <td>0.301921</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>rawr</th>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>rawrr</th>\n      <td>0.781826</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>rawrrr</th>\n      <td>0.772067</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>wrap</th>\n      <td>0.140178</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1286 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_generation.candidates_from_tweets(raw[:2], w2v_vectors, norm_dictionary, lex, dictionary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH, \"../hpc/candidates.txt\"), index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "# get all tokens where correct normalisation not produced by candidate generation\n",
    "filtered = df.groupby(\"raw_tok_index\").filter(lambda x: x.sum()[\"correct\"] == 0)\n",
    "ungenerated = filtered.loc[filtered[\"from_original_token\"] == 1.0][\"gold\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "raw, _ = loadNormData(os.path.join(DATA_PATH, \"raw/dev.norm\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "6876"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for raw_tweet, norm_tweet in zip(raw, norm):\n",
    "    for raw_tok, norm_tok in zip(raw_tweet, norm_tweet):\n",
    "        if is_eligible(raw_tok):\n",
    "            count += 1\n",
    "count\n",
    "# as expected - perhaps can be used to test candidate_generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "data": {
      "text/plain": "[(('v', 'very'), 2),\n (('hapi', 'happy'), 2),\n (('witchu', 'with you'), 2),\n (('yessss', 'yes'), 1),\n (('bestie', 'best friend'), 1),\n (('niggra', 'nigger'), 1),\n (('wada', 'water'), 1),\n (('chu', 'you'), 1),\n (('nows', 'now is'), 1),\n (('nuh', 'know'), 1),\n (('ntn', 'nothing'), 1),\n (('mnl', 'my new love'), 1),\n (('za', 'that'), 1),\n (('skepta', 'sunglasses'), 1),\n (('whatdoiwear', 'what do i wear'), 1),\n (('brutha', 'brother'), 1),\n (('yah', 'you'), 1),\n (('nuff', 'enough'), 1),\n (('shizz', 'shit'), 1),\n (('nuffin', 'nothing'), 1),\n (('diss', 'this'), 1),\n (('vas', 'was'), 1),\n (('redsox', 'red sox'), 1),\n (('nem', 'they'), 1),\n (('fkn', 'fucking'), 1),\n (('sim', 'seems'), 1),\n (('hbu', 'how about you'), 1),\n (('goddamit', 'god damn it'), 1),\n (('satnite', 'saturday night'), 1),\n (('dese', 'these'), 1),\n (('summn', 'something'), 1),\n (('cums', 'comes'), 1),\n (('dnt', \"doesn't\"), 1),\n (('getcha', 'get you'), 1),\n (('trynna', 'trying to'), 1),\n (('ya', 'your'), 1),\n (('lottle', 'lot'), 1),\n (('happylgovo', 'happy'), 1),\n (('gal', 'guy'), 1),\n (('fuccin', 'fucking'), 1),\n (('cuh', 'see you'), 1),\n (('datpiff', 'the piff'), 1),\n (('diy', 'do it yourself'), 1),\n (('da', 'that'), 1),\n (('shat', 'shit'), 1),\n (('slp', 'sleep'), 1),\n (('dia', 'their'), 1),\n (('devs', 'developer'), 1),\n (('yea', 'you'), 1),\n (('cannnot', \"can't\"), 1),\n (('ull', 'you will'), 1),\n (('icant', \"i can't\"), 1),\n (('brotha', 'brother'), 1),\n (('poooollll', 'pool'), 1),\n (('sup', \"what's up\"), 1),\n (('wassup', \"what's up\"), 1),\n (('pre', 'preorder'), 1),\n (('order', nan), 1)]"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(zip(ungenerated.index, ungenerated)).most_common()\n",
    "# very few ungenerated correct candidates! So candidate generation module perhaps alright."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "data": {
      "text/plain": "['broths',\n 'broth',\n 'broth a',\n 'broth-a',\n 'brouhaha',\n 'Botha',\n 'Hasbro',\n 'troth',\n 'breath',\n 'brethren']"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dictionary.suggest(\"brotha\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
