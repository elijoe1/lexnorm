{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import lexnorm.models.annotation\n",
    "from lexnorm.data import normEval\n",
    "from lexnorm.data import baseline\n",
    "from lexnorm.definitions import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_raw, train_norm = normEval.loadNormData(os.path.join(DATA_PATH, 'raw/train.norm'))\n",
    "test_raw, test_norm = normEval.loadNormData(os.path.join(DATA_PATH, 'raw/test.norm'))\n",
    "dev_raw, dev_norm = normEval.loadNormData(os.path.join(DATA_PATH, 'raw/dev.norm'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 4917\n",
      "Total number of normed tweets: 4917\n",
      "Unchanged from 2015 dataset.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of tweets: {len(train_raw) + len(test_raw) + len(dev_raw)}\")\n",
    "print(f\"Total number of normed tweets: {len(train_norm) + len(test_norm) + len(dev_norm)}\")\n",
    "print(\"Unchanged from 2015 dataset.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test set: 1967\n",
      "Unchanged from 2015 dataset. Keep split so can compare with both 2015 and 2021 entries.\n",
      "Size of train set: 2360\n",
      "As described in 2021 task paper.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of test set: {len(test_raw)}\")\n",
    "print(\"Unchanged from 2015 dataset. Keep split so can compare with both 2015 and 2021 entries.\")\n",
    "print(f\"Size of train set: {len(train_raw)}\")\n",
    "print(\"As described in 2021 task paper.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "full_raw = train_raw + dev_raw\n",
    "full_norm = train_norm + dev_norm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No length mismatch (as expected).\n"
     ]
    }
   ],
   "source": [
    "for tweet_raw, tweet_norm in zip(full_raw, full_norm):\n",
    "    if len(tweet_raw) != len(tweet_norm):\n",
    "        print(\"Length mismatch!\")\n",
    "print(\"No length mismatch (as expected).\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Number of raw tokens: 35216\n",
      "Number of normed tokens: 35598\n",
      "Number of 1 to n normalisation raw tokens: 307\n",
      "Percentage of 1 to n: 0.87\n",
      "Number of n to 1 normalisation raw tokens: 13\n",
      "Percentage of n to 1: 0.04\n",
      "Number of normalised raw tokens: 2666\n",
      "Percentage normalised: 7.570422535211268\n",
      "DEV\n",
      "Number of raw tokens: 9169\n",
      "Number of normed tokens: 9282\n",
      "Number of 1 to n normalisation raw tokens: 98\n",
      "Percentage of 1 to n: 1.07\n",
      "Number of n to 1 normalisation raw tokens: 1\n",
      "Percentage of n to 1: 0.01\n",
      "Number of normalised raw tokens: 633\n",
      "Percentage normalised: 6.903697240702367\n",
      "FULL\n",
      "Number of raw tokens: 44385\n",
      "Number of normed tokens: 44880\n",
      "Number of 1 to n normalisation raw tokens: 405\n",
      "Percentage of 1 to n: 0.91\n",
      "Number of n to 1 normalisation raw tokens: 14\n",
      "Percentage of n to 1: 0.03\n",
      "Number of normalised raw tokens: 3299\n",
      "Percentage normalised: 7.432691224512785\n"
     ]
    }
   ],
   "source": [
    "for name, collection in [(\"TRAIN\", zip(train_raw, train_norm)), (\"DEV\", zip(dev_raw, dev_norm)), (\"FULL\", zip(full_raw, full_norm))]:\n",
    "    print(name)\n",
    "    one_to_n_count = 0\n",
    "    n_to_one_count = 0\n",
    "    raw_count = 0\n",
    "    norm_count = 0\n",
    "    raw_normalised_count = 0\n",
    "    for tweet_raw, tweet_norm in collection:\n",
    "        for token_raw, token_norm in zip(tweet_raw, tweet_norm):\n",
    "            raw_count += 1\n",
    "            norm_count += len(token_norm.split(\" \"))\n",
    "            if not token_norm:\n",
    "                n_to_one_count += 1\n",
    "            if len(token_norm.split(\" \")) > 1:\n",
    "                one_to_n_count += 1\n",
    "            if token_norm != token_raw:\n",
    "                raw_normalised_count += 1\n",
    "    print(f\"Number of raw tokens: {raw_count}\")\n",
    "    print(f\"Number of normed tokens: {norm_count}\")\n",
    "    print(f\"Number of 1 to n normalisation raw tokens: {one_to_n_count}\")\n",
    "    print(f\"Percentage of 1 to n: {one_to_n_count * 100 / raw_count:.2f}\")\n",
    "    print(f\"Number of n to 1 normalisation raw tokens: {n_to_one_count}\")\n",
    "    print(f\"Percentage of n to 1: {n_to_one_count * 100 / raw_count:.2f}\")\n",
    "    print(f\"Number of normalised raw tokens: {raw_normalised_count}\")\n",
    "    print(f\"Percentage normalised: {raw_normalised_count * 100 / raw_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For some reason, the stats in the 2021 task paper are on the train set only (correct in that case).\n",
      "Apart from percentage normalised - unclear how this is calculated anyway.\n",
      "Note the 1 to n and n to 1 counts are counting the number of raw tokens involved in the respective normalisations.\n",
      "So a 5 to 1 normalisation would produce a count of 4 (number of tokens merged into first token) for 1 to n, and a 1 to 5 normalisation would produce a count of 1 for n to 1.\n",
      "Note as no capitalisation correction for 2015 dataset, in 2021 dataset version EVERYTHING (RAW AND GOLD) IS LOWER CASE\n",
      "2015 task paper has different statistics, one reason for this being lack of capitalisation consideration in 2021\n"
     ]
    }
   ],
   "source": [
    "print(\"For some reason, the stats in the 2021 task paper are on the train set only (correct in that case).\")\n",
    "print(\"Apart from percentage normalised - unclear how this is calculated anyway.\")\n",
    "print(\"Note the 1 to n and n to 1 counts are counting the number of raw tokens involved in the respective normalisations.\")\n",
    "print(\"So a 5 to 1 normalisation would produce a count of 4 (number of tokens merged into first token) for 1 to n, and a 1 to 5 normalisation would produce a count of 1 for n to 1.\")\n",
    "print(\"Note as no capitalisation correction for 2015 dataset, in 2021 dataset version EVERYTHING (RAW AND GOLD) IS LOWER CASE\")\n",
    "print(\"2015 task paper has different statistics, one reason for this being lack of capitalisation consideration in 2021\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import json\n",
    "f_train = open(os.path.join(DATA_PATH, \"raw/2015/train_data.json\"))\n",
    "# f_test = open(os.path.join(DATA_PATH, \"raw/2015/test_truth.json\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "fif_data = json.load(f_train)\n",
    "# fif_data += json.load(f_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 raw differences, 606 norm only differences\n",
      "Most common norm differences: [(('laughing out loud', 'lol'), 271), (('oh my god', 'omg'), 66), (('laughing my ass off', 'lmao'), 51), ((\"i don't know\", 'idk'), 36), (('gonna', 'going to'), 29), (('what the fuck', 'wtf'), 26), (('shaking my head', 'smh'), 21), (('to be honest', 'tbh'), 16), ((\"i don't care\", 'idc'), 15), (('laughing my fucking ass off', 'lmfao'), 13)]\n",
      "Differences in 2015, 2021 raw due to username anonymization\n",
      "Differences in 2015, 2021 gold due to leaving interjections alone e.g. lol, lmfao, ctfu and normalising gonna and wanna\n",
      "Hence make sure models do too to ensure good performance on 2021 set (maybe dict lookup, hard coding?)\n",
      "Could evaluate on both datasets to compare with submissions from both tasks\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "raw_diff = 0\n",
    "norm_diff = 0\n",
    "norm = Counter()\n",
    "for fif, twe_raw, twe_norm in zip(fif_data, full_raw, full_norm):\n",
    "    fif_raw = [x.lower() for x in fif[\"input\"]]\n",
    "    fif_norm = [x.lower() for x in fif[\"output\"]]\n",
    "    if fif_raw != twe_raw:\n",
    "        raw_diff += 1\n",
    "    elif fif_norm != twe_norm:\n",
    "        norm_diff += 1\n",
    "        norm.update((x, y) for x, y in zip(fif_norm, twe_norm) if x != y)\n",
    "print(f\"{raw_diff} raw differences, {norm_diff} norm only differences\")\n",
    "print(f\"Most common norm differences: {norm.most_common(10)}\")\n",
    "print(\"Differences in 2015, 2021 raw due to username anonymization\")\n",
    "print(\"Differences in 2015, 2021 gold due to leaving interjections alone e.g. lol, lmfao, ctfu and normalising gonna and wanna\")\n",
    "print(\"Hence make sure models do too to ensure good performance on 2021 set (maybe dict lookup, hard coding?)\")\n",
    "print(\"Could evaluate on both datasets to compare with submissions from both tasks\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common normalisation pairs: [(('u', 'you'), 328), (('im', \"i'm\"), 181), (('dont', \"don't\"), 92), (('nigga', 'nigger'), 57), (('niggas', 'niggers'), 52), (('n', 'and'), 47), (('pls', 'please'), 43), (('lil', 'little'), 35), (('ur', 'your'), 33), (('thats', \"that's\"), 33)]\n",
      "Most common normalised raw words: [('u', 333), ('im', 182), ('dont', 92), ('nigga', 57), ('niggas', 52), ('n', 49), ('ur', 46), ('pls', 43), ('lil', 35), ('thats', 33)]\n",
      "Think about for candidate generation.\n"
     ]
    }
   ],
   "source": [
    "normalised_pairs = Counter()\n",
    "non_standard_tokens = Counter()\n",
    "\n",
    "for tweet_raw, tweet_norm in zip(full_raw, full_norm):\n",
    "    for token_raw, token_norm in zip(tweet_raw, tweet_norm):\n",
    "        if token_raw != token_norm:\n",
    "            normalised_pairs.update([(token_raw, token_norm)])\n",
    "            non_standard_tokens.update([token_raw])\n",
    "\n",
    "print(f\"Most common normalisation pairs: {normalised_pairs.most_common(10)}\")\n",
    "print(f\"Most common normalised raw words: {non_standard_tokens.most_common(10)}\")\n",
    "print(\"Think about for candidate generation.\")\n",
    "# print(\"Remember this is including the test set - can't use all of this for the normalisation dictionary!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline acc.(LAI): 92.10\n",
      "Accuracy:           97.23\n",
      "ERR:                64.93\n",
      "As in 2021 paper. For some reason not using dev for training - could fix. Notice the difference in accuracy and ERR.\n"
     ]
    }
   ],
   "source": [
    "normEval.evaluate(test_raw, test_norm, baseline.mfr(train_raw, train_norm, test_raw))\n",
    "print(\"As in 2021 paper. For some reason not using dev for training - could fix. Notice the difference in accuracy and ERR.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "american_70 = open(os.path.join(DATA_PATH, \"test/american-70.txt\"))\n",
    "words = set()\n",
    "for line in american_70:\n",
    "    words.add(line.strip().lower())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOWL AMERICAN 70\n",
      "Percent raw tokens not in lexicon: 17.72\n",
      "Percent normed tokens not in lexicon: 13.04\n",
      "Phi coefficient between in lexicon and normalisation: 0.31\n",
      "This means there is a moderate relationship between them.\n",
      "Most common un-normalised raw alphanumeric tokens in lexicon: [('rt', 921), ('i', 648), ('the', 631), ('to', 534), ('a', 479), ('and', 411), ('you', 340), ('in', 326), ('for', 320), ('is', 318), ('me', 281), ('my', 278), ('on', 271), ('of', 249), ('it', 203), ('with', 186), ('that', 185), ('this', 180), ('so', 180), ('be', 159)]\n",
      "Not super helpful except note domain specific 'rt' left alone.\n",
      "Most common normalised raw alphanumeric tokens in lexicon: [('u', 333), ('nigga', 57), ('niggas', 52), ('n', 49), ('ur', 46), ('gonna', 29), ('rt', 29), ('r', 24), ('d', 22), ('bout', 21), ('yo', 19), ('b', 18), ('wit', 17), ('tho', 17), ('cause', 16), ('dat', 16), ('bc', 16), ('ya', 16), ('da', 14), ('wanna', 12)]\n",
      "Annotation guidelines for the n-word! May want to remove single letter words from lexicon (apart from v. common ones), and filter out double letter acronyms with an internet acronyms list. Note wanna normalised in 2021, inconsistent rt normalisation.\n",
      "This is important as lookup is used to determine if generated candidate is valid/used as feature for candidate selection.\n",
      "Most common un-normalised raw alphanumeric tokens not in lexicon: [('lol', 272), ('haha', 81), ('omg', 67), ('lmao', 51), ('bae', 45), ('niall', 40), ('2', 40), ('hahaha', 36), ('idk', 36), ('1', 34), ('exo', 31), ('wtf', 26), ('5', 25), ('zayn', 23), ('2014', 23), ('smh', 21), ('3', 21), ('4', 20), ('xd', 16), ('tbh', 16)]\n",
      "Pretty much all interjections and some common names (one direction - time specific). May want to expand lexicon in these areas - have to generate as candidates to get correct!. Hard code what to leave alone?\n",
      "Most common normalised raw alphanumeric tokens not in lexicon: [('im', 182), ('dont', 92), ('pls', 43), ('lil', 35), ('thats', 33), ('bruh', 31), ('aint', 30), ('ima', 25), ('ppl', 25), ('yall', 23), ('cuz', 22), ('didnt', 19), ('fav', 19), ('gon', 18), ('tryna', 18), ('imma', 18), ('goin', 16), ('ive', 16), ('2', 14), ('favourite', 13)]\n",
      "A lot of missing apostrophes - think about for candidate generation.\n",
      "A good lexicon (high correlation between in lexicon and normalised) will be good for checking validity of generated candidates - not suggesting candidates that wouldn't be considered normalised, not rejecting ones that would be (obviously on individual word basis). Size offers tradeoff between former and latter.\n",
      "WANT: to either expand lexicon or hard code to reduce un-normalised non-lexical, so that non-lexical->normalised. to reduce lexicon to reduce normalised lexical, so that lexical->non-normalised. Of course there will always be OOV words not requiring normalisation, e.g. unknown/novel named entities, and IV words requiring normalisation, e.g. where misspelling of other words etc.\n",
      "Most common raw tokens not in lexicon: [('lol', 272), ('im', 182), ('dont', 92), ('haha', 81), ('omg', 67), ('2', 54), ('lmao', 51), ('bae', 45), ('pls', 43), ('niall', 40)]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "raw_non_lexical = Counter()\n",
    "norm_non_lexical = Counter()\n",
    "changed_non_lexical = Counter()\n",
    "unchanged_non_lexical = Counter()\n",
    "changed_lexical = Counter()\n",
    "unchanged_lexical = Counter()\n",
    "\n",
    "for twe_raw, twe_norm in zip(full_raw, full_norm):\n",
    "    for token in twe_raw:\n",
    "        if token.isalnum() and token not in words:\n",
    "            raw_non_lexical.update([token])\n",
    "    for norm in twe_norm:\n",
    "        for token in norm.split():\n",
    "            if token.isalnum() and token not in words:\n",
    "                norm_non_lexical.update([token])\n",
    "    for raw, norm in zip(twe_raw, twe_norm):\n",
    "        if raw.isalnum():\n",
    "            if raw in words:\n",
    "                if raw == norm:\n",
    "                    unchanged_lexical.update([raw])\n",
    "                else:\n",
    "                    changed_lexical.update([raw])\n",
    "            elif raw not in words:\n",
    "                if raw == norm:\n",
    "                    unchanged_non_lexical.update([raw])\n",
    "                else:\n",
    "                    changed_non_lexical.update([raw])\n",
    "print(\"SCOWL AMERICAN 70\")\n",
    "print(f\"Percent raw tokens not in lexicon: {sum(raw_non_lexical.values())*100/raw_count:.2f}\")\n",
    "print(f\"Percent normed tokens not in lexicon: {sum(norm_non_lexical.values())*100/raw_count:.2f}\")\n",
    "a = sum(unchanged_lexical.values())\n",
    "b = sum(changed_lexical.values())\n",
    "c = sum(unchanged_non_lexical.values())\n",
    "d = sum(changed_non_lexical.values())\n",
    "phi = (a * d - b * c) / math.sqrt((a+b)*(b+d)*(a+c)*(c+d))\n",
    "print(f\"Phi coefficient between in lexicon and normalisation: {phi:.2f}\")\n",
    "print(\"This means there is a moderate relationship between them.\")\n",
    "print(f\"Most common un-normalised raw alphanumeric tokens in lexicon: {unchanged_lexical.most_common(20)}\")\n",
    "print(\"Not super helpful except note domain specific 'rt' left alone.\")\n",
    "print(f\"Most common normalised raw alphanumeric tokens in lexicon: {changed_lexical.most_common(20)}\")\n",
    "print(\"Annotation guidelines for the n-word! May want to remove single letter words from lexicon (apart from v. common ones), and filter out double letter acronyms with an internet acronyms list. Note wanna normalised in 2021, inconsistent rt normalisation.\")\n",
    "print(\"This is important as lookup is used to determine if generated candidate is valid/used as feature for candidate selection.\")\n",
    "print(f\"Most common un-normalised raw alphanumeric tokens not in lexicon: {unchanged_non_lexical.most_common(20)}\")\n",
    "print(\"Pretty much all interjections and some common names (one direction - time specific). May want to expand lexicon in these areas - have to generate as candidates to get correct!. Hard code what to leave alone?\")\n",
    "print(f\"Most common normalised raw alphanumeric tokens not in lexicon: {changed_non_lexical.most_common(20)}\")\n",
    "print(\"A lot of missing apostrophes - think about for candidate generation.\")\n",
    "print(\"A good lexicon (high correlation between in lexicon and normalised) will be good for checking validity of generated candidates - not suggesting candidates that wouldn't be considered normalised, not rejecting ones that would be (obviously on individual word basis). Size offers tradeoff between former and latter.\")\n",
    "print(\"WANT: to either expand lexicon or hard code to reduce un-normalised non-lexical, so that non-lexical->normalised. to reduce lexicon to reduce normalised lexical, so that lexical->non-normalised. Of course there will always be OOV words not requiring normalisation, e.g. unknown/novel named entities, and IV words requiring normalisation, e.g. where misspelling of other words etc.\")\n",
    "print(f\"Most common raw tokens not in lexicon: {raw_non_lexical.most_common(10)}\")\n",
    "# print(f\"Most common norm tokens not in lexicon: {norm_non_lexical.most_common(10)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# def if_normed(raw_list, norm_list):\n",
    "#     resp = []\n",
    "#     for raw_tweet, norm_tweet in zip(raw_list, norm_list):\n",
    "#         resp_tweet = []\n",
    "#         for raw_tok, norm_tok in zip(raw_tweet, norm_tweet):\n",
    "#             if raw_tok == norm_tok:\n",
    "#                 resp_tweet.append((raw_tok, \"\"))\n",
    "#             else:\n",
    "#                 resp_tweet.append((raw_tok, norm_tok))\n",
    "#         resp.append(resp_tweet)\n",
    "#     return resp\n",
    "#\n",
    "# full_if_normed = if_normed(full_raw, full_norm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def norm_condition(raw_list, norm_list, condition, pair=False, norm=False):\n",
    "    \"\"\"\n",
    "    Return counter for each quadrant of normalised and condition.\n",
    "    pair option returns the normalisation pair if True\n",
    "    norm option evaluates the condition on the normed rather than the raw token if True\n",
    "    \"\"\"\n",
    "    p_normed = Counter()\n",
    "    p_unnormed = Counter()\n",
    "    n_normed = Counter()\n",
    "    n_unnormed = Counter()\n",
    "    for tweet_raw, tweet_norm in zip(raw_list, norm_list):\n",
    "        for raw, normed in zip(tweet_raw, tweet_norm):\n",
    "            tok = normed if norm else raw\n",
    "            to_update = (tok, normed) if pair else tok\n",
    "            if raw != normed and condition(tok):\n",
    "                p_normed.update([to_update])\n",
    "            elif raw == normed and condition(tok):\n",
    "                p_unnormed.update([to_update])\n",
    "            elif raw != normed and not condition(tok):\n",
    "                n_normed.update([to_update])\n",
    "            else:\n",
    "                n_unnormed.update([to_update])\n",
    "    return p_unnormed, p_normed, n_unnormed, n_normed\n",
    "\n",
    "def correlation_with_norm(p_unnormed, p_normed, n_unnormed, n_normed):\n",
    "    \"\"\"\n",
    "    Calculate phi correlation coefficient between normalisation and a condition (two binary variables)\n",
    "    \"\"\"\n",
    "    a = sum(p_unnormed.values())\n",
    "    b = sum(p_normed.values())\n",
    "    c = sum(n_unnormed.values())\n",
    "    d = sum(n_normed.values())\n",
    "    phi = (a * d - b * c) / math.sqrt((a+b)*(b+d)*(a+c)*(c+d))\n",
    "    return phi\n",
    "\n",
    "# a, b, c, d = norm_condition([[tok for tok in tweet if tok[0].isalnum()] for tweet in full_if_normed], lambda x: x in words)\n",
    "# correlation_with_norm(a, b, c, d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 4 non-alphanumeric raw tokens are normalised: [((\"good'o\", 'good'), 1), ((\"could've\", 'could have'), 1), ((\"should've\", 'should have'), 1), ((\"ca'nt\", \"can't\"), 1)]. These all contain apostrophes, which are included as not invalidating tokens for normalisation. However, could've and should've should not have been normalised under 2015 annotation rule 9. This rule also makes sense as expanding could change the formality of the text. ca'nt has the apostrophe in the wrong place. Perhaps the contraction module could handle moving apostrophes as well as inserting to get a IV word. Modules should only be able to add candidates, not remove them. Unclear what is happening in good'o but perhaps could hypothesise drop/split before/after the apostrophe? The alphanumeric filter conveniently also filters out domain specific entities (hashtags and mentions).\n"
     ]
    }
   ],
   "source": [
    "_, b, _, _= norm_condition(full_raw, full_norm, lambda x: not x.isalnum(), True, False)\n",
    "print(f\"Only {sum(b.values())} non-alphanumeric raw tokens are normalised: {b.most_common()}. These all contain apostrophes, which are included as not invalidating tokens for normalisation. However, could've and should've should not have been normalised under 2015 annotation rule 9. This rule also makes sense as expanding could change the formality of the text. ca'nt has the apostrophe in the wrong place. Perhaps the contraction module could handle moving apostrophes as well as inserting to get a IV word. Modules should only be able to add candidates, not remove them. Unclear what is happening in good'o but perhaps could hypothesise drop/split before/after the apostrophe? The alphanumeric filter conveniently also filters out domain specific entities (hashtags and mentions).\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 raw tokens containing whitespace.\n"
     ]
    }
   ],
   "source": [
    "a, b, _, _ = norm_condition(full_raw, full_norm, lambda x: any(char.isspace() for char in x), True)\n",
    "print(f\"There are {sum((a+b).values())} raw tokens containing whitespace.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 950 rt tokens total, with 921 left alone. rt at the start of a tweet is a domain specific entity and thus should be disregarded as per rule 3. In the middle of a tweet, this is more debatable. There are 860 rt tokens at the start of tweets, which are all left alone. Middle rts (85) are inconsistently normalised (27 normalised), but if they are normalised, this is to retweet. From observation looks like domain-specific rts are always followed by a @mention. 24/27 normalised middle rts are not followed by @, 42/58 left alone middle rts are. There are 6 rts at the end of tweets, and they are inconsistently normalised. So perhaps rule could be: if at start of tweet or followed by @mention, ignore. Otherwise normalise to retweet.\n"
     ]
    }
   ],
   "source": [
    "a, b, _, _ = norm_condition(full_raw, full_norm, lambda x: x == \"rt\", True)\n",
    "print(f\"There are {sum((a+b).values())} rt tokens total, with {sum(a.values())} left alone. rt at the start of a tweet is a domain specific entity and thus should be disregarded as per rule 3. In the middle of a tweet, this is more debatable. There are {sum(1 if tweet[0] == 'rt' else 0 for tweet in full_raw)} rt tokens at the start of tweets, which are all left alone. Middle rts (85) are inconsistently normalised (27 normalised), but if they are normalised, this is to retweet. From observation looks like domain-specific rts are always followed by a @mention. 24/27 normalised middle rts are not followed by @, 42/58 left alone middle rts are. There are 6 rts at the end of tweets, and they are inconsistently normalised. So perhaps rule could be: if at start of tweet or followed by @mention, ignore. Otherwise normalise to retweet.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for tweet_raw, tweet_norm in zip(full_raw, full_norm):\n",
    "#     for i, tok in enumerate(zip(tweet_raw, tweet_norm)):\n",
    "#         tok_raw, tok_norm = tok\n",
    "#         # if tok_raw == 'rt' and 0 < i < len(tweet_raw)-1 and tok_raw == tok_norm:\n",
    "#         if tok_raw == 'rt' and i == len(tweet_raw)-1:\n",
    "#             # print(tweet_raw[i+1])\n",
    "#             print(tok_norm)\n",
    "#             count += 1\n",
    "# print(count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "spacy_full_raw = []\n",
    "for tweet in full_raw:\n",
    "    spacy_full_raw.append(nlp(\" \".join(tweet)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 8\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# for tweet in full_if_normed:\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#     for tok, norm in tweet:\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#         dok = nlp(tok)[0]\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#         type = dok.pos_\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#         if type == \"PROPN\":\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#             print(tok, norm)\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m a, b, c, d \u001B[38;5;241m=\u001B[39m \u001B[43mnorm_condition\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfull_raw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfull_norm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpos_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPROPN\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[17], line 17\u001B[0m, in \u001B[0;36mnorm_condition\u001B[0;34m(raw_list, norm_list, condition, pair, norm)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m raw \u001B[38;5;241m!=\u001B[39m normed \u001B[38;5;129;01mand\u001B[39;00m condition(tok):\n\u001B[1;32m     16\u001B[0m     p_normed\u001B[38;5;241m.\u001B[39mupdate([to_update])\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m raw \u001B[38;5;241m==\u001B[39m normed \u001B[38;5;129;01mand\u001B[39;00m \u001B[43mcondition\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtok\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     18\u001B[0m     p_unnormed\u001B[38;5;241m.\u001B[39mupdate([to_update])\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m raw \u001B[38;5;241m!=\u001B[39m normed \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m condition(tok):\n",
      "Cell \u001B[0;32mIn[24], line 8\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# for tweet in full_if_normed:\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#     for tok, norm in tweet:\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#         dok = nlp(tok)[0]\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#         type = dok.pos_\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m#         if type == \"PROPN\":\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#             print(tok, norm)\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m a, b, c, d \u001B[38;5;241m=\u001B[39m norm_condition(full_raw, full_norm, \u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mnlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mpos_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPROPN\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/spacy/language.py:1026\u001B[0m, in \u001B[0;36mLanguage.__call__\u001B[0;34m(self, text, disable, component_cfg)\u001B[0m\n\u001B[1;32m   1024\u001B[0m     error_handler \u001B[38;5;241m=\u001B[39m proc\u001B[38;5;241m.\u001B[39mget_error_handler()\n\u001B[1;32m   1025\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1026\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[43mproc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcomponent_cfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m   1027\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1028\u001B[0m     \u001B[38;5;66;03m# This typically happens if a component is not initialized\u001B[39;00m\n\u001B[1;32m   1029\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE109\u001B[38;5;241m.\u001B[39mformat(name\u001B[38;5;241m=\u001B[39mname)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001B[0m, in \u001B[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/spacy/pipeline/transition_parser.pyx:253\u001B[0m, in \u001B[0;36mspacy.pipeline.transition_parser.Parser.predict\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/spacy/pipeline/transition_parser.pyx:274\u001B[0m, in \u001B[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/thinc/model.py:315\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutT:\n\u001B[1;32m    312\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001B[39;00m\n\u001B[1;32m    313\u001B[0m \u001B[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001B[39;00m\n\u001B[1;32m    314\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 315\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/spacy/ml/tb_framework.py:33\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(model, X, is_train):\n\u001B[0;32m---> 33\u001B[0m     step_model \u001B[38;5;241m=\u001B[39m \u001B[43mParserStepModel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m        \u001B[49m\u001B[43munseen_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munseen_classes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_upper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhas_upper\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m step_model, step_model\u001B[38;5;241m.\u001B[39mfinish_steps\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/spacy/ml/parser_model.pyx:213\u001B[0m, in \u001B[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/thinc/model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/thinc/model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/thinc/model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Documents/2/Diss/lexnorm/.venv/lib/python3.10/site-packages/thinc/model.py:288\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    286\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot add reference to node not in tree.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[1;32m    291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_func(\u001B[38;5;28mself\u001B[39m, X, is_train\u001B[38;5;241m=\u001B[39mis_train)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# for tweet in full_if_normed:\n",
    "#     for tok, norm in tweet:\n",
    "#         dok = nlp(tok)[0]\n",
    "#         type = dok.pos_\n",
    "#         if type == \"PROPN\":\n",
    "#             print(tok, norm)\n",
    "\n",
    "a, b, c, d = norm_condition(full_raw, full_norm, lambda x: nlp(x)[0].pos_ == \"PROPN\", True, False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(f\"{sum(b.values())}/{sum(d.values())+sum(b.values())}\")\n",
    "print(f\"Examples of unnormalised words tagged as PROPN not in lexicon: {[k[0] for k in a.keys() if k[0] not in words and k[0].isalnum()][:10]}\")\n",
    "print(f\"Correlation of PROPN and normalisation: {correlation_with_norm(a, b, c, d):.2f}. Very low - probably due to bad POS performance thanks to lower casing and other irregularities of the text - sort of a chicken and egg issue with downstream processing. A lot these could probably be found by expanding the lexicon instead - looking at POS tagging may be a red herring\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a, b, c, d = norm_condition(full_raw, full_norm, lambda x: nlp(x)[0].ent_type_ in ['LOC', 'PERSON'], True, False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Examples of unnormalised words with these entity types not in lexicon: {[k[0] for k in a.keys() if k[0] not in words and k[0].isalnum()][:10]}\")\n",
    "print(f\"Correlation of normalisation and these entity types: {correlation_with_norm(a, b, c, d):.2f}. Zero correlation, probably due to the same reasons as above.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def alphanum(raw_list, norm_list):\n",
    "    raw_resp, norm_resp = [], []\n",
    "    for raw_tweet, norm_tweet in zip(raw_list, norm_list):\n",
    "        raw_resp_tweet, norm_resp_tweet = [], []\n",
    "        for raw_tok, norm_tok in zip(raw_tweet, norm_tweet):\n",
    "            if raw_tok.isalnum() and raw_tok != 'rt':\n",
    "                raw_resp_tweet.append(raw_tok)\n",
    "                norm_resp_tweet.append(norm_tok)\n",
    "        raw_resp.append(raw_resp_tweet)\n",
    "        norm_resp.append(norm_resp_tweet)\n",
    "    return raw_resp, norm_resp\n",
    "\n",
    "def lexicon_investigate(raw_list, norm_list, lex):\n",
    "    \"\"\"\n",
    "    Gives statistics for a given lexicon\n",
    "    \"\"\"\n",
    "    a, b, c, d = norm_condition(*alphanum(raw_list, norm_list), lambda x: x in lex, pair=True)\n",
    "    print(f\"Correlation of lexicon with normalisation: {correlation_with_norm(a, b, c, d):.2f}\")\n",
    "    print(f\"Most common un-normalised raw alphanumeric tokens in lexicon: {a.most_common(20)}\")\n",
    "    print(f\"Most common normalised raw alphanumeric tokens in lexicon: {b.most_common(20)}\")\n",
    "    print(f\"Most common un-normalised raw alphanumeric tokens not in lexicon: {c.most_common(20)}\")\n",
    "    print(f\"Most common normalised raw alphanumeric tokens not in lexicon: {d.most_common(20)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of lexicon with normalisation: 0.31\n",
      "Most common un-normalised raw alphanumeric tokens in lexicon: [(('i', 'i'), 648), (('the', 'the'), 631), (('to', 'to'), 534), (('a', 'a'), 479), (('and', 'and'), 411), (('you', 'you'), 340), (('in', 'in'), 326), (('for', 'for'), 320), (('is', 'is'), 318), (('me', 'me'), 281), (('my', 'my'), 278), (('on', 'on'), 271), (('of', 'of'), 249), (('it', 'it'), 203), (('with', 'with'), 186), (('that', 'that'), 185), (('this', 'this'), 180), (('so', 'so'), 180), (('be', 'be'), 159), (('like', 'like'), 156)]\n",
      "Most common normalised raw alphanumeric tokens in lexicon: [(('u', 'you'), 328), (('nigga', 'nigger'), 57), (('niggas', 'niggers'), 52), (('n', 'and'), 47), (('ur', 'your'), 33), (('gonna', 'going to'), 29), (('r', 'are'), 22), (('d', 'the'), 22), (('bout', 'about'), 21), (('b', 'be'), 17), (('wit', 'with'), 17), (('tho', 'though'), 17), (('cause', 'because'), 16), (('dat', 'that'), 16), (('bc', 'because'), 16), (('ya', 'you'), 15), (('da', 'the'), 13), (('wanna', 'want to'), 12), (('cant', \"can't\"), 12), (('congrats', 'congratulations'), 12)]\n",
      "Most common un-normalised raw alphanumeric tokens not in lexicon: [(('lol', 'lol'), 272), (('haha', 'haha'), 81), (('omg', 'omg'), 67), (('lmao', 'lmao'), 51), (('bae', 'bae'), 45), (('niall', 'niall'), 40), (('2', '2'), 40), (('hahaha', 'hahaha'), 36), (('idk', 'idk'), 36), (('1', '1'), 34), (('exo', 'exo'), 31), (('wtf', 'wtf'), 26), (('5', '5'), 25), (('zayn', 'zayn'), 23), (('2014', '2014'), 23), (('smh', 'smh'), 21), (('3', '3'), 21), (('4', '4'), 20), (('xd', 'xd'), 16), (('tbh', 'tbh'), 16)]\n",
      "Most common normalised raw alphanumeric tokens not in lexicon: [(('im', \"i'm\"), 181), (('dont', \"don't\"), 92), (('pls', 'please'), 43), (('lil', 'little'), 35), (('thats', \"that's\"), 33), (('bruh', 'brother'), 31), (('aint', \"ain't\"), 30), (('ima', \"i'm going to\"), 25), (('ppl', 'people'), 25), (('yall', \"y'all\"), 23), (('cuz', 'because'), 22), (('didnt', \"didn't\"), 19), (('gon', 'gonna'), 18), (('tryna', 'trying to'), 18), (('imma', \"i'm going to\"), 18), (('fav', 'favorite'), 16), (('goin', 'going'), 16), (('ive', \"i've\"), 16), (('2', 'to'), 14), (('favourite', 'favorite'), 13)]\n"
     ]
    }
   ],
   "source": [
    "lexicon_investigate(full_raw, full_norm, words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation of lexicon with normalisation: 0.40\n",
      "Most common un-normalised raw alphanumeric tokens in lexicon: [(('i', 'i'), 648), (('the', 'the'), 631), (('to', 'to'), 534), (('a', 'a'), 479), (('and', 'and'), 411), (('you', 'you'), 340), (('in', 'in'), 326), (('for', 'for'), 320), (('is', 'is'), 318), (('me', 'me'), 281), (('my', 'my'), 278), (('on', 'on'), 271), (('of', 'of'), 249), (('it', 'it'), 203), (('with', 'with'), 186), (('that', 'that'), 185), (('this', 'this'), 180), (('so', 'so'), 180), (('be', 'be'), 159), (('like', 'like'), 156)]\n",
      "Most common normalised raw alphanumeric tokens in lexicon: [(('nigga', 'nigger'), 57), (('niggas', 'niggers'), 52), (('ur', 'your'), 33), (('gonna', 'going to'), 29), (('bout', 'about'), 21), (('wit', 'with'), 17), (('tho', 'though'), 17), (('cause', 'because'), 16), (('dat', 'that'), 16), (('bc', 'because'), 16), (('ya', 'you'), 15), (('da', 'the'), 13), (('wanna', 'want to'), 12), (('cant', \"can't\"), 12), (('congrats', 'congratulations'), 12), (('ur', \"you're\"), 12), (('yo', 'you'), 11), (('nd', 'and'), 11), (('pic', 'picture'), 11), (('dm', 'direct message'), 10)]\n",
      "Most common un-normalised raw alphanumeric tokens not in lexicon: [(('lol', 'lol'), 272), (('haha', 'haha'), 81), (('omg', 'omg'), 67), (('lmao', 'lmao'), 51), (('bae', 'bae'), 45), (('x', 'x'), 44), (('niall', 'niall'), 40), (('2', '2'), 40), (('hahaha', 'hahaha'), 36), (('idk', 'idk'), 36), (('1', '1'), 34), (('exo', 'exo'), 31), (('wtf', 'wtf'), 26), (('t', 't'), 25), (('5', '5'), 25), (('zayn', 'zayn'), 23), (('2014', '2014'), 23), (('smh', 'smh'), 21), (('c', 'c'), 21), (('b', 'b'), 21)]\n",
      "Most common normalised raw alphanumeric tokens not in lexicon: [(('u', 'you'), 328), (('im', \"i'm\"), 181), (('dont', \"don't\"), 92), (('n', 'and'), 47), (('pls', 'please'), 43), (('lil', 'little'), 35), (('thats', \"that's\"), 33), (('bruh', 'brother'), 31), (('aint', \"ain't\"), 30), (('ima', \"i'm going to\"), 25), (('ppl', 'people'), 25), (('yall', \"y'all\"), 23), (('cuz', 'because'), 22), (('r', 'are'), 22), (('d', 'the'), 22), (('didnt', \"didn't\"), 19), (('gon', 'gonna'), 18), (('tryna', 'trying to'), 18), (('imma', \"i'm going to\"), 18), (('b', 'be'), 17)]\n",
      "STRONG CORRELATION!\n",
      "So filter lexicon by removing all single letter words but a and i\n",
      "Filter tokens by ignoring some rts, alphanumeric/apostrophe only\n"
     ]
    }
   ],
   "source": [
    "lexicon_file = open(os.path.join(DATA_PATH, \"test/american-70.txt\"))\n",
    "lexicon = set()\n",
    "for line in lexicon_file:\n",
    "    word = line.strip().lower()\n",
    "    if len(word) > 1 or word in ['a', 'i']:\n",
    "        lexicon.add(word)\n",
    "lexicon_investigate(full_raw, full_norm, lexicon)\n",
    "print(\"STRONG CORRELATION!\")\n",
    "print(\"So filter lexicon by removing all single letter words but a and i\")\n",
    "print(\"Filter tokens by ignoring some rts, alphanumeric/apostrophe only\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from lexnorm.evaluation import condition_normalisation\n",
    "a, b, c, d = condition_normalisation.contingency(full_raw, full_norm, lambda x: \"'\" in x, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt\n",
      "rt\n",
      "rt\n",
      "So our initial filter only excludes three normalised tokens in the entire train + dev set - three middle rts followed by @ still normalised to retweet.\n"
     ]
    }
   ],
   "source": [
    "from lexnorm.models.annotation import list_eligible\n",
    "\n",
    "for tweet_raw, tweet_norm in zip(full_raw, full_norm):\n",
    "    elig = list_eligible(tweet_raw)\n",
    "    for token_raw, token_norm, lig in zip(tweet_raw, tweet_norm, elig):\n",
    "        if not lig and token_raw != token_norm:\n",
    "            print(token_raw)\n",
    "\n",
    "print(\"So our initial filter only excludes three normalised tokens in the entire train + dev set - three middle rts followed by @ still normalised to retweet.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
